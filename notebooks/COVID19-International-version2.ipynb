{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID19 International V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Python-setup\" data-toc-modified-id=\"Python-setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Python setup</a></span></li><li><span><a href=\"#Get-the-raw-data-and-adjust-for-anomalies\" data-toc-modified-id=\"Get-the-raw-data-and-adjust-for-anomalies-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Get the raw data and adjust for anomalies</a></span><ul class=\"toc-item\"><li><span><a href=\"#Nation-naming-stuff\" data-toc-modified-id=\"Nation-naming-stuff-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Nation naming stuff</a></span></li><li><span><a href=\"#Population-data-retrieval\" data-toc-modified-id=\"Population-data-retrieval-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Population data retrieval</a></span></li><li><span><a href=\"#COVID-data-retrieval-and-adjustment-for-outliers\" data-toc-modified-id=\"COVID-data-retrieval-and-adjustment-for-outliers-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>COVID data retrieval and adjustment for outliers</a></span></li></ul></li><li><span><a href=\"#Plot-weekly-new-case/deaths-data-from-January-2020\" data-toc-modified-id=\"Plot-weekly-new-case/deaths-data-from-January-2020-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Plot weekly new-case/deaths data from January 2020</a></span></li><li><span><a href=\"#Plot-new-vs-cumulative-(all-and-last-3-months)\" data-toc-modified-id=\"Plot-new-vs-cumulative-(all-and-last-3-months)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Plot new-vs-cumulative (all and last 3 months)</a></span></li><li><span><a href=\"#International-comparisons---maps/leader-boards/swarms\" data-toc-modified-id=\"International-comparisons---maps/leader-boards/swarms-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>International comparisons - maps/leader-boards/swarms</a></span></li><li><span><a href=\"#Semi-log-comparison-plots-of-cumulative\" data-toc-modified-id=\"Semi-log-comparison-plots-of-cumulative-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Semi-log comparison plots of cumulative</a></span></li><li><span><a href=\"#Comparison-plots-of-daily-new-per-capita\" data-toc-modified-id=\"Comparison-plots-of-daily-new-per-capita-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Comparison plots of daily new per capita</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "#analytic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.units as munits\n",
    "import seaborn as sns\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import geopandas as gpd\n",
    "import iso3166\n",
    "\n",
    "# COVID19 specific imports\n",
    "sys.path.append(r'../bin')\n",
    "from datagrabber import get_data, get_population_from_eu\n",
    "import plotstuff as ps\n",
    "\n",
    "# directory\n",
    "CHART_DIRECTORY = '../charts'\n",
    "I_PREFIX = '/!I-'\n",
    "Path(CHART_DIRECTORY).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# display settings\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "# plotting stuff\n",
    "plt.style.use('ggplot')\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the raw data and adjust for anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nation naming stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make country names ISO compliant\n",
    "iso_name_map = {\n",
    "    # from              # to\n",
    "    \"Bolivia\":          \"Bolivia, Plurinational State of\",\n",
    "    \"Bonaire, Saint Eustatius And Saba\": \"Bonaire, Sint Eustatius and Saba\",\n",
    "    \"British Virgin Islands\": \"Virgin Islands, British\",\n",
    "    \"Brunei\":           \"Brunei Darussalam\",\n",
    "    \"Cape Verde\":       \"Cabo Verde\",\n",
    "    \"Cote D'Ivoire\":    \"Côte d'Ivoire\",\n",
    "    \"Curaã§Ao\":         \"Curaçao\",\n",
    "    \"Democratic Republic Of Congo\": \"Congo, Democratic Republic of the\",\n",
    "    \"Guinea Bissau\":    \"Guinea-Bissau\",\n",
    "    \"Vatican\":          \"Holy See\",\n",
    "    \"Iran\":             \"Iran, Islamic Republic of\",\n",
    "    \"Laos\":             \"Lao People's Democratic Republic\",\n",
    "    \"Moldova\":          \"Moldova, Republic of\",\n",
    "    \"Russia\":           \"Russian Federation\",\n",
    "    \"Sint Maarten\":     \"Sint Maarten (Dutch part)\",\n",
    "    \"South Korea\":      \"Korea, Republic of\",\n",
    "    \"Syria\":            \"Syrian Arab Republic\",\n",
    "    \"Timor Leste\":      \"Timor-Leste\",\n",
    "    \"United Kingdom\":   \"United Kingdom of Great Britain and Northern Ireland\",\n",
    "    \"United Republic Of Tanzania\": \"Tanzania, United Republic of\",\n",
    "    \"United States\":    \"United States of America\",\n",
    "    \"United States Virgin Islands\":   \"Virgin Islands, U.S.\",\n",
    "    \"Venezuela\":        \"Venezuela, Bolivarian Republic of\",\n",
    "    \"Vietnam\":          \"Viet Nam\",\n",
    "}\n",
    "\n",
    "must_name_map = {\n",
    "    # these names from the EU source are ugly and we will change anyway\n",
    "    \"Cote D'Ivoire\":    \"Côte d'Ivoire\",\n",
    "    \"Curaã§Ao\":         \"Curaçao\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_map(object_, map_):\n",
    "    \"\"\"Rename the index of a Series or the columns of a DataFrame\n",
    "       The renaming is done in place.\n",
    "       Parameters\n",
    "       - object_ - the pandas Series or DataFrame\n",
    "       - map_ - a dictionary of old to new mappings \n",
    "       Returns: None \"\"\"\n",
    "\n",
    "    fixing = {}\n",
    "    if isinstance(object_, pd.Series):\n",
    "        for name in map_:\n",
    "            if name in object_.index:\n",
    "                fixing[name] = map_[name]\n",
    "        object_.rename(index=fixing, inplace=True)\n",
    "    else:\n",
    "        for name in map_:\n",
    "            if name in object_.columns:\n",
    "                fixing[name] = map_[name]\n",
    "        object_.rename(columns=fixing, inplace=True)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_national_code(nation):\n",
    "    if nation in iso_name_map.keys():\n",
    "        nation = iso_name_map[nation]\n",
    "    code = iso3166.countries.get(nation).alpha2\n",
    "    return code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving data from: https://www.ecdc.europa.eu/sites/default/files/documents/COVID-19-geographic-disbtribution-worldwide-2020-12-02.xlsx\n",
      "https://www.ecdc.europa.eu/sites/default/files/documents/COVID-19-geographic-disbtribution-worldwide-2020-12-02.xlsx\n"
     ]
    }
   ],
   "source": [
    "# get population data\n",
    "population = get_population_from_eu()\n",
    "population = population[population.columns[0]] # to Series\n",
    "name_map(population, must_name_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COVID data retrieval and adjustment for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved from the lake\n",
      "Spikes in Andorra\n",
      "DateRep  2020-06-03\n",
      "spike     79.000000\n",
      "mean       0.714286\n",
      "zeros     10.000000\n",
      "Data too sparse in Anguilla (max_consecutive=1)\n",
      "Data too sparse in Antigua And Barbuda (max_consecutive=2)\n",
      "Data too sparse in Barbados (max_consecutive=11)\n",
      "Negatives in Benin\n",
      "DateRep\n",
      "2020-05-20   -209.0\n",
      "Name: Benin, dtype: float64\n",
      "Data too sparse in Benin (max_consecutive=10)\n",
      "Data too sparse in Bermuda (max_consecutive=3)\n",
      "Data too sparse in Bhutan (max_consecutive=6)\n",
      "Data too sparse in Bonaire, Saint Eustatius And Saba (max_consecutive=5)\n",
      "Data too sparse in Botswana (max_consecutive=2)\n",
      "Data too sparse in British Virgin Islands (max_consecutive=2)\n",
      "Spikes in Burkina Faso\n",
      "DateRep  2020-05-07  2020-09-14\n",
      "spike     41.000000  193.000000\n",
      "mean       6.714286   14.714286\n",
      "zeros      0.000000    0.000000\n",
      "Data too sparse in Burundi (max_consecutive=11)\n",
      "Data too sparse in Cambodia (max_consecutive=11)\n",
      "Data too sparse in Cameroon (max_consecutive=10)\n",
      "Spikes in Cape Verde\n",
      "DateRep  2020-04-16\n",
      "spike     44.000000\n",
      "mean       1.571429\n",
      "zeros      6.000000\n",
      "Negatives in Cases On An International Conveyance Japan\n",
      "DateRep\n",
      "2020-03-10   -9.0\n",
      "Name: Cases On An International Conveyance Japan, dtype: float64\n",
      "Data too sparse in Cases On An International Conveyance Japan (max_consecutive=4)\n",
      "Data too sparse in Cayman Islands (max_consecutive=7)\n",
      "Spikes in Chile\n",
      "DateRep    2020-06-18\n",
      "spike    36179.000000\n",
      "mean      5391.285714\n",
      "zeros        0.000000\n",
      "Spikes in China\n",
      "DateRep    2020-02-13  2020-04-17\n",
      "spike    15141.000000  352.000000\n",
      "mean      2513.642857   47.285714\n",
      "zeros        0.000000    0.000000\n",
      "Data too sparse in Comoros (max_consecutive=4)\n",
      "Data too sparse in Congo (max_consecutive=4)\n",
      "Data too sparse in Dominica (max_consecutive=3)\n",
      "Negatives in Ecuador\n",
      "DateRep\n",
      "2020-05-07   -2461.0\n",
      "2020-05-09   -1480.0\n",
      "2020-05-12     -50.0\n",
      "2020-09-07   -8261.0\n",
      "Name: Ecuador, dtype: float64\n",
      "Spikes in Ecuador\n",
      "DateRep   2020-04-11   2020-04-27\n",
      "spike    1660.628163  8723.591297\n",
      "mean      166.959460   485.052072\n",
      "zeros       0.000000     2.000000\n",
      "Data too sparse in Equatorial Guinea (max_consecutive=5)\n",
      "Data too sparse in Eritrea (max_consecutive=6)\n",
      "Data too sparse in Falkland Islands (Malvinas) (max_consecutive=1)\n",
      "Data too sparse in Fiji (max_consecutive=4)\n",
      "Negatives in France\n",
      "DateRep\n",
      "2020-06-03   -766.0\n",
      "Name: France, dtype: float64\n",
      "Spikes in France\n",
      "DateRep   2020-05-07   2020-05-29\n",
      "spike    4142.326578  3292.669346\n",
      "mean      687.251887   478.929160\n",
      "zeros       0.000000     0.000000\n",
      "Data too sparse in French Polynesia (max_consecutive=8)\n",
      "Data too sparse in Gabon (max_consecutive=6)\n",
      "Data too sparse in Gambia (max_consecutive=7)\n",
      "Data too sparse in Greenland (max_consecutive=4)\n",
      "Data too sparse in Grenada (max_consecutive=2)\n",
      "Data too sparse in Guinea Bissau (max_consecutive=6)\n",
      "Data too sparse in Vatican (max_consecutive=2)\n",
      "Data too sparse in Isle Of Man (max_consecutive=14)\n",
      "Negatives in Italy\n",
      "DateRep\n",
      "2020-06-20   -148.0\n",
      "Name: Italy, dtype: float64\n",
      "Negatives in Jersey\n",
      "DateRep\n",
      "2020-09-11   -6.0\n",
      "Name: Jersey, dtype: float64\n",
      "Data too sparse in Jersey (max_consecutive=7)\n",
      "Negatives in Jordan\n",
      "DateRep\n",
      "2020-07-22   -110.0\n",
      "Name: Jordan, dtype: float64\n",
      "Spikes in Kazakhstan\n",
      "DateRep    2020-07-01\n",
      "spike    19246.000000\n",
      "mean       970.142857\n",
      "zeros        0.000000\n",
      "Spikes in Kyrgyzstan\n",
      "DateRep    2020-07-18\n",
      "spike    11505.000000\n",
      "mean       764.357143\n",
      "zeros        0.000000\n",
      "Data too sparse in Laos (max_consecutive=2)\n",
      "Data too sparse in Lesotho (max_consecutive=5)\n",
      "Negatives in Lithuania\n",
      "DateRep\n",
      "2020-04-29   -105.0\n",
      "Name: Lithuania, dtype: float64\n",
      "Negatives in Luxembourg\n",
      "DateRep\n",
      "2020-08-28   -1385.0\n",
      "Name: Luxembourg, dtype: float64\n",
      "Spikes in Madagascar\n",
      "DateRep  2020-10-25  2020-11-22\n",
      "spike         158.0   77.000000\n",
      "mean            4.0    2.214286\n",
      "zeros          13.0   13.000000\n",
      "Spikes in Malaysia\n",
      "DateRep  2020-06-06\n",
      "spike    296.000000\n",
      "mean      34.071429\n",
      "zeros      1.000000\n",
      "Spikes in Maldives\n",
      "DateRep  2020-05-01\n",
      "spike    191.000000\n",
      "mean      26.142857\n",
      "zeros      1.000000\n",
      "Data too sparse in Marshall Islands (max_consecutive=1)\n",
      "Data too sparse in Mauritania (max_consecutive=10)\n",
      "Data too sparse in Mongolia (max_consecutive=12)\n",
      "Data too sparse in Montserrat (max_consecutive=1)\n",
      "Data too sparse in New Caledonia (max_consecutive=7)\n",
      "Data too sparse in Nicaragua (max_consecutive=3)\n",
      "Data too sparse in Northern Mariana Islands (max_consecutive=3)\n",
      "Spikes in Palestine\n",
      "DateRep  2020-04-27\n",
      "spike         153.0\n",
      "mean            4.0\n",
      "zeros           5.0\n",
      "Data too sparse in Papua New Guinea (max_consecutive=8)\n",
      "Spikes in Paraguay\n",
      "DateRep  2020-05-10  2020-05-20\n",
      "spike    126.000000        41.0\n",
      "mean      22.785714         8.0\n",
      "zeros      0.000000         0.0\n",
      "Negatives in Portugal\n",
      "DateRep\n",
      "2020-05-03   -161.0\n",
      "Name: Portugal, dtype: float64\n",
      "Spikes in Qatar\n",
      "DateRep  2020-03-12\n",
      "spike    238.000000\n",
      "mean      14.714286\n",
      "zeros      3.000000\n",
      "Data too sparse in Saint Kitts And Nevis (max_consecutive=2)\n",
      "Data too sparse in Saint Lucia (max_consecutive=10)\n",
      "Data too sparse in Saint Vincent And The Grenadines (max_consecutive=3)\n",
      "Negatives in San Marino\n",
      "DateRep\n",
      "2020-05-11   -9.0\n",
      "Name: San Marino, dtype: float64\n",
      "Data too sparse in Sao Tome And Principe (max_consecutive=11)\n",
      "Spikes in Senegal\n",
      "DateRep  2020-09-16\n",
      "spike    223.000000\n",
      "mean      37.285714\n",
      "zeros      0.000000\n",
      "Data too sparse in Seychelles (max_consecutive=3)\n",
      "Data too sparse in Solomon Islands (max_consecutive=2)\n",
      "Data too sparse in Somalia (max_consecutive=7)\n",
      "Data too sparse in South Sudan (max_consecutive=10)\n",
      "Negatives in Spain\n",
      "DateRep\n",
      "2020-04-19   -713.0\n",
      "2020-05-25   -372.0\n",
      "Name: Spain, dtype: float64\n",
      "Spikes in Sri Lanka\n",
      "DateRep  2020-07-10  2020-10-07\n",
      "spike    256.000000  519.000000\n",
      "mean      26.928571   82.571429\n",
      "zeros      0.000000    0.000000\n",
      "Data too sparse in Sudan (max_consecutive=14)\n",
      "Data too sparse in Taiwan (max_consecutive=12)\n",
      "Data too sparse in Timor Leste (max_consecutive=3)\n",
      "Spikes in Trinidad And Tobago\n",
      "DateRep  2020-03-22\n",
      "spike     40.000000\n",
      "mean       2.285714\n",
      "zeros      3.000000\n",
      "Negatives in Uganda\n",
      "DateRep\n",
      "2020-05-21   -115.0\n",
      "2020-06-02     -1.0\n",
      "Name: Uganda, dtype: float64\n",
      "Data too sparse in United Republic Of Tanzania (max_consecutive=7)\n",
      "Data too sparse in United States Virgin Islands (max_consecutive=8)\n",
      "Data too sparse in Vanuatu (max_consecutive=1)\n",
      "Data too sparse in Wallis And Futuna (max_consecutive=1)\n",
      "Data too sparse in Western Sahara (max_consecutive=2)\n",
      "Spikes in Zimbabwe\n",
      "DateRep  2020-06-19\n",
      "spike     62.000000\n",
      "mean      12.071429\n",
      "zeros      0.000000\n",
      "Data retrieved from the lake\n",
      "Data too sparse in Anguilla (max_consecutive=0)\n",
      "Data too sparse in Antigua And Barbuda (max_consecutive=1)\n",
      "Spikes in Argentina\n",
      "DateRep   2020-10-02\n",
      "spike    3351.000000\n",
      "mean      355.928571\n",
      "zeros       0.000000\n",
      "Data too sparse in Aruba (max_consecutive=3)\n",
      "Data too sparse in Bahamas (max_consecutive=7)\n",
      "Data too sparse in Barbados (max_consecutive=3)\n",
      "Data too sparse in Benin (max_consecutive=4)\n",
      "Data too sparse in Bermuda (max_consecutive=2)\n",
      "Data too sparse in Bhutan (max_consecutive=0)\n",
      "Spikes in Bolivia\n",
      "DateRep   2020-09-07\n",
      "spike    1610.000000\n",
      "mean       56.857143\n",
      "zeros       1.000000\n",
      "Data too sparse in Bonaire, Saint Eustatius And Saba (max_consecutive=1)\n",
      "Data too sparse in Botswana (max_consecutive=1)\n",
      "Data too sparse in British Virgin Islands (max_consecutive=1)\n",
      "Data too sparse in Brunei (max_consecutive=1)\n",
      "Data too sparse in Burkina Faso (max_consecutive=5)\n",
      "Data too sparse in Burundi (max_consecutive=1)\n",
      "Data too sparse in Cambodia (max_consecutive=0)\n",
      "Data too sparse in Cameroon (max_consecutive=5)\n",
      "Spikes in Canada\n",
      "DateRep  2020-10-03\n",
      "spike     90.000000\n",
      "mean      17.571429\n",
      "zeros      0.000000\n",
      "Data too sparse in Cape Verde (max_consecutive=5)\n",
      "Data too sparse in Cases On An International Conveyance Japan (max_consecutive=1)\n",
      "Data too sparse in Cayman Islands (max_consecutive=1)\n",
      "Data too sparse in Central African Republic (max_consecutive=4)\n",
      "Data too sparse in Chad (max_consecutive=6)\n",
      "Spikes in Chile\n",
      "DateRep  2020-06-08   2020-07-18\n",
      "spike    649.000000  1057.000000\n",
      "mean     119.785714    83.928571\n",
      "zeros      0.000000     0.000000\n",
      "Spikes in China\n",
      "DateRep  2020-04-17\n",
      "spike        1290.0\n",
      "mean            0.5\n",
      "zeros          10.0\n",
      "Data too sparse in Comoros (max_consecutive=1)\n",
      "Data too sparse in Congo (max_consecutive=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data too sparse in Côte d'Ivoire (max_consecutive=5)\n",
      "Data too sparse in Cuba (max_consecutive=14)\n",
      "Data too sparse in Curaçao (max_consecutive=1)\n",
      "Data too sparse in Cyprus (max_consecutive=6)\n",
      "Negatives in Czechia\n",
      "DateRep\n",
      "2020-07-05   -1.0\n",
      "2020-07-06   -3.0\n",
      "Name: Czechia, dtype: float64\n",
      "Data too sparse in Democratic Republic Of Congo (max_consecutive=9)\n",
      "Data too sparse in Djibouti (max_consecutive=4)\n",
      "Data too sparse in Dominica (max_consecutive=0)\n",
      "Spikes in Ecuador\n",
      "DateRep   2020-09-07  2020-10-09\n",
      "spike    3800.000000       398.0\n",
      "mean       40.428571        39.5\n",
      "zeros       0.000000         0.0\n",
      "Data too sparse in Equatorial Guinea (max_consecutive=2)\n",
      "Data too sparse in Eritrea (max_consecutive=0)\n",
      "Data too sparse in Estonia (max_consecutive=10)\n",
      "Data too sparse in Eswatini (max_consecutive=8)\n",
      "Data too sparse in Falkland Islands (Malvinas) (max_consecutive=0)\n",
      "Data too sparse in Faroe Islands (max_consecutive=0)\n",
      "Data too sparse in Fiji (max_consecutive=1)\n",
      "Spikes in Finland\n",
      "DateRep  2020-04-22\n",
      "spike     43.000000\n",
      "mean       6.928571\n",
      "zeros      0.000000\n",
      "Data too sparse in French Polynesia (max_consecutive=2)\n",
      "Data too sparse in Gabon (max_consecutive=5)\n",
      "Data too sparse in Gambia (max_consecutive=6)\n",
      "Data too sparse in Ghana (max_consecutive=4)\n",
      "Data too sparse in Gibraltar (max_consecutive=2)\n",
      "Data too sparse in Greenland (max_consecutive=0)\n",
      "Data too sparse in Grenada (max_consecutive=0)\n",
      "Data too sparse in Guam (max_consecutive=7)\n",
      "Data too sparse in Guernsey (max_consecutive=3)\n",
      "Data too sparse in Guinea (max_consecutive=3)\n",
      "Data too sparse in Guinea Bissau (max_consecutive=2)\n",
      "Data too sparse in Guyana (max_consecutive=10)\n",
      "Data too sparse in Haiti (max_consecutive=8)\n",
      "Data too sparse in Vatican (max_consecutive=0)\n",
      "Data too sparse in Iceland (max_consecutive=3)\n",
      "Spikes in India\n",
      "DateRep   2020-06-17\n",
      "spike    2003.000000\n",
      "mean      357.642857\n",
      "zeros       0.000000\n",
      "Negatives in Ireland\n",
      "DateRep\n",
      "2020-10-03   -5.0\n",
      "Name: Ireland, dtype: float64\n",
      "Data too sparse in Isle Of Man (max_consecutive=5)\n",
      "Spikes in Israel\n",
      "DateRep  2020-08-20  2020-11-23\n",
      "spike          71.0   49.000000\n",
      "mean           13.0    6.714286\n",
      "zeros           0.0    1.000000\n",
      "Negatives in Italy\n",
      "DateRep\n",
      "2020-06-25   -31.0\n",
      "Name: Italy, dtype: float64\n",
      "Spikes in Italy\n",
      "DateRep  2020-08-16\n",
      "spike    158.000000\n",
      "mean       5.857143\n",
      "zeros      0.000000\n",
      "Spikes in Japan\n",
      "DateRep  2020-04-23\n",
      "spike    101.000000\n",
      "mean      13.928571\n",
      "zeros      1.000000\n",
      "Data too sparse in Jersey (max_consecutive=4)\n",
      "Spikes in Kazakhstan\n",
      "DateRep  2020-07-21  2020-09-16  2020-11-03\n",
      "spike         210.0   38.000000   34.000000\n",
      "mean            0.0    7.357143    3.071429\n",
      "zeros          14.0    0.000000    3.000000\n",
      "Negatives in Kosovo\n",
      "DateRep\n",
      "2020-08-06   -12.0\n",
      "Name: Kosovo, dtype: float64\n",
      "Negatives in Kyrgyzstan\n",
      "DateRep\n",
      "2020-08-24   -443.0\n",
      "Name: Kyrgyzstan, dtype: float64\n",
      "Spikes in Kyrgyzstan\n",
      "DateRep  2020-07-18\n",
      "spike    512.850805\n",
      "mean      20.077264\n",
      "zeros      0.000000\n",
      "Data too sparse in Laos (max_consecutive=0)\n",
      "Data too sparse in Latvia (max_consecutive=13)\n",
      "Data too sparse in Lesotho (max_consecutive=3)\n",
      "Data too sparse in Liberia (max_consecutive=4)\n",
      "Data too sparse in Liechtenstein (max_consecutive=2)\n",
      "Data too sparse in Maldives (max_consecutive=4)\n",
      "Data too sparse in Mali (max_consecutive=8)\n",
      "Data too sparse in Marshall Islands (max_consecutive=0)\n",
      "Data too sparse in Mauritania (max_consecutive=3)\n",
      "Data too sparse in Mauritius (max_consecutive=2)\n",
      "Spikes in Mexico\n",
      "DateRep   2020-10-09\n",
      "spike    3013.000000\n",
      "mean      330.428571\n",
      "zeros       1.000000\n",
      "Data too sparse in Monaco (max_consecutive=1)\n",
      "Data too sparse in Mongolia (max_consecutive=0)\n",
      "Data too sparse in Montserrat (max_consecutive=1)\n",
      "Data too sparse in Mozambique (max_consecutive=11)\n",
      "Data too sparse in New Caledonia (max_consecutive=0)\n",
      "Data too sparse in New Zealand (max_consecutive=5)\n",
      "Data too sparse in Nicaragua (max_consecutive=1)\n",
      "Data too sparse in Niger (max_consecutive=5)\n",
      "Data too sparse in Northern Mariana Islands (max_consecutive=1)\n",
      "Spikes in Pakistan\n",
      "DateRep  2020-11-20\n",
      "spike    313.000000\n",
      "mean      37.785714\n",
      "zeros      0.000000\n",
      "Data too sparse in Papua New Guinea (max_consecutive=2)\n",
      "Spikes in Peru\n",
      "DateRep   2020-07-24   2020-08-14\n",
      "spike    3887.000000  3935.000000\n",
      "mean      194.071429   205.071429\n",
      "zeros       0.000000     0.000000\n",
      "Data too sparse in Qatar (max_consecutive=12)\n",
      "Data too sparse in Rwanda (max_consecutive=3)\n",
      "Data too sparse in Saint Kitts And Nevis (max_consecutive=0)\n",
      "Data too sparse in Saint Lucia (max_consecutive=1)\n",
      "Data too sparse in Saint Vincent And The Grenadines (max_consecutive=0)\n",
      "Data too sparse in San Marino (max_consecutive=4)\n",
      "Data too sparse in Sao Tome And Principe (max_consecutive=3)\n",
      "Data too sparse in Seychelles (max_consecutive=0)\n",
      "Data too sparse in Sierra Leone (max_consecutive=8)\n",
      "Data too sparse in Singapore (max_consecutive=4)\n",
      "Data too sparse in Sint Maarten (max_consecutive=2)\n",
      "Data too sparse in Slovakia (max_consecutive=12)\n",
      "Data too sparse in Solomon Islands (max_consecutive=0)\n",
      "Data too sparse in Somalia (max_consecutive=6)\n",
      "Data too sparse in South Sudan (max_consecutive=2)\n",
      "Negatives in Spain\n",
      "DateRep\n",
      "2020-05-25   -1918.0\n",
      "2020-08-12      -2.0\n",
      "Name: Spain, dtype: float64\n",
      "Spikes in Spain\n",
      "DateRep  2020-05-22   2020-06-19\n",
      "spike    639.887028  1179.000000\n",
      "mean      76.479675     1.642857\n",
      "zeros      0.000000     7.000000\n",
      "Data too sparse in Sudan (max_consecutive=10)\n",
      "Data too sparse in Suriname (max_consecutive=8)\n",
      "Data too sparse in Taiwan (max_consecutive=1)\n",
      "Data too sparse in Tajikistan (max_consecutive=5)\n",
      "Data too sparse in Thailand (max_consecutive=10)\n",
      "Data too sparse in Timor Leste (max_consecutive=0)\n",
      "Data too sparse in Togo (max_consecutive=4)\n",
      "Data too sparse in Trinidad And Tobago (max_consecutive=10)\n",
      "Data too sparse in Turks And Caicos Islands (max_consecutive=1)\n",
      "Data too sparse in Uganda (max_consecutive=9)\n",
      "Data too sparse in United Republic Of Tanzania (max_consecutive=2)\n",
      "Data too sparse in United States Virgin Islands (max_consecutive=3)\n",
      "Data too sparse in Uruguay (max_consecutive=4)\n",
      "Data too sparse in Vanuatu (max_consecutive=0)\n",
      "Data too sparse in Vietnam (max_consecutive=4)\n",
      "Data too sparse in Wallis And Futuna (max_consecutive=0)\n",
      "Data too sparse in Western Sahara (max_consecutive=1)\n",
      "Spikes in Yemen\n",
      "DateRep  2020-07-13\n",
      "spike          52.0\n",
      "mean            4.0\n",
      "zeros           0.0\n",
      "Data too sparse in Zambia (max_consecutive=9)\n",
      "Data too sparse in Zimbabwe (max_consecutive=12)\n"
     ]
    }
   ],
   "source": [
    "# get case data \n",
    "DATA_SOURCE = 'EU' # 'EU' or 'OWID'\n",
    "CASES = 0\n",
    "DEATHS = 1\n",
    "modes = {\n",
    "    'Cases': CASES,\n",
    "    'Deaths': DEATHS,\n",
    "}\n",
    "raw_cum_data = [None, None]\n",
    "raw_daily_data = [None, None]\n",
    "adj_daily_data = [None, None]\n",
    "adj_cum_data = [None, None]\n",
    "\n",
    "data_quality = [None, None]\n",
    "\n",
    "for mode, index in modes.items():\n",
    "    \n",
    "    # get the raw data\n",
    "    raw_cum_data[index], source = get_data(data_type=mode.lower(),\n",
    "                                     from_where=DATA_SOURCE)\n",
    "    name_map(raw_cum_data[index], must_name_map)\n",
    "    \n",
    "    # make missing data zero\n",
    "    raw_cum_data[index] = raw_cum_data[index].fillna(0)\n",
    "    \n",
    "    # adjust data for anomalies\n",
    "    (raw_daily_data[index], \n",
    "        adj_daily_data[index], \n",
    "        adj_cum_data[index]) = ps.dataframe_correction(\n",
    "                                    raw_cum_data[index])\n",
    "    \n",
    "    # identify whether the adjustment for anomalies \n",
    "    # changed the data\n",
    "    data_quality[index] = pd.Series(None, \n",
    "                            index=raw_cum_data[index].columns,\n",
    "                            dtype='str')\n",
    "    for col in raw_cum_data[index].columns:\n",
    "        if (raw_daily_data[index][col] == \n",
    "            adj_daily_data[index][col]).all():\n",
    "            data_quality[index][col] = (f'Source: {source}, '\n",
    "                                         'original data')\n",
    "        else:\n",
    "            data_quality[index][col] = (f'Source: {source}, '\n",
    "                            'data adjusted for extreme outliers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot weekly new-case/deaths data from January 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_weekly(daily, mode, data_quality, dfrom=\"2020-01-21\"):\n",
    "    \"\"\"Plot weekly bar charts for daily new cases and deaths\n",
    "        Function paramters:\n",
    "        - daily is a DataFrame of daily timeseries data\n",
    "        - mode is one of 'cases' or 'deaths' \n",
    "        - data_quality is a Series of strings,\n",
    "            used for the left footnote on charts\n",
    "        - dfrom is a date string to display from\n",
    "        Returns: weekly data in a DataFrame \"\"\"\n",
    "    \n",
    "    DISPLAY_FROM = pd.Timestamp(dfrom)\n",
    "    \n",
    "    # find the day that the week ends - last day of dataframe\n",
    "    LAST_DAY = daily.index[-1]\n",
    "    RULE = {\n",
    "        0: 'W-MON',\n",
    "        1: 'W-TUE',\n",
    "        2: 'W-WED',\n",
    "        3: 'W-THU',\n",
    "        4: 'W-FRI',\n",
    "        5: 'W-SAT',\n",
    "        6: 'W-SUN',\n",
    "    }[LAST_DAY.dayofweek]\n",
    "\n",
    "    # convert the data to weekly\n",
    "    returnable = weekly = daily.resample(rule=RULE, \n",
    "                                         closed='right').sum()\n",
    "    total = weekly.sum()\n",
    "    \n",
    "    # adjust data and dates for plotting\n",
    "    # we move the data by half a week becuase \n",
    "    # we want the bars to be centred\n",
    "    weekly = weekly[weekly.index > DISPLAY_FROM]\n",
    "    weekly.index = weekly.index - pd.Timedelta(3.5, unit='d')\n",
    "    \n",
    "    for name in daily.columns:\n",
    "    \n",
    "        # avoid plotting an empty plot\n",
    "        if total[name] == 0: continue\n",
    "    \n",
    "        # plot the data\n",
    "        fig, ax = plt.subplots(figsize=(8, 4))\n",
    "        ax.bar(weekly.index, weekly[name], width=5, color='#dd0000', )\n",
    "        ax.margins(0.01)\n",
    "            \n",
    "        # This makes the dates for xticklabels look a little nicer\n",
    "        locator = mdates.AutoDateLocator(minticks=4, maxticks=13)\n",
    "        formatter = mdates.ConciseDateFormatter(locator)\n",
    "        ax.xaxis.set_major_locator(locator)\n",
    "        ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "        # label the plot\n",
    "        ax.set_title(f'COVID-19 {mode.title()}: {name}')\n",
    "        ax.set_ylabel(f'New {mode.lower()}/week ending '\n",
    "                      f'{RULE[-3:].title()}')\n",
    "        ax.set_xlabel(None)\n",
    "        \n",
    "        # adjust y-limits to be prettier, \n",
    "        # assume ylim[0] is zero\n",
    "        # this adjustment should not be needed, but it is\n",
    "        ylim = ax.get_ylim()\n",
    "        ylim = ylim[0], ylim[1] * 1.025\n",
    "        ax.set_ylim(ylim)\n",
    "        if ylim[0] != 0:\n",
    "            # this should not happen - ever.\n",
    "            print(f'Warning: ylim[0] is {ylim[0]} for {name}')\n",
    "        \n",
    "        # an ugly kludge for putting commas in the ylabels\n",
    "        def small(x): return np.round(x, 2)\n",
    "        def big(x): return int(x)\n",
    "        functor = small if weekly[name].max() <= 4 else big\n",
    "        ax.get_yaxis().set_major_formatter(\n",
    "            mpl.ticker.FuncFormatter(\n",
    "                lambda x, p: format(functor(x), ',')))\n",
    "            \n",
    "        fig = ax.figure\n",
    "        \n",
    "        # footnote the plot\n",
    "        fig.text(0.01, 0.01, \n",
    "            f'Total {mode.lower()}: {int(total[name]):,}',\n",
    "            ha='left', va='bottom',\n",
    "            fontsize=9, fontstyle='italic',\n",
    "            color='#999999')\n",
    "        fig.text(0.99, 0.01, \n",
    "            data_quality[index][name],\n",
    "            ha='right', va='bottom',\n",
    "            fontsize=9, fontstyle='italic',\n",
    "            color='#999999')\n",
    "\n",
    "        # final tidy - save - close\n",
    "        fig.tight_layout(pad=1.2)\n",
    "        #plt.show()\n",
    "        fig.savefig(\n",
    "            f'{CHART_DIRECTORY}/{name}-{mode.lower()}-new-weekly', \n",
    "            dpi=125)\n",
    "        plt.close()\n",
    "        \n",
    "    return returnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True: # switch this output on/off\n",
    "    adj_weekly_data = [None, None]\n",
    "    for (mode, index) in modes.items():\n",
    "        daily = adj_daily_data[index]\n",
    "        adj_weekly_data[index] = plot_weekly(daily, mode.lower(), \n",
    "                                             data_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot new-vs-cumulative (all and last 3 months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True: # switch this output on/off\n",
    "\n",
    "    THREE_MONTHS = 93 # days\n",
    "    periods = [0, THREE_MONTHS]\n",
    "\n",
    "    tags = [\"full\", \"3months\"]  \n",
    "    for period, tag in zip(periods, tags):\n",
    "        for mode, index in modes.items():\n",
    "            for name in adj_cum_data[index].columns:\n",
    "        \n",
    "                # let's not plot empty charts\n",
    "                if adj_daily_data[index][name][-period:].sum() == 0: \n",
    "                    continue\n",
    "            \n",
    "                ps.plot_new_cum(\n",
    "                    adj_daily_data[index][name][-period:].copy(), \n",
    "                    adj_cum_data[index][name][-period:].copy(), \n",
    "                    mode, name, \n",
    "                    title=f'{name}: COVID-19 {mode.title()}',\n",
    "                    rfooter=data_quality[index][name],\n",
    "                    tight=1.2, \n",
    "                    savefig=f'{CHART_DIRECTORY}/{name}-{mode.lower()}'\n",
    "                                f'-new-vs-cum-{tag}.png'\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## International comparisons - maps/leader-boards/swarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_million_population(population: pd.Series, power:int = 6):\n",
    "    \"\"\"Take a population series and a power and return in a tuple:\n",
    "       - the power\n",
    "       - the factor (which is 10 ** power)\n",
    "       - an updated population series (which is population / factor)\"\"\"\n",
    "    \n",
    "    factor = 10 ** power\n",
    "    return power, factor, population / factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rear_offsets(dataframe, period):\n",
    "    \"\"\"Get offset to last non-zero values in dataframe by col\n",
    "       provided offset is within period, otherwise zero offset\n",
    "       [We do this becuase some nations are slow in reporting,\n",
    "       and without this adjustment late reporting nations would \n",
    "       look better than they actually are.]\"\"\"\n",
    "    \n",
    "    nrows = len(dataframe)\n",
    "    rear_offsets = pd.Series(0, index=dataframe.columns)\n",
    "    for col in dataframe.columns:\n",
    "        index_array = (np.nonzero(dataframe[col].to_numpy()))[0]\n",
    "        if len(index_array) > 0:\n",
    "            last = index_array[-1]\n",
    "            rear_offsets[col] = nrows - last - 1\n",
    "            # Note: rear_offsets[col] is 0 if len(index_array) == 0\n",
    "    rear_offsets = rear_offsets.where(rear_offsets<=period, other=0)\n",
    "    return rear_offsets\n",
    "\n",
    "def get_recent_total(dataframe, rear_offsets, period):\n",
    "    \"\"\"Sum the last rows of a dataframe, making adjustments\n",
    "       for zero rows at the very end\"\"\"\n",
    "    \n",
    "    daily_sum = pd.Series(0.0, index=dataframe.columns)\n",
    "    for col in dataframe.columns:\n",
    "        p = 0 - (period+rear_offsets[col])\n",
    "        daily_sum[col] = dataframe[col].iloc[p:].sum()\n",
    "    return daily_sum\n",
    "\n",
    "def get_larger_nations(population, thresh=100_000):\n",
    "    \"\"\"return a list of nations with a population exceeding thresh\"\"\"\n",
    "    \n",
    "    return population[population >= thresh].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_world(series, title, legend_title, source):\n",
    "    \n",
    "    # prepare data for mapping\n",
    "    name_map(series, iso_name_map)\n",
    "    score = pd.DataFrame(series) # back to DataFrame\n",
    "    score.columns = ['Score']\n",
    "    score['country'] = score.index\n",
    "    score['code'] = [iso3166.countries.get(x.upper())[2] \n",
    "                     for x in score['country']]\n",
    "    \n",
    "    # get map data\n",
    "    shapefile = ('../geo-data/ne_110m_admin_0_countries/'\n",
    "        'ne_110m_admin_0_countries.shp')\n",
    "    gdf = gpd.read_file(shapefile)[['ADMIN', 'ADM0_A3', 'geometry']]\n",
    "    gdf.columns = ['country', 'country_code', 'geometry']\n",
    "    gdf = gdf[gdf['country'] != 'Antarctica'] \n",
    "    \n",
    "    merged = gdf.merge(score,\n",
    "                       left_on='country_code', \n",
    "                       right_on='code', how='left')\n",
    "\n",
    "    variable = 'Score'\n",
    "    cmap = mpl.cm.get_cmap('viridis').reversed()\n",
    "    cmap.set_bad('white')\n",
    "    cmap.set_under('white')\n",
    "    ax = merged.plot(column=variable, cmap=cmap, legend=False)\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    # remove ticks and labels from the map\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    # colorbar\n",
    "    world_map = ax.collections[0]\n",
    "    cb = plt.colorbar(world_map, ax=ax, orientation='horizontal')\n",
    "    \n",
    "    # legend title\n",
    "    fig = ax.figure\n",
    "    fig.text(0.5, 0.175, legend_title,\n",
    "        ha='center', va='bottom',\n",
    "        fontsize=12, # fontstyle='italic',\n",
    "        color='#222222')\n",
    "    \n",
    "    # footnote the plot\n",
    "    fig.text(0.99, 0.008, source,\n",
    "        ha='right', va='bottom',\n",
    "        fontsize=9, fontstyle='italic',\n",
    "        color='#999999')\n",
    "\n",
    "    # finalise\n",
    "    fig.set_size_inches(8, 5)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f'{CHART_DIRECTORY}'+\n",
    "                f'{I_PREFIX}MAP-{title}.png', \n",
    "                dpi=125)\n",
    "    #plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swarm(data: pd.Series,\n",
    "          title=\"Don't forget the title\",\n",
    "          ylabel=\"Don't forget the ylabel\",\n",
    "          source=\"Don't forget the source\",\n",
    "          color='cornflowerblue'):\n",
    "    \"\"\"Produce a swarm plot from the following input:\n",
    "        - data - a pandas Series of values, with an index of nations\n",
    "        - title - plot title\n",
    "        - ylabel - label for the y axis\n",
    "        - source - string for data source - becomes right footer\n",
    "        - color - colour of swarm plot dots\n",
    "       \"\"\"\n",
    "    \n",
    "    # get country information\n",
    "    wbd = pd.read_excel('../data/CLASS.xls', header=4, index_col=0, \n",
    "                        na=['x']).iloc[1:219].dropna(how='all', axis=1)\n",
    "    mapping = wbd['Income group']\n",
    "    mapping.index = wbd['Code']\n",
    "    \n",
    "    # prepare for plot\n",
    "    name_map(data, iso_name_map)\n",
    "    data = pd.DataFrame(data)\n",
    "    data.columns = ['Rate']\n",
    "    data['alpha3'] = [iso3166.countries.get(x).alpha3 for x in data.index]\n",
    "    data['alpha2'] = [iso3166.countries.get(x).alpha2 for x in data.index]\n",
    "    data['Income Group'] = data.alpha3.map(mapping)\n",
    "    data = data[data['Income Group'].notna()]\n",
    "    \n",
    "    # labels \n",
    "    data['alpha2'] = data['alpha2'].where(data['alpha2'].notna(), other='')\n",
    "    \n",
    "    # swarm plot\n",
    "    # - set up\n",
    "    categories = ['Low income', 'Lower middle income',\n",
    "                  'Upper middle income', 'High income']\n",
    "    # - plot\n",
    "    fig, ax = plt.subplots(figsize=(8,5))\n",
    "    sns.swarmplot(x='Income Group', y='Rate', data=data, \n",
    "                       size=10,\n",
    "                       dodge=True, \n",
    "                       color=color, alpha=0.5,\n",
    "                       order=categories,\n",
    "                       ax=ax)\n",
    "    \n",
    "    # - point annotation - this is one ugly hack\n",
    "    for collect, name in zip(ax.collections, categories):\n",
    "        \n",
    "        # retrieve positional data from plot\n",
    "        op = collect.get_offset_position()\n",
    "        collect.set_offset_position('data')\n",
    "        retrieved_xy_pairs = collect.get_offsets()\n",
    "        collect.set_offset_position(op)\n",
    "        \n",
    "        # build an xy map with duplicate keys\n",
    "        THRESH = 7\n",
    "        dup_map = {}\n",
    "        for x, y in retrieved_xy_pairs:\n",
    "            yy = np.round(y, THRESH)\n",
    "            if yy in dup_map:\n",
    "                dup_map[yy].append(x)\n",
    "            else:\n",
    "                dup_map[yy] = [x]\n",
    "        \n",
    "        # use this map to plot in the data labels\n",
    "        for index, row in data[data['Income Group'] == name].iterrows():\n",
    "            lookup = np.round(row['Rate'], THRESH)\n",
    "            if lookup in dup_map:\n",
    "                ax.text(dup_map[lookup].pop(), row['Rate'], row['alpha2'],\n",
    "                       ha='center', va='center', fontsize='xx-small', \n",
    "                        color='#333333')\n",
    "        \n",
    "    # - plot labelling \n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(None)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    \n",
    "    # footnote the plot\n",
    "    fig = ax.figure\n",
    "    fig.text(0.99, 0.008, source,\n",
    "        ha='right', va='bottom',\n",
    "        fontsize=9, fontstyle='italic',\n",
    "        color='#999999')\n",
    "\n",
    "    # finalise plot        \n",
    "    fig.tight_layout(pad=1.3)\n",
    "    fig.savefig(f'{CHART_DIRECTORY}{I_PREFIX}SWARM-{title}.png', dpi=125)\n",
    " \n",
    "    #plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cases\n",
      "Deaths\n"
     ]
    }
   ],
   "source": [
    "if True: # switch this output on/off\n",
    "\n",
    "    # set-up\n",
    "    PERIOD = 7 # days (recent data period for daily averages)\n",
    "    THRESH = 100_000 # people (minimum nation size for plotting)\n",
    "    BAR_N = 40 # maximum bars on chart\n",
    "    keepers = get_larger_nations(population, THRESH)\n",
    "    power, factor, pop_millions =  per_million_population(population)\n",
    "\n",
    "    # for cases then deaths ...\n",
    "    for mode, index in modes.items():\n",
    "        print(mode)\n",
    "    \n",
    "        # collect the data for plotting\n",
    "        raw_dataframe = adj_daily_data[index]\n",
    "        # - cumulative data\n",
    "        cumulative = raw_dataframe.sum()\n",
    "        cumulative_percapita = (cumulative / pop_millions)[keepers]\n",
    "        log_cumulative_percapita = np.log(cumulative_percapita + 1)\n",
    "        # - latest daily average data\n",
    "        rear_offsets = get_rear_offsets(raw_dataframe, PERIOD)\n",
    "        daily_ave = (get_recent_total(raw_dataframe, rear_offsets, \n",
    "                                      PERIOD) / PERIOD)\n",
    "        daily_ave_percapita = (daily_ave / pop_millions)[keepers]\n",
    "        log_daily_ave_percapita = np.log(daily_ave_percapita + 1)\n",
    "\n",
    "        # bar charts\n",
    "        # - bar chart of the top cumulative performers\n",
    "        top_tier = cumulative.sort_values(ascending=True)[-BAR_N:]\n",
    "        ps.plot_barh(\n",
    "            series = np.round(top_tier.copy(), 0).astype(int), \n",
    "            title=(f'COVID-19: Top cumulative {mode.lower()}'),\n",
    "            xlabel=(f'Cumulative {mode.lower()}'),\n",
    "            tight=1.2,\n",
    "            figsize=(8,8),\n",
    "            lfooter=f'For nations with a population >= {THRESH:,}',\n",
    "            rfooter=f'Source: {source}',\n",
    "            savefig=f'{CHART_DIRECTORY}{I_PREFIX}Top-{mode.title()} (cum).png'\n",
    "        )\n",
    "\n",
    "        # - bar chart of the top cumulative performers per capita\n",
    "        top_tier = cumulative_percapita.sort_values(ascending=True)[-BAR_N:]\n",
    "        ps.plot_barh(\n",
    "            series = np.round(top_tier.copy(), 1), \n",
    "            title=(f'COVID-19: Top cumulative {mode.lower()} per capita'),\n",
    "            xlabel=(f'Cumulative {mode.lower()} per '\n",
    "                    f'$10^{power}$ population'),\n",
    "            tight=1.2,\n",
    "            figsize=(8,8),\n",
    "            lfooter=f'For nations with a population >= {THRESH:,}',\n",
    "            rfooter=f'Source: {source}',\n",
    "            savefig=f'{CHART_DIRECTORY}{I_PREFIX}TOP-{mode.title()} per capita (cum).png'\n",
    "        )\n",
    "\n",
    "        # - bar chart of the top daily averages\n",
    "        top_tier = daily_ave.sort_values(ascending=True)[-BAR_N:]\n",
    "        ps.plot_barh(\n",
    "            series = np.round(top_tier.copy(), 1), \n",
    "            title=(f'COVID-19: Top {mode.lower()} - '\n",
    "                  f'past {PERIOD} days'),\n",
    "            xlabel=(f'Average daily {mode.lower()}'),\n",
    "            tight=1.2,\n",
    "            figsize=(8,8),\n",
    "            lfooter=f'For nations with a population >= {THRESH:,}',\n",
    "            rfooter=f'Source: {source}',\n",
    "            savefig=f'{CHART_DIRECTORY}{I_PREFIX}Top-{mode.title()} (recent).png'\n",
    "        ) \n",
    "        \n",
    "        # - bar chart of the top daily averages per capita\n",
    "        top_tier = daily_ave_percapita.sort_values(ascending=True)[-BAR_N:]\n",
    "        ps.plot_barh(\n",
    "            series = np.round(top_tier.copy(), 1), \n",
    "            title=(f'COVID-19: Top {mode.lower()} per capita - '\n",
    "                  f'past {PERIOD} days'),\n",
    "            xlabel=(f'Average daily {mode.lower()} per '\n",
    "                    f'$10^{power}$ population'),\n",
    "            tight=1.2,\n",
    "            figsize=(8,8),\n",
    "            lfooter=f'For nations with a population >= {THRESH:,}',\n",
    "            rfooter=f'Source: {source}',\n",
    "            savefig=f'{CHART_DIRECTORY}{I_PREFIX}Top-{mode.title()} per capita (recent).png'\n",
    "        )  \n",
    "\n",
    "        # world maps\n",
    "        # - world map - cumulative per capita\n",
    "        title = f'COVID-19 Cumulative {mode.lower()} per capita'\n",
    "        legend = (f'Cumulative {mode.lower()} per '\n",
    "                  f'$10^{power}$ population')\n",
    "        map_world(cumulative_percapita.copy(), title, legend,\n",
    "                  f'Source: {source}')\n",
    "\n",
    "        # - world map - cumulative per capita - log scale\n",
    "        title = (f'COVID-19 Cumulative {mode.lower()} per capita '\n",
    "                 f'(log scale)')\n",
    "        legend = (f'log((cumulative {mode.lower()} per '\n",
    "                  f'$10^{power}$ pop.) + 1)')\n",
    "        map_world(log_cumulative_percapita.copy(), title, legend,\n",
    "                  f'Source: {source}')\n",
    "        \n",
    "        # - world map - average daily per capita past PERIOD days\n",
    "        title = (f'COVID-19 Ave. daily {mode.lower()} per capita '\n",
    "             f'- past {PERIOD} days')\n",
    "        legend = (f'Ave. daily {mode.lower()} per '\n",
    "                  f'$10^{power}$ population')\n",
    "        map_world(daily_ave_percapita.copy(), title, legend, \n",
    "                  f'Source: {source}')\n",
    "\n",
    "        # - world map - average daily per capita past PERIOD days - log scale\n",
    "        title = (f'COVID-19 Ave. daily {mode.lower()} per capita '\n",
    "             f'- past {PERIOD} days (log scale)')\n",
    "        legend = (f'log((average daily {mode.lower()} per '\n",
    "              f'$10^{power}$-population) + 1)')\n",
    "        map_world(log_daily_ave_percapita.copy(), title, legend,\n",
    "                  f'Source: {source}')\n",
    "\n",
    "        # swarm plots\n",
    "        # - swarm plot of cumulative per capita\n",
    "        title = f'COVID-19 Cumulative {mode.lower()} per capita'\n",
    "        ylabel = (f'Cumulative {mode.lower()} per '\n",
    "                  f'$10^{power}$ population')\n",
    "        swarm(cumulative_percapita.copy(), title, \n",
    "              ylabel, f'Source: {source}', color='darkorchid')        \n",
    "\n",
    "        # - swarm plot of cumulative per capita - log scale\n",
    "        log_cumulative_percapita = np.log(cumulative_percapita + 1)\n",
    "        title = f'COVID-19 Cumulative {mode.lower()} per capita (log scale)'\n",
    "        ylabel = (f'log((cumulative {mode.lower()} per '\n",
    "                  f'$10^{power}$ pop.) + 1)')\n",
    "        swarm(log_cumulative_percapita.copy(), title, \n",
    "              ylabel, f'Source: {source}', color='hotpink')\n",
    "        \n",
    "        # - swarm plot of daily average per capita past PERIOD days\n",
    "        title = (f'COVID-19 Ave. daily {mode.lower()} per capita '\n",
    "             f'- past {PERIOD} days')\n",
    "        ylabel = (f'Ave. daily {mode.lower()} per '\n",
    "                 f'$10^{power}$ population')\n",
    "        swarm(daily_ave_percapita.copy(), title, \n",
    "              ylabel, f'Source: {source}')\n",
    "        \n",
    "        # - swarm plot of daily average per capita past PERIOD days - log scale\n",
    "        title = (f'COVID-19 Ave. daily {mode.lower()} per capita '\n",
    "             f'- past {PERIOD} days (log scale)')\n",
    "        ylabel = (f'log((ave. daily {mode.lower()} per '\n",
    "                 f'$10^{power}$ pop.) + 1)')\n",
    "        swarm(log_daily_ave_percapita.copy(), title, \n",
    "              ylabel, f'Source: {source}', color='darkorange')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-log comparison plots of cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_semi_log_trajectory(data, mode, threshold, selections, source):\n",
    "    \"\"\"Produce semi-log plots of cumulative data from the \n",
    "       following inputs:\n",
    "        - data - a pandas dataframe of cumulative data\n",
    "        - mode - a string, either 'Cases' or 'Deaths'\n",
    "        - threshold - starting point (eg. 100th case)\n",
    "        - selections - a python dictionary of \n",
    "         'grouping': ['list', 'of', 'nations'], pairs\n",
    "        - source - string for data source\n",
    "       \"\"\"\n",
    "    \n",
    "    styles = ['-'] #, '--', '-.', ':'] # 4 lines \n",
    "    markers = list('PXo^v<>D*pH.d') # 13 markers\n",
    "    colours = ['maroon', 'brown', 'olive', 'red', \n",
    "               'darkorange', 'darkgoldenrod', 'green',  \n",
    "               'blue', 'purple', 'black', 'teal'] # 11 colours\n",
    "\n",
    "    for tag, nation_list in selections.items():\n",
    "    \n",
    "        # set up for the plot\n",
    "        ax = plt.subplot(111,)\n",
    "        ax.set_title('COVID-19 Semilog plot of selected '\n",
    "                     f'{mode.lower()[:-1]} trajectories')\n",
    "        ax.set_xlabel('Days from the notional '\n",
    "                      f'{int(threshold)}th {mode.lower()[:-1]}')\n",
    "        ax.set_ylabel(f'Cumulative {mode} (log scale)')\n",
    "        ax.set_yscale('log')\n",
    "\n",
    "        # add the data\n",
    "        endpoints = pd.DataFrame()\n",
    "        nation_list.sort()\n",
    "        for i, name in enumerate(nation_list):\n",
    "            if name not in data.columns:\n",
    "                print(f'{name} is not in data')\n",
    "                continue\n",
    "            y = data[name]\n",
    "            y.index = range(len(y))\n",
    "            start = y[y >= threshold]\n",
    "            if len(start) < 5:\n",
    "                continue\n",
    "            start = start.index[0] - 1\n",
    "            if start < 0:\n",
    "                start = 0\n",
    "            y = y[start:].values\n",
    "            x = range(-1, len(y) - 1)\n",
    "            \n",
    "            # plot line\n",
    "            code = get_national_code(name)\n",
    "            label = f'{name} ({code}) {int(y[-1]):,}'\n",
    "            color = colours[i % len(colours)]\n",
    "            ax.plot(x, y, label=label,\n",
    "                    color=color,)\n",
    "            \n",
    "            # plot end text\n",
    "            endpoints = endpoints.append(\n",
    "                pd.Series([x[-1], y[-1], f'{code}', color],\n",
    "                          index=['x', 'y', 'code', 'color'],\n",
    "                          name=name))\n",
    "\n",
    "        # add endpoint labels \n",
    "        EXPANSION = 0.02\n",
    "        additional = endpoints.x.max() * EXPANSION\n",
    "        for row in endpoints.itertuples(): \n",
    "            ax.text(x=row.x+additional, y=row.y, s=row.code,\n",
    "                    size='small', color='black',\n",
    "                    ha='left', va='center',\n",
    "                    bbox={'alpha':0.5, 'facecolor':'white'})\n",
    "\n",
    "        # etc.\n",
    "        min_, max_ = ax.get_xlim()\n",
    "        max_ = max_ + (max_ * EXPANSION)\n",
    "        ax.set_xlim(min_, max_)\n",
    "        ax.legend(loc='lower right', fontsize='8', ncol=3)\n",
    "        fig = ax.figure\n",
    "\n",
    "        # footnote the plot\n",
    "        fig.text(0.99, 0.01, source,\n",
    "            ha='right', va='bottom',\n",
    "            fontsize=9, fontstyle='italic',\n",
    "            color='#999999')\n",
    "\n",
    "        # finalise \n",
    "        fig.set_size_inches(8, 6)\n",
    "        fig.tight_layout(pad=1.2)\n",
    "        fig.savefig(f'{CHART_DIRECTORY}/{I_PREFIX}semilog-{mode}-{tag}', dpi=125)\n",
    "        #plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cases\n",
      "Deaths\n"
     ]
    }
   ],
   "source": [
    "if True: # switch this output on/off\n",
    "\n",
    "    selections = {\n",
    "        'Anglophone':  ['Australia', 'United States', 'Canada', \n",
    "                        'United Kingdom', 'New Zealand', 'Ireland', ],\n",
    "        'Neighbours':  ['Australia', 'New Zealand', 'Papua New Guinea',\n",
    "                        'Indonesia', 'Singapore', 'Malaysia', #'Brunei',\n",
    "                        'Timor Leste', 'China', 'Japan', 'South Korea', 'India'],\n",
    "        \"Europe\":      ['Austria', 'Belgium', 'Denmark', \n",
    "                        'France', 'Germany', 'Greece', 'Italy', 'Netherlands', \n",
    "                        'Norway', 'Poland', 'Portugal', 'Russia', 'Spain',  \n",
    "                        'Sweden', 'Switzerland', 'United Kingdom', ],\n",
    "    }\n",
    "    \n",
    "    # for cases then deaths ...\n",
    "    for mode, index in modes.items():\n",
    "        print(mode)\n",
    "        cumulative = adj_cum_data[index]\n",
    "        \n",
    "        # include top N nations as a chart\n",
    "        N = 15\n",
    "        top = cumulative.iloc[-1].sort_values(ascending=False)[:N]\n",
    "        selections['Top'] = top.index.to_list()\n",
    "        \n",
    "        # and plot\n",
    "        thresh = 100 if mode.lower() == 'cases' else 10\n",
    "        plot_semi_log_trajectory(cumulative.copy(), mode, thresh, \n",
    "                                 selections, f'Source: {source}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison plots of daily new per capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_daily_comparative(data, mode, regions, source, period=14):\n",
    "    \"\"\"Produce daily plots highlighting new cases/deaths for a \n",
    "       specific set of nations against a backdrop of all nations.\n",
    "    Inputs:\n",
    "        - data - pandas DataFrame of daily new cases/deaths\n",
    "        - mode - string - either \"cases\" or \"deaths\"\n",
    "        - regions - python list of lists of strings \n",
    "          (nation names - same as columns in data)\n",
    "        - source - string for data source\n",
    "        - period - period for the rolling average \"\"\"\n",
    "    \n",
    "    # set-up\n",
    "    colours = ['maroon', 'brown', 'olivedrab', 'red', \n",
    "               'darkorange', 'darkgoldenrod', 'green',  \n",
    "               'blue', 'purple', 'black', 'teal'] # 11 colours\n",
    "    power, factor, pop_millions =  per_million_population(population)\n",
    "    keepers = get_larger_nations(population, 100_000) # used for backgrounds\n",
    "\n",
    "    # get rolling average per capita from start date\n",
    "    df = data.rolling(period).mean().div(other=pop_millions)\n",
    "    df = df[df.index >= pd.Timestamp('2020-02-01')]\n",
    "\n",
    "    for region_list in regions:\n",
    "    \n",
    "        # plot background\n",
    "        ax = df[keepers].plot(c='#aaaaaa', lw=0.5)\n",
    "        ax.get_legend().remove()\n",
    "        ax.set_title(f'COVID-19 Daily New {mode.title()}')\n",
    "        ax.set_ylabel(f'Daily new {mode.lower()} per $10^{power}$ populationb'\n",
    "                          f'\\n{period}-day rolling average')\n",
    "        ax.set_xlabel(None)\n",
    "\n",
    "        # plot highlighted regions\n",
    "        region_list.sort()\n",
    "        ax_new = ax.twinx()        \n",
    "        for i, name in enumerate(region_list):\n",
    "            df[name].plot(c=colours[i], label=name, lw=2.5, ax=ax_new)\n",
    "        ax_new.legend(title=None, loc=\"upper left\")\n",
    "        ax_new.grid(False)\n",
    "        ax_new.set_yticklabels([])\n",
    "        ax_new.set_ylim(ax.get_ylim())\n",
    "        fig = ax.figure\n",
    "\n",
    "        # footnote the plot\n",
    "        fig.text(0.99, 0.01, source,\n",
    "            ha='right', va='bottom',\n",
    "            fontsize=9, fontstyle='italic',\n",
    "            color='#999999')\n",
    "\n",
    "        # finalise plot        \n",
    "        fig.set_size_inches(8, 5)\n",
    "        fig.tight_layout(pad=1.2)\n",
    "        fig.savefig(f'{CHART_DIRECTORY}/{I_PREFIX}'\n",
    "                    f'daily-{mode}-{\" \".join(region_list)}', dpi=125)\n",
    "        #plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cases\n",
      "Deaths\n"
     ]
    }
   ],
   "source": [
    "if True: # switch this output on/off\n",
    "\n",
    "    # identify the regional sets to be plotted\n",
    "    regions = [\n",
    "        ['Belgium', 'Ireland', 'Netherlands', 'United Kingdom', 'Iceland'],\n",
    "        ['France', 'Italy', 'Portugal', 'Spain'],\n",
    "        ['Denmark', 'Norway', 'Sweden', 'Austria', 'Germany', 'Switzerland'], \n",
    "        ['Finland', 'Estonia', 'Latvia', 'Lithuania', 'Poland'],\n",
    "        ['Belarus', 'Russia', 'Ukraine', 'Romania', 'Bulgaria', 'Moldova', ],\n",
    "        ['Czechia', 'Slovakia', 'Hungary', 'Slovenia'],\n",
    "        ['Croatia', 'Bosnia And Herzegovina', 'Montenegro',\n",
    "            'Serbia', 'Kosovo', 'Albania', 'North Macedonia', 'Greece'],\n",
    "        ['Turkey', 'Syria', 'Lebanon', 'Israel', 'Jordan', \n",
    "             'Egypt', 'Libya', 'Cyprus'],\n",
    "        ['Georgia', 'Armenia', 'Azerbaijan'],\n",
    "        ['Iraq', 'Iran', 'Saudi Arabia', 'Bahrain', 'Qatar', \n",
    "            'United Arab Emirates', 'Kuwait', 'Yemen', 'Oman',], \n",
    "        ['Democratic Republic Of Congo', 'Ghana', 'Ethiopia', 'Kenya', \n",
    "             'Nigeria', 'South Africa', 'United Republic Of Tanzania'],\n",
    "        ['Afghanistan', 'Kazakhstan', 'Kyrgyzstan', 'Pakistan', \n",
    "            'Tajikistan', 'Uzbekistan', ],\n",
    "        ['Bangladesh', 'Nepal', 'India', 'Sri Lanka'], \n",
    "        ['Indonesia', 'Malaysia', 'Philippines', 'Singapore', 'Thailand'],\n",
    "        ['China', 'Japan', 'South Korea', 'Taiwan', 'Vietnam'],\n",
    "        ['Australia', 'New Zealand', 'Papua New Guinea', 'Timor Leste'], \n",
    "        ['Canada', 'Mexico', 'United States'], \n",
    "        ['Costa Rica', 'Guatemala', 'Honduras', 'Nicaragua', 'Panama'], \n",
    "        ['Argentina', 'Brazil', 'Chile', 'Colombia', 'Ecuador', \n",
    "            'Peru', 'Venezuela'], \n",
    "        ['Cuba', 'Dominican Republic', 'Haiti', 'Puerto Rico', 'Jamaica'],\n",
    "    ]\n",
    "\n",
    "    # for cases then deaths ...\n",
    "    for mode, index in modes.items():\n",
    "        print(mode)\n",
    "        daily = adj_daily_data[index]\n",
    "        plot_daily_comparative(daily.copy(), mode, regions, f'Source: {source}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "202px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
