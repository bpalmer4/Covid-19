{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID19 International V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Python-setup\" data-toc-modified-id=\"Python-setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Python setup</a></span></li><li><span><a href=\"#Get-the-raw-data-and-adjust-for-anomalies\" data-toc-modified-id=\"Get-the-raw-data-and-adjust-for-anomalies-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Get the raw data and adjust for anomalies</a></span><ul class=\"toc-item\"><li><span><a href=\"#Nation-naming-stuff\" data-toc-modified-id=\"Nation-naming-stuff-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Nation naming stuff</a></span></li><li><span><a href=\"#COVID-data-retrieval-and-adjustment-for-outliers\" data-toc-modified-id=\"COVID-data-retrieval-and-adjustment-for-outliers-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>COVID data retrieval and adjustment for outliers</a></span></li></ul></li><li><span><a href=\"#Plot-weekly-new-case/deaths-data-from-January-2020\" data-toc-modified-id=\"Plot-weekly-new-case/deaths-data-from-January-2020-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Plot weekly new-case/deaths data from January 2020</a></span></li><li><span><a href=\"#Plot-new-vs-cumulative-(all-and-last-3-months)\" data-toc-modified-id=\"Plot-new-vs-cumulative-(all-and-last-3-months)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Plot new-vs-cumulative (all and last 3 months)</a></span></li><li><span><a href=\"#International-comparisons---maps/leader-boards/swarms\" data-toc-modified-id=\"International-comparisons---maps/leader-boards/swarms-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>International comparisons - maps/leader-boards/swarms</a></span></li><li><span><a href=\"#Semi-log-comparison-plots-of-cumulative\" data-toc-modified-id=\"Semi-log-comparison-plots-of-cumulative-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Semi-log comparison plots of cumulative</a></span></li><li><span><a href=\"#Comparison-plots-of-daily-new-per-capita\" data-toc-modified-id=\"Comparison-plots-of-daily-new-per-capita-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Comparison plots of daily new per capita</a></span></li><li><span><a href=\"#Growth\" data-toc-modified-id=\"Growth-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Growth</a></span></li><li><span><a href=\"#The-End\" data-toc-modified-id=\"The-End-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>The End</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "#analytic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.units as munits\n",
    "import seaborn as sns\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import geopandas as gpd\n",
    "import iso3166\n",
    "\n",
    "# COVID19 specific imports\n",
    "sys.path.append(r'../bin')\n",
    "import datagrabber as dg\n",
    "import plotstuff as ps\n",
    "\n",
    "# directory\n",
    "CHART_DIRECTORY = '../charts'\n",
    "Path(CHART_DIRECTORY).mkdir(parents=True, exist_ok=True)\n",
    "CHART_DIRECTORY += '/'\n",
    "I_PREFIX = '!I-'\n",
    "\n",
    "# display settings\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "# plotting stuff\n",
    "plt.style.use('ggplot')\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the raw data and adjust for anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nation naming stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make country names ISO compliant\n",
    "iso_name_map = {\n",
    "    # from              # to\n",
    "    \"Bolivia\":          \"Bolivia, Plurinational State of\",\n",
    "    \"Bonaire, Saint Eustatius And Saba\": \"Bonaire, Sint Eustatius and Saba\",\n",
    "    \"British Virgin Islands\": \"Virgin Islands, British\",\n",
    "    \"Brunei\":           \"Brunei Darussalam\",\n",
    "    \"Cape Verde\":       \"Cabo Verde\",\n",
    "    \"Cote D'Ivoire\":    \"Côte d'Ivoire\",\n",
    "    \"Cote d'Ivoire\":    \"Côte d'Ivoire\",\n",
    "    \"Curaã§Ao\":         \"Curaçao\",\n",
    "    \"Democratic Republic Of Congo\": \"Congo, Democratic Republic of the\",\n",
    "    \"Democratic Republic of Congo\": \"Congo, Democratic Republic of the\",\n",
    "    \"Guinea Bissau\":    \"Guinea-Bissau\",\n",
    "    \"Vatican\":          \"Holy See\",\n",
    "    \"Iran\":             \"Iran, Islamic Republic of\",\n",
    "    \"Laos\":             \"Lao People's Democratic Republic\",\n",
    "    \"Moldova\":          \"Moldova, Republic of\",\n",
    "    \"Russia\":           \"Russian Federation\",\n",
    "    \"Sint Maarten\":     \"Sint Maarten (Dutch part)\",\n",
    "    \"South Korea\":      \"Korea, Republic of\",\n",
    "    \"Syria\":            \"Syrian Arab Republic\",\n",
    "    \"Tanzania\":         \"Tanzania, United Republic of\",\n",
    "    \"Timor\":            \"Timor-Leste\",\n",
    "    \"Timor Leste\":      \"Timor-Leste\",\n",
    "    \"United Kingdom\":   \"United Kingdom of Great Britain and Northern Ireland\",\n",
    "    \"United Republic Of Tanzania\": \"Tanzania, United Republic of\",\n",
    "    \"United States\":    \"United States of America\",\n",
    "    \"United States Virgin Islands\":   \"Virgin Islands, U.S.\",\n",
    "    \"Venezuela\":        \"Venezuela, Bolivarian Republic of\",\n",
    "    \"Vietnam\":          \"Viet Nam\",\n",
    "}\n",
    "\n",
    "must_name_map = {\n",
    "    # these names from the EU source are ugly and we will change anyway\n",
    "    \"Cote D'Ivoire\":    \"Côte d'Ivoire\",\n",
    "    \"Curaã§Ao\":         \"Curaçao\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_map(object_, map_):\n",
    "    \"\"\"Rename the index of a Series or the columns of a DataFrame\n",
    "       The renaming is done in place.\n",
    "       Parameters\n",
    "       - object_ - the pandas Series or DataFrame\n",
    "       - map_ - a dictionary of old to new mappings \n",
    "       Returns: None \"\"\"\n",
    "\n",
    "    fixing = {}\n",
    "    if isinstance(object_, pd.Series):\n",
    "        for name in map_:\n",
    "            if name in object_.index:\n",
    "                fixing[name] = map_[name]\n",
    "        object_.rename(index=fixing, inplace=True)\n",
    "    else:\n",
    "        for name in map_:\n",
    "            if name in object_.columns:\n",
    "                fixing[name] = map_[name]\n",
    "        object_.rename(columns=fixing, inplace=True)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_national_code(nation):\n",
    "    if nation in iso_name_map.keys():\n",
    "        nation = iso_name_map[nation]\n",
    "    if nation == 'European Union':\n",
    "        return 'EU'\n",
    "    code = iso3166.countries.get(nation).alpha2\n",
    "    return code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COVID data retrieval and adjustment for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/owid/covid-19-data/raw/master/public/data/owid-covid-data.csv\n",
      "We have the data\n"
     ]
    }
   ],
   "source": [
    "# retrieve raw\n",
    "raw_cases, raw_deaths, population, source = dg.get_OWID_data()\n",
    "\n",
    "# apply compulsory name changes\n",
    "name_map(population, must_name_map)\n",
    "name_map(raw_cases, must_name_map)\n",
    "name_map(raw_deaths, must_name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OWID 2020-12-23'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identify the source\n",
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing data in the last row\n",
    "for mode, data in zip(['cases', 'death'],\n",
    "                      [raw_cases, raw_deaths]):\n",
    "    missing = data.iloc[-1]\n",
    "    missing = missing[missing.isna()]\n",
    "    if len(missing):\n",
    "        print(f'Missing {mode}')\n",
    "        display(data[missing.index].iloc[-7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spikes in Andorra\n",
      "date   2020-06-02\n",
      "spike   79.000000\n",
      "mean     0.714286\n",
      "zeros   10.000000\n",
      "Negatives in Antigua and Barbuda\n",
      "date\n",
      "2020-07-03   -1.0\n",
      "Name: Antigua and Barbuda, dtype: float64\n",
      "Data too sparse in Antigua and Barbuda (max_consecutive=2)\n",
      "Data too sparse in Barbados (max_consecutive=10)\n",
      "Spikes in Belize\n",
      "date    2020-12-03\n",
      "spike  1382.000000\n",
      "mean    142.857143\n",
      "zeros     2.000000\n",
      "Negatives in Benin\n",
      "date\n",
      "2020-05-19   -209.0\n",
      "Name: Benin, dtype: float64\n",
      "Data too sparse in Benin (max_consecutive=10)\n",
      "Data too sparse in Bhutan (max_consecutive=9)\n",
      "Data too sparse in Botswana (max_consecutive=2)\n",
      "Spikes in Burkina Faso\n",
      "date   2020-05-06  2020-06-02  2020-09-13\n",
      "spike   41.000000   34.000000       193.0\n",
      "mean     6.714286    1.785714        17.5\n",
      "zeros    0.000000    6.000000         0.0\n",
      "Data too sparse in Burundi (max_consecutive=10)\n",
      "Data too sparse in Cambodia (max_consecutive=14)\n",
      "Data too sparse in Cameroon (max_consecutive=7)\n",
      "Spikes in Cape Verde\n",
      "date   2020-04-15\n",
      "spike        45.0\n",
      "mean          1.5\n",
      "zeros         6.0\n",
      "Data too sparse in Central African Republic (max_consecutive=14)\n",
      "Negatives in China\n",
      "date\n",
      "2020-06-03   -1.0\n",
      "Name: China, dtype: float64\n",
      "Spikes in China\n",
      "date   2020-02-13  2020-04-17\n",
      "spike     15136.0  357.000000\n",
      "mean       2321.5   47.071429\n",
      "zeros         0.0    0.000000\n",
      "Data too sparse in Comoros (max_consecutive=2)\n",
      "Data too sparse in Congo (max_consecutive=3)\n",
      "Negatives in Cote d'Ivoire\n",
      "date\n",
      "2020-12-16   -34.0\n",
      "Name: Cote d'Ivoire, dtype: float64\n",
      "Negatives in Cyprus\n",
      "date\n",
      "2020-08-27   -17.0\n",
      "Name: Cyprus, dtype: float64\n",
      "Data too sparse in Dominica (max_consecutive=2)\n",
      "Negatives in Ecuador\n",
      "date\n",
      "2020-05-07   -1583.0\n",
      "2020-05-08   -1480.0\n",
      "2020-05-11     -50.0\n",
      "2020-09-07   -7953.0\n",
      "Name: Ecuador, dtype: float64\n",
      "Spikes in Ecuador\n",
      "date    2020-04-10   2020-04-24\n",
      "spike  1727.637828  9075.605639\n",
      "mean    173.696608   369.477580\n",
      "zeros     1.000000     2.000000\n",
      "Data too sparse in Equatorial Guinea (max_consecutive=5)\n",
      "Data too sparse in Eritrea (max_consecutive=6)\n",
      "Data too sparse in Fiji (max_consecutive=4)\n",
      "Negatives in Finland\n",
      "date\n",
      "2020-07-15   -5.0\n",
      "2020-07-16   -3.0\n",
      "Name: Finland, dtype: float64\n",
      "Negatives in France\n",
      "date\n",
      "2020-04-04   -17074.0\n",
      "2020-04-07    -3491.0\n",
      "2020-04-23    -1710.0\n",
      "2020-04-29    -1455.0\n",
      "2020-05-24     -439.0\n",
      "2020-06-02     -647.0\n",
      "2020-06-03    -3226.0\n",
      "2020-06-28     -406.0\n",
      "2020-11-04   -46076.0\n",
      "Name: France, dtype: float64\n",
      "Spikes in France\n",
      "date     2020-04-12   2020-05-06   2020-06-04\n",
      "spike  43806.856125  3740.300520  4090.739838\n",
      "mean    3870.077783   632.317632   763.252686\n",
      "zeros      0.000000     0.000000     0.000000\n",
      "Data too sparse in Gabon (max_consecutive=7)\n",
      "Negatives in Gambia\n",
      "date\n",
      "2020-08-24   -100.0\n",
      "Name: Gambia, dtype: float64\n",
      "Data too sparse in Gambia (max_consecutive=8)\n",
      "Spikes in Greece\n",
      "date   2020-04-21\n",
      "spike  156.000000\n",
      "mean    18.928571\n",
      "zeros    1.000000\n",
      "Data too sparse in Grenada (max_consecutive=2)\n",
      "Data too sparse in Guinea-Bissau (max_consecutive=9)\n",
      "Negatives in Guyana\n",
      "date\n",
      "2020-03-24   -15.0\n",
      "Name: Guyana, dtype: float64\n",
      "Negatives in Honduras\n",
      "date\n",
      "2020-05-12   -20.0\n",
      "Name: Honduras, dtype: float64\n",
      "Data too sparse in International (max_consecutive=7)\n",
      "Negatives in Israel\n",
      "date\n",
      "2020-03-11   -28.0\n",
      "Name: Israel, dtype: float64\n",
      "Negatives in Italy\n",
      "date\n",
      "2020-06-19   -148.0\n",
      "Name: Italy, dtype: float64\n",
      "Negatives in Jordan\n",
      "date\n",
      "2020-07-21   -110.0\n",
      "Name: Jordan, dtype: float64\n",
      "Spikes in Kazakhstan\n",
      "date     2020-07-01\n",
      "spike  18757.000000\n",
      "mean     966.928571\n",
      "zeros      2.000000\n",
      "Spikes in Kyrgyzstan\n",
      "date     2020-07-18\n",
      "spike  11505.000000\n",
      "mean     764.928571\n",
      "zeros      3.000000\n",
      "Data too sparse in Laos (max_consecutive=5)\n",
      "Data too sparse in Lesotho (max_consecutive=6)\n",
      "Spikes in Liberia\n",
      "date   2020-12-03  2020-12-16\n",
      "spike   68.000000   97.000000\n",
      "mean     2.142857    0.428571\n",
      "zeros   11.000000   13.000000\n",
      "Negatives in Lithuania\n",
      "date\n",
      "2020-04-28   -105.0\n",
      "Name: Lithuania, dtype: float64\n",
      "Negatives in Luxembourg\n",
      "date\n",
      "2020-08-28   -1348.0\n",
      "Name: Luxembourg, dtype: float64\n",
      "Negatives in Madagascar\n",
      "date\n",
      "2020-05-11   -7.0\n",
      "Name: Madagascar, dtype: float64\n",
      "Spikes in Malaysia\n",
      "date   2020-06-04\n",
      "spike  277.000000\n",
      "mean    33.785714\n",
      "zeros    0.000000\n",
      "Spikes in Maldives\n",
      "date   2020-04-30\n",
      "spike  190.000000\n",
      "mean    26.571429\n",
      "zeros    0.000000\n",
      "Negatives in Malta\n",
      "date\n",
      "2020-08-16   -42.0\n",
      "Name: Malta, dtype: float64\n",
      "Spikes in Malta\n",
      "date   2020-07-30\n",
      "spike   88.178954\n",
      "mean    11.591914\n",
      "zeros    1.000000\n",
      "Negatives in Marshall Islands\n",
      "date\n",
      "2020-11-05   -1.0\n",
      "Name: Marshall Islands, dtype: float64\n",
      "Data too sparse in Marshall Islands (max_consecutive=1)\n",
      "Negatives in Mauritius\n",
      "date\n",
      "2020-04-29   -2.0\n",
      "Name: Mauritius, dtype: float64\n",
      "Spikes in Mexico\n",
      "date     2020-10-05\n",
      "spike  28115.000000\n",
      "mean    4472.357143\n",
      "zeros      0.000000\n",
      "Negatives in Monaco\n",
      "date\n",
      "2020-09-02   -12.0\n",
      "Name: Monaco, dtype: float64\n",
      "Spikes in Mongolia\n",
      "date   2020-12-06  2020-12-22\n",
      "spike   38.000000        57.0\n",
      "mean     6.428571         8.5\n",
      "zeros    0.000000         0.0\n",
      "Negatives in Nepal\n",
      "date\n",
      "2020-05-14   -1.0\n",
      "Name: Nepal, dtype: float64\n",
      "Negatives in New Zealand\n",
      "date\n",
      "2020-04-26   -1.0\n",
      "2020-05-04   -1.0\n",
      "Name: New Zealand, dtype: float64\n",
      "Data too sparse in Nicaragua (max_consecutive=2)\n",
      "Negatives in Niger\n",
      "date\n",
      "2020-07-27   -4.0\n",
      "Name: Niger, dtype: float64\n",
      "Negatives in Papua New Guinea\n",
      "date\n",
      "2020-08-13   -16.0\n",
      "Name: Papua New Guinea, dtype: float64\n",
      "Data too sparse in Papua New Guinea (max_consecutive=8)\n",
      "Spikes in Paraguay\n",
      "date   2020-05-09  2020-05-19\n",
      "spike  126.000000        41.0\n",
      "mean    22.785714         8.0\n",
      "zeros    0.000000         0.0\n",
      "Negatives in Portugal\n",
      "date\n",
      "2020-05-02   -161.0\n",
      "Name: Portugal, dtype: float64\n",
      "Spikes in Qatar\n",
      "date   2020-03-11\n",
      "spike  238.000000\n",
      "mean    14.785714\n",
      "zeros    5.000000\n",
      "Data too sparse in Saint Kitts and Nevis (max_consecutive=2)\n",
      "Data too sparse in Saint Lucia (max_consecutive=10)\n",
      "Data too sparse in Saint Vincent and the Grenadines (max_consecutive=3)\n",
      "Data too sparse in Samoa (max_consecutive=1)\n",
      "Negatives in San Marino\n",
      "date\n",
      "2020-05-10    -9.0\n",
      "2020-09-05   -19.0\n",
      "Name: San Marino, dtype: float64\n",
      "Data too sparse in San Marino (max_consecutive=11)\n",
      "Data too sparse in Sao Tome and Principe (max_consecutive=12)\n",
      "Spikes in Senegal\n",
      "date   2020-09-15\n",
      "spike  223.000000\n",
      "mean    37.285714\n",
      "zeros    0.000000\n",
      "Data too sparse in Seychelles (max_consecutive=4)\n",
      "Data too sparse in Solomon Islands (max_consecutive=1)\n",
      "Data too sparse in Somalia (max_consecutive=6)\n",
      "Data too sparse in South Sudan (max_consecutive=9)\n",
      "Negatives in Spain\n",
      "date\n",
      "2020-04-24   -10034.0\n",
      "2020-05-25     -372.0\n",
      "Name: Spain, dtype: float64\n",
      "Spikes in Sri Lanka\n",
      "date   2020-07-10  2020-10-06\n",
      "spike  300.000000  739.000000\n",
      "mean    23.642857   66.857143\n",
      "zeros    0.000000    0.000000\n",
      "Data too sparse in Sudan (max_consecutive=13)\n",
      "Negatives in Taiwan\n",
      "date\n",
      "2020-08-03   -1.0\n",
      "2020-08-09   -2.0\n",
      "Name: Taiwan, dtype: float64\n",
      "Data too sparse in Tanzania (max_consecutive=5)\n",
      "Spikes in Thailand\n",
      "date   2020-09-28  2020-12-21\n",
      "spike   36.000000  809.000000\n",
      "mean     4.142857   57.285714\n",
      "zeros    1.000000    2.000000\n",
      "Data too sparse in Timor (max_consecutive=4)\n",
      "Spikes in Trinidad and Tobago\n",
      "date   2020-03-21\n",
      "spike   40.000000\n",
      "mean     2.428571\n",
      "zeros    2.000000\n",
      "Spikes in Turkey\n",
      "date      2020-12-10\n",
      "spike  823225.000000\n",
      "mean    30826.785714\n",
      "zeros       0.000000\n",
      "Negatives in Uganda\n",
      "date\n",
      "2020-04-18     -1.0\n",
      "2020-05-21   -104.0\n",
      "Name: Uganda, dtype: float64\n",
      "Negatives in Uruguay\n",
      "date\n",
      "2020-04-12   -21.0\n",
      "Name: Uruguay, dtype: float64\n",
      "Data too sparse in Vanuatu (max_consecutive=1)\n",
      "Data too sparse in Vatican (max_consecutive=1)\n",
      "Spikes in World\n",
      "date     2020-02-13\n",
      "spike  15153.000000\n",
      "mean    2386.857143\n",
      "zeros      0.000000\n",
      "Negatives in Yemen\n",
      "date\n",
      "2020-08-11     -1.0\n",
      "2020-12-08   -305.0\n",
      "Name: Yemen, dtype: float64\n",
      "Spikes in Zambia\n",
      "date   2020-07-07\n",
      "spike  263.000000\n",
      "mean     4.571429\n",
      "zeros   12.000000\n",
      "Negatives in Zimbabwe\n",
      "date\n",
      "2020-05-02   -6.0\n",
      "Name: Zimbabwe, dtype: float64\n",
      "Spikes in Zimbabwe\n",
      "date   2020-09-07\n",
      "spike       461.0\n",
      "mean         47.0\n",
      "zeros         2.0\n",
      "Data too sparse in Andorra (max_consecutive=13)\n",
      "Negatives in Angola\n",
      "date\n",
      "2020-10-08   -3.0\n",
      "Name: Angola, dtype: float64\n",
      "Data too sparse in Antigua and Barbuda (max_consecutive=2)\n",
      "Spikes in Argentina\n",
      "date    2020-10-01\n",
      "spike  3351.000000\n",
      "mean    355.928571\n",
      "zeros     0.000000\n",
      "Negatives in Australia\n",
      "date\n",
      "2020-06-01   -1.0\n",
      "Name: Australia, dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negatives in Austria\n",
      "date\n",
      "2020-07-21   -1.0\n",
      "2020-10-11   -1.0\n",
      "Name: Austria, dtype: float64\n",
      "Data too sparse in Bahamas (max_consecutive=9)\n",
      "Data too sparse in Barbados (max_consecutive=3)\n",
      "Negatives in Belgium\n",
      "date\n",
      "2020-08-26   -117.0\n",
      "Name: Belgium, dtype: float64\n",
      "Data too sparse in Benin (max_consecutive=3)\n",
      "Spikes in Bolivia\n",
      "date    2020-09-07\n",
      "spike  1656.000000\n",
      "mean     55.142857\n",
      "zeros     1.000000\n",
      "Data too sparse in Botswana (max_consecutive=1)\n",
      "Data too sparse in Brunei (max_consecutive=1)\n",
      "Data too sparse in Burkina Faso (max_consecutive=5)\n",
      "Data too sparse in Burundi (max_consecutive=1)\n",
      "Data too sparse in Cameroon (max_consecutive=5)\n",
      "Spikes in Canada\n",
      "date   2020-10-02\n",
      "spike   98.000000\n",
      "mean    17.357143\n",
      "zeros    0.000000\n",
      "Data too sparse in Cape Verde (max_consecutive=5)\n",
      "Data too sparse in Central African Republic (max_consecutive=5)\n",
      "Data too sparse in Chad (max_consecutive=6)\n",
      "Spikes in Chile\n",
      "date   2020-06-08   2020-07-17\n",
      "spike  627.000000  1057.000000\n",
      "mean   120.071429    83.928571\n",
      "zeros    0.000000     0.000000\n",
      "Spikes in China\n",
      "date   2020-04-17\n",
      "spike      1290.0\n",
      "mean          0.5\n",
      "zeros        10.0\n",
      "Data too sparse in Comoros (max_consecutive=1)\n",
      "Negatives in Congo\n",
      "date\n",
      "2020-09-10   -31.0\n",
      "Name: Congo, dtype: float64\n",
      "Data too sparse in Congo (max_consecutive=2)\n",
      "Data too sparse in Cote d'Ivoire (max_consecutive=10)\n",
      "Negatives in Cuba\n",
      "date\n",
      "2020-08-14   -1.0\n",
      "Name: Cuba, dtype: float64\n",
      "Data too sparse in Cuba (max_consecutive=14)\n",
      "Negatives in Cyprus\n",
      "date\n",
      "2020-04-05   -2.0\n",
      "2020-11-08   -7.0\n",
      "Name: Cyprus, dtype: float64\n",
      "Data too sparse in Cyprus (max_consecutive=5)\n",
      "Negatives in Czechia\n",
      "date\n",
      "2020-05-18   -1.0\n",
      "2020-06-11   -2.0\n",
      "2020-06-13   -1.0\n",
      "2020-06-28   -1.0\n",
      "2020-07-04   -2.0\n",
      "2020-07-05   -3.0\n",
      "2020-08-04   -3.0\n",
      "2020-08-07   -1.0\n",
      "Name: Czechia, dtype: float64\n",
      "Data too sparse in Democratic Republic of Congo (max_consecutive=13)\n",
      "Negatives in Denmark\n",
      "date\n",
      "2020-05-12   -6.0\n",
      "Name: Denmark, dtype: float64\n",
      "Data too sparse in Djibouti (max_consecutive=4)\n",
      "Spikes in Ecuador\n",
      "date    2020-09-07  2020-10-08\n",
      "spike  3852.000000       398.0\n",
      "mean     36.785714        39.5\n",
      "zeros     1.000000         0.0\n",
      "Data too sparse in Equatorial Guinea (max_consecutive=2)\n",
      "Data too sparse in Eritrea (max_consecutive=1)\n",
      "Negatives in Estonia\n",
      "date\n",
      "2020-08-02   -6.0\n",
      "Name: Estonia, dtype: float64\n",
      "Data too sparse in Eswatini (max_consecutive=8)\n",
      "Data too sparse in Fiji (max_consecutive=1)\n",
      "Negatives in Finland\n",
      "date\n",
      "2020-04-06   -1.0\n",
      "2020-06-01   -2.0\n",
      "2020-07-15   -1.0\n",
      "2020-09-30   -1.0\n",
      "2020-10-23   -2.0\n",
      "Name: Finland, dtype: float64\n",
      "Spikes in Finland\n",
      "date   2020-04-21\n",
      "spike   43.000000\n",
      "mean     6.928571\n",
      "zeros    0.000000\n",
      "Negatives in France\n",
      "date\n",
      "2020-05-19   -217.0\n",
      "2020-05-24    -80.0\n",
      "2020-07-05     -1.0\n",
      "2020-07-21    -13.0\n",
      "2020-09-04    -21.0\n",
      "2020-10-25    -21.0\n",
      "2020-11-04    -31.0\n",
      "2020-12-12     -1.0\n",
      "Name: France, dtype: float64\n",
      "Data too sparse in Gabon (max_consecutive=5)\n",
      "Data too sparse in Gambia (max_consecutive=6)\n",
      "Negatives in Germany\n",
      "date\n",
      "2020-04-11   -31.0\n",
      "2020-07-06    -1.0\n",
      "Name: Germany, dtype: float64\n",
      "Data too sparse in Ghana (max_consecutive=4)\n",
      "Data too sparse in Guinea (max_consecutive=3)\n",
      "Data too sparse in Guinea-Bissau (max_consecutive=1)\n",
      "Data too sparse in Guyana (max_consecutive=10)\n",
      "Data too sparse in Haiti (max_consecutive=6)\n",
      "Data too sparse in Iceland (max_consecutive=3)\n",
      "Negatives in India\n",
      "date\n",
      "2020-03-21   -1.0\n",
      "Name: India, dtype: float64\n",
      "Spikes in India\n",
      "date    2020-06-16\n",
      "spike  2003.000000\n",
      "mean    357.142857\n",
      "zeros     0.000000\n",
      "Data too sparse in International (max_consecutive=1)\n",
      "Negatives in Ireland\n",
      "date\n",
      "2020-05-25   -2.0\n",
      "2020-06-01   -2.0\n",
      "2020-07-08   -4.0\n",
      "2020-07-30   -1.0\n",
      "2020-10-02   -5.0\n",
      "2020-12-08   -2.0\n",
      "Name: Ireland, dtype: float64\n",
      "Spikes in Ireland\n",
      "date   2020-04-24\n",
      "spike  220.000000\n",
      "mean    39.928571\n",
      "zeros    0.000000\n",
      "Negatives in Italy\n",
      "date\n",
      "2020-06-24   -31.0\n",
      "Name: Italy, dtype: float64\n",
      "Spikes in Italy\n",
      "date   2020-08-15\n",
      "spike  158.000000\n",
      "mean     5.857143\n",
      "zeros    0.000000\n",
      "Negatives in Japan\n",
      "date\n",
      "2020-06-06   -1.0\n",
      "Name: Japan, dtype: float64\n",
      "Negatives in Kazakhstan\n",
      "date\n",
      "2020-04-04   -1.0\n",
      "Name: Kazakhstan, dtype: float64\n",
      "Spikes in Kazakhstan\n",
      "date   2020-07-20  2020-09-16  2020-11-03  2020-11-25\n",
      "spike       210.0   38.000000   34.000000   49.000000\n",
      "mean          0.0    7.357143    3.071429    4.785714\n",
      "zeros        14.0    0.000000    3.000000    2.000000\n",
      "Negatives in Kyrgyzstan\n",
      "date\n",
      "2020-08-21   -443.0\n",
      "Name: Kyrgyzstan, dtype: float64\n",
      "Spikes in Kyrgyzstan\n",
      "date   2020-07-18\n",
      "spike  511.688825\n",
      "mean    19.958780\n",
      "zeros    3.000000\n",
      "Data too sparse in Lesotho (max_consecutive=3)\n",
      "Data too sparse in Liberia (max_consecutive=3)\n",
      "Negatives in Libya\n",
      "date\n",
      "2020-07-30   -3.0\n",
      "Name: Libya, dtype: float64\n",
      "Data too sparse in Liechtenstein (max_consecutive=3)\n",
      "Negatives in Luxembourg\n",
      "date\n",
      "2020-04-14   -2.0\n",
      "Name: Luxembourg, dtype: float64\n",
      "Data too sparse in Luxembourg (max_consecutive=9)\n",
      "Data too sparse in Malawi (max_consecutive=10)\n",
      "Data too sparse in Maldives (max_consecutive=4)\n",
      "Negatives in Malta\n",
      "date\n",
      "2020-11-03   -2.0\n",
      "Name: Malta, dtype: float64\n",
      "Data too sparse in Malta (max_consecutive=12)\n",
      "Data too sparse in Mauritius (max_consecutive=3)\n",
      "Spikes in Mexico\n",
      "date    2020-10-05\n",
      "spike  2789.000000\n",
      "mean    337.571429\n",
      "zeros     0.000000\n",
      "Negatives in Monaco\n",
      "date\n",
      "2020-09-02   -3.0\n",
      "Name: Monaco, dtype: float64\n",
      "Data too sparse in Monaco (max_consecutive=1)\n",
      "Data too sparse in Mozambique (max_consecutive=11)\n",
      "Negatives in Netherlands\n",
      "date\n",
      "2020-07-10    -1.0\n",
      "2020-07-14    -2.0\n",
      "2020-07-18    -2.0\n",
      "2020-07-27   -18.0\n",
      "2020-08-11   -16.0\n",
      "Name: Netherlands, dtype: float64\n",
      "Data too sparse in New Zealand (max_consecutive=4)\n",
      "Data too sparse in Nicaragua (max_consecutive=1)\n",
      "Data too sparse in Niger (max_consecutive=5)\n",
      "Negatives in Nigeria\n",
      "date\n",
      "2020-11-08   -1.0\n",
      "Name: Nigeria, dtype: float64\n",
      "Spikes in Pakistan\n",
      "date   2020-11-19\n",
      "spike  313.000000\n",
      "mean    37.785714\n",
      "zeros    0.000000\n",
      "Data too sparse in Papua New Guinea (max_consecutive=2)\n",
      "Spikes in Peru\n",
      "date    2020-07-23   2020-08-14\n",
      "spike  3887.000000  4143.000000\n",
      "mean    179.428571   176.214286\n",
      "zeros     3.000000     3.000000\n",
      "Negatives in Philippines\n",
      "date\n",
      "2020-03-19   -2.0\n",
      "Name: Philippines, dtype: float64\n",
      "Data too sparse in Qatar (max_consecutive=12)\n",
      "Data too sparse in Rwanda (max_consecutive=4)\n",
      "Data too sparse in Saint Lucia (max_consecutive=2)\n",
      "Data too sparse in San Marino (max_consecutive=2)\n",
      "Data too sparse in Sao Tome and Principe (max_consecutive=2)\n",
      "Negatives in Serbia\n",
      "date\n",
      "2020-03-26   -3.0\n",
      "Name: Serbia, dtype: float64\n",
      "Data too sparse in Sierra Leone (max_consecutive=8)\n",
      "Data too sparse in Singapore (max_consecutive=4)\n",
      "Negatives in Somalia\n",
      "date\n",
      "2020-09-04   -1.0\n",
      "Name: Somalia, dtype: float64\n",
      "Data too sparse in Somalia (max_consecutive=6)\n",
      "Data too sparse in South Sudan (max_consecutive=4)\n",
      "Negatives in Spain\n",
      "date\n",
      "2020-05-25   -1918.0\n",
      "2020-08-12      -2.0\n",
      "Name: Spain, dtype: float64\n",
      "Spikes in Spain\n",
      "date    2020-06-19\n",
      "spike  1179.000000\n",
      "mean      1.642857\n",
      "zeros     7.000000\n",
      "Data too sparse in Sudan (max_consecutive=10)\n",
      "Data too sparse in Suriname (max_consecutive=8)\n",
      "Negatives in Sweden\n",
      "date\n",
      "2020-08-31   -13.0\n",
      "2020-10-06   -12.0\n",
      "Name: Sweden, dtype: float64\n",
      "Negatives in Switzerland\n",
      "date\n",
      "2020-10-21   -106.0\n",
      "Name: Switzerland, dtype: float64\n",
      "Data too sparse in Taiwan (max_consecutive=1)\n",
      "Negatives in Tajikistan\n",
      "date\n",
      "2020-12-13   -1.0\n",
      "Name: Tajikistan, dtype: float64\n",
      "Data too sparse in Tajikistan (max_consecutive=6)\n",
      "Data too sparse in Tanzania (max_consecutive=2)\n",
      "Data too sparse in Togo (max_consecutive=4)\n",
      "Data too sparse in Trinidad and Tobago (max_consecutive=10)\n",
      "Data too sparse in Tunisia (max_consecutive=12)\n",
      "Data too sparse in Uganda (max_consecutive=9)\n",
      "Data too sparse in Uruguay (max_consecutive=9)\n",
      "Negatives in Venezuela\n",
      "date\n",
      "2020-05-01   -6.0\n",
      "Name: Venezuela, dtype: float64\n",
      "Negatives in Vietnam\n",
      "date\n",
      "2020-08-19   -1.0\n",
      "Name: Vietnam, dtype: float64\n",
      "Data too sparse in Vietnam (max_consecutive=7)\n",
      "Negatives in Yemen\n",
      "date\n",
      "2020-12-08   -43.0\n",
      "Name: Yemen, dtype: float64\n",
      "Spikes in Yemen\n",
      "date   2020-07-12\n",
      "spike   48.394910\n",
      "mean     3.722685\n",
      "zeros    0.000000\n",
      "Spikes in Zambia\n",
      "date   2020-07-17\n",
      "spike   67.000000\n",
      "mean     1.928571\n",
      "zeros   10.000000\n",
      "Data too sparse in Zimbabwe (max_consecutive=10)\n"
     ]
    }
   ],
   "source": [
    "# make adjustments to the data\n",
    "CASES = 0\n",
    "DEATHS = 1\n",
    "modes = {\n",
    "    'Cases': CASES,\n",
    "    'Deaths': DEATHS,\n",
    "}\n",
    "raw_cum_data = [raw_cases, raw_deaths]\n",
    "raw_daily_data = [None, None]\n",
    "adj_daily_data = [None, None]\n",
    "adj_cum_data = [None, None]\n",
    "\n",
    "data_quality = [None, None]\n",
    "\n",
    "for mode, index in modes.items():\n",
    "    \n",
    "    name_map(raw_cum_data[index], must_name_map)\n",
    "    \n",
    "    # make missing data zero\n",
    "    raw_cum_data[index] = raw_cum_data[index].fillna(0)\n",
    "    \n",
    "    # adjust data for anomalies\n",
    "    (raw_daily_data[index], \n",
    "        adj_daily_data[index], \n",
    "        adj_cum_data[index]) = ps.dataframe_correction(\n",
    "                                    raw_cum_data[index])\n",
    "    \n",
    "    # identify whether the adjustment for anomalies \n",
    "    # changed the data\n",
    "    data_quality[index] = pd.Series(None, \n",
    "                            index=raw_cum_data[index].columns,\n",
    "                            dtype='str')\n",
    "    for col in raw_cum_data[index].columns:\n",
    "        if (raw_daily_data[index][col] == \n",
    "            adj_daily_data[index][col]).all():\n",
    "            data_quality[index][col] = (f'Source: {source}, '\n",
    "                                         'original data')\n",
    "        else:\n",
    "            data_quality[index][col] = (f'Source: {source}, '\n",
    "                            'data adjusted for extreme outliers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot weekly new-case/deaths data from January 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weekly(daily, mode, data_quality, dfrom=\"2020-01-21\"):\n",
    "    \"\"\"Plot weekly bar charts for daily new cases and deaths\n",
    "        Function paramters:\n",
    "        - daily is a DataFrame of daily timeseries data\n",
    "        - mode is one of 'cases' or 'deaths' \n",
    "        - data_quality is a Series of strings,\n",
    "            used for the left footnote on charts\n",
    "        - dfrom is a date string to display from\n",
    "        Returns: weekly data in a DataFrame \"\"\"\n",
    "    \n",
    "    DISPLAY_FROM = pd.Timestamp(dfrom)\n",
    "    \n",
    "    # find the day that the week ends - last day of dataframe\n",
    "    LAST_DAY = daily.index[-1]\n",
    "    RULE = {\n",
    "        0: 'W-MON',\n",
    "        1: 'W-TUE',\n",
    "        2: 'W-WED',\n",
    "        3: 'W-THU',\n",
    "        4: 'W-FRI',\n",
    "        5: 'W-SAT',\n",
    "        6: 'W-SUN',\n",
    "    }[LAST_DAY.dayofweek]\n",
    "\n",
    "    # convert the data to weekly\n",
    "    returnable = weekly = daily.resample(rule=RULE, \n",
    "                                         closed='right').sum()\n",
    "    total = weekly.sum()\n",
    "    \n",
    "    # adjust data and dates for plotting\n",
    "    # we move the data by half a week becuase \n",
    "    # we want the bars to be centred\n",
    "    weekly = weekly[weekly.index > DISPLAY_FROM]\n",
    "    weekly.index = weekly.index - pd.Timedelta(3.5, unit='d')\n",
    "    \n",
    "    for name in daily.columns:\n",
    "    \n",
    "        # avoid plotting an empty plot\n",
    "        if total[name] == 0: continue\n",
    "    \n",
    "        # plot the data\n",
    "        fig, ax = plt.subplots(figsize=(8, 4))\n",
    "        ax.bar(weekly.index, weekly[name], width=5, color='#dd0000', )\n",
    "        ax.margins(0.01)\n",
    "            \n",
    "        # This makes the dates for xticklabels look a little nicer\n",
    "        locator = mdates.AutoDateLocator(minticks=4, maxticks=13)\n",
    "        formatter = mdates.ConciseDateFormatter(locator)\n",
    "        ax.xaxis.set_major_locator(locator)\n",
    "        ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "        # adjust y-limits to be prettier, \n",
    "        # assume ylim[0] is zero\n",
    "        # this adjustment should not be needed, but it is\n",
    "        ylim = ax.get_ylim()\n",
    "        ylim = ylim[0], ylim[1] * 1.025\n",
    "        if ylim[0] != 0:\n",
    "            # this should not happen - ever.\n",
    "            print(f'Warning: ylim[0] is {ylim[0]} for {name}')\n",
    "        \n",
    "        # an ugly kludge for putting commas in the ylabels\n",
    "        def small(x): return np.round(x, 2)\n",
    "        def big(x): return int(x)\n",
    "        functor = small if weekly[name].max() <= 4 else big\n",
    "        ax.get_yaxis().set_major_formatter(\n",
    "            mpl.ticker.FuncFormatter(\n",
    "                lambda x, p: format(functor(x), ',')))\n",
    "            \n",
    "        ps.finalise_plot(ax, \n",
    "                         title=f'COVID-19 {mode.title()}: {name}',\n",
    "                         xlabel=None,\n",
    "                         ylabel=f'New {mode.lower()}/week ending '\n",
    "                                f'{RULE[-3:].title()}',\n",
    "                         ylim=ylim,\n",
    "                         rfooter=data_quality[index][name],\n",
    "                         lfooter=f'Total {mode.lower()}: '\n",
    "                                 f'{int(total[name]):,}',\n",
    "                         save_as=f'{CHART_DIRECTORY}'\n",
    "                                 f'{name}-{mode.lower()}'\n",
    "                                  '-new-weekly.png'\n",
    "                         )\n",
    "        \n",
    "    return returnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True: # switch this output on/off\n",
    "    adj_weekly_data = [None, None]\n",
    "    for (mode, index) in modes.items():\n",
    "        daily = adj_daily_data[index].copy()\n",
    "        adj_weekly_data[index] = plot_weekly(daily, \n",
    "                                             mode.lower(), \n",
    "                                             data_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot new-vs-cumulative (all and last 3 months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True: # switch this output on/off\n",
    "\n",
    "    THREE_MONTHS = 93 # days\n",
    "    periods = [0, THREE_MONTHS]\n",
    "\n",
    "    tags = [\"full\", \"3months\"]  \n",
    "    for period, tag in zip(periods, tags):\n",
    "        for mode, index in modes.items():\n",
    "            for name in adj_cum_data[index].columns:\n",
    "        \n",
    "                # let's not plot empty charts\n",
    "                if adj_daily_data[index][name][-period:].sum() == 0: \n",
    "                    continue\n",
    "            \n",
    "                ps.plot_new_cum(\n",
    "                    adj_daily_data[index][name][-period:].copy(), \n",
    "                    adj_cum_data[index][name][-period:].copy(), \n",
    "                    mode, name, \n",
    "                    title=f'{name}: COVID-19 {mode.title()}',\n",
    "                    rfooter=data_quality[index][name],\n",
    "                    save_as=f'{CHART_DIRECTORY}{name}-{mode.lower()}'\n",
    "                                f'-new-vs-cum-{tag}.png'\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## International comparisons - maps/leader-boards/swarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_million_population(population: pd.Series, power:int = 6):\n",
    "    \"\"\"Take a population series and a power and return in a tuple:\n",
    "       - the power\n",
    "       - the factor (which is 10 ** power)\n",
    "       - an updated population series (which is population / factor)\"\"\"\n",
    "    \n",
    "    factor = 10 ** power\n",
    "    return power, factor, population / factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rear_offsets(dataframe, period):\n",
    "    \"\"\"Get offset to last non-zero values in dataframe by col\n",
    "       provided offset is within period, otherwise zero offset\n",
    "       [We do this becuase some nations are slow in reporting,\n",
    "       and without this adjustment late reporting nations would \n",
    "       look better than they actually are.]\"\"\"\n",
    "    \n",
    "    nrows = len(dataframe)\n",
    "    rear_offsets = pd.Series(0, index=dataframe.columns)\n",
    "    for col in dataframe.columns:\n",
    "        index_array = (np.nonzero(dataframe[col].to_numpy()))[0]\n",
    "        if len(index_array) > 0:\n",
    "            last = index_array[-1]\n",
    "            rear_offsets[col] = nrows - last - 1\n",
    "            # Note: rear_offsets[col] is 0 if len(index_array) == 0\n",
    "    rear_offsets = rear_offsets.where(rear_offsets<=period, other=0)\n",
    "    return rear_offsets\n",
    "\n",
    "def get_recent_total(dataframe, rear_offsets, period):\n",
    "    \"\"\"Sum the last rows of a dataframe, making adjustments\n",
    "       for zero rows at the very end\"\"\"\n",
    "    \n",
    "    daily_sum = pd.Series(0.0, index=dataframe.columns)\n",
    "    for col in dataframe.columns:\n",
    "        p = 0 - (period+rear_offsets[col])\n",
    "        daily_sum[col] = dataframe[col].iloc[p:].sum()\n",
    "    return daily_sum\n",
    "\n",
    "def get_larger_nations(population, thresh=100_000):\n",
    "    \"\"\"return a list of nations with a population exceeding thresh\"\"\"\n",
    "    \n",
    "    return population[population >= thresh].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_world(series, title, legend_title, source):\n",
    "    \n",
    "    # prepare data for mapping\n",
    "    name_map(series, iso_name_map)\n",
    "    score = pd.DataFrame(series) # back to DataFrame\n",
    "    score.columns = ['Score']\n",
    "    score['country'] = score.index\n",
    "    score['code'] = [iso3166.countries.get(x.upper())[2] \n",
    "                     for x in score['country']]\n",
    "    \n",
    "    # get map data\n",
    "    shapefile = ('../geo-data/ne_110m_admin_0_countries/'\n",
    "        'ne_110m_admin_0_countries.shp')\n",
    "    gdf = gpd.read_file(shapefile)[['ADMIN', 'ADM0_A3', 'geometry']]\n",
    "    gdf.columns = ['country', 'country_code', 'geometry']\n",
    "    gdf = gdf[gdf['country'] != 'Antarctica'] \n",
    "    \n",
    "    merged = gdf.merge(score,\n",
    "                       left_on='country_code', \n",
    "                       right_on='code', how='left')\n",
    "\n",
    "    variable = 'Score'\n",
    "    cmap = mpl.cm.get_cmap('viridis').reversed()\n",
    "    cmap.set_bad('white')\n",
    "    cmap.set_under('white')\n",
    "    ax = merged.plot(column=variable, cmap=cmap, legend=False)\n",
    "    \n",
    "    # colorbar\n",
    "    world_map = ax.collections[0]\n",
    "    cb = plt.colorbar(world_map, ax=ax, orientation='horizontal')\n",
    "    \n",
    "    # legend title\n",
    "    fig = ax.figure\n",
    "    fig.text(0.5, 0.175, legend_title,\n",
    "        ha='center', va='bottom',\n",
    "        fontsize=12, # fontstyle='italic',\n",
    "        color='#222222')\n",
    "    \n",
    "    ps.finalise_plot(ax, title=title,\n",
    "                     xticklabels=[], yticklabels=[],\n",
    "                     xticks=[], yticks=[],\n",
    "                     rfooter=source,\n",
    "                     set_size_inches=(8,5),\n",
    "                     save_as=f'{CHART_DIRECTORY}'\n",
    "                             f'{I_PREFIX}MAP-{title}.png',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swarm(data: pd.Series,\n",
    "          title=\"Don't forget the title\",\n",
    "          ylabel=\"Don't forget the ylabel\",\n",
    "          source=\"Don't forget the source\",\n",
    "          color='cornflowerblue'):\n",
    "    \"\"\"Produce a swarm plot from the following input:\n",
    "        - data - a pandas Series of values, with an index of nations\n",
    "        - title - plot title\n",
    "        - ylabel - label for the y axis\n",
    "        - source - string for data source - becomes right footer\n",
    "        - color - colour of swarm plot dots\n",
    "       \"\"\"\n",
    "    \n",
    "    # get country information\n",
    "    wbd = pd.read_excel('../data/CLASS.xls', header=4, index_col=0, \n",
    "                        ).iloc[1:219].dropna(how='all', axis=1)\n",
    "    mapping = wbd['Income group']\n",
    "    mapping.index = wbd['Code']\n",
    "    \n",
    "    # prepare for plot\n",
    "    name_map(data, iso_name_map)\n",
    "    data = pd.DataFrame(data)\n",
    "    data.columns = ['Rate']\n",
    "    data['alpha3'] = [iso3166.countries.get(x).alpha3 for x in data.index]\n",
    "    data['alpha2'] = [iso3166.countries.get(x).alpha2 for x in data.index]\n",
    "    data['Income Group'] = data.alpha3.map(mapping)\n",
    "    data = data[data['Income Group'].notna()]\n",
    "    \n",
    "    # labels \n",
    "    data['alpha2'] = data['alpha2'].where(data['alpha2'].notna(), other='')\n",
    "    \n",
    "    # swarm plot\n",
    "    # - set up\n",
    "    categories = ['Low income', 'Lower middle income',\n",
    "                  'Upper middle income', 'High income']\n",
    "    # - plot\n",
    "    fig, ax = plt.subplots(figsize=(8,5))\n",
    "    sns.swarmplot(x='Income Group', y='Rate', data=data, \n",
    "                       size=10,\n",
    "                       dodge=True, \n",
    "                       color=color, alpha=0.5,\n",
    "                       order=categories,\n",
    "                       ax=ax)\n",
    "    \n",
    "    # === Next code broken with Matplotlib v3.3.3 ===\n",
    "    # - point annotation - this is one ugly hack\n",
    "    #for collect, name in zip(ax.collections, categories):\n",
    "    #    \n",
    "    #    # retrieve positional data from plot\n",
    "    #    op = collect.get_offset_position()\n",
    "    #    collect.set_offset_position('data')\n",
    "    #    retrieved_xy_pairs = collect.get_offsets()\n",
    "    #    collect.set_offset_position(op)\n",
    "    #    \n",
    "    #    # build an xy map with duplicate keys\n",
    "    #    THRESH = 7\n",
    "    #    dup_map = {}\n",
    "    #    for x, y in retrieved_xy_pairs:\n",
    "    #        yy = np.round(y, THRESH)\n",
    "    #        if yy in dup_map:\n",
    "    #            dup_map[yy].append(x)\n",
    "    #        else:\n",
    "    #            dup_map[yy] = [x]\n",
    "    #    \n",
    "    #    # use this map to plot in the data labels\n",
    "    #   for index, row in data[data['Income Group'] == name].iterrows():\n",
    "    #        lookup = np.round(row['Rate'], THRESH)\n",
    "    #        if lookup in dup_map:\n",
    "    #           ax.text(dup_map[lookup].pop(), row['Rate'], row['alpha2'],\n",
    "    #                   ha='center', va='center', fontsize='xx-small', \n",
    "    #                    color='#333333')\n",
    "        \n",
    "    ps.finalise_plot(ax, title=title,\n",
    "                     xlabel=None, ylabel=ylabel,\n",
    "                     rfooter=source,\n",
    "                     set_size_inches=(8, 8),\n",
    "                     chart_directory=CHART_DIRECTORY\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cases\n",
      "Deaths\n"
     ]
    }
   ],
   "source": [
    "if True: # switch this output on/off\n",
    "\n",
    "    # set-up\n",
    "    PERIOD = 7 # days (recent data period for daily averages)\n",
    "    THRESH = 100_000 # people (minimum nation size for plotting)\n",
    "    BAR_N = 40 # maximum bars on chart\n",
    "    BAR_PLOT_SIZE = (8, 8)\n",
    "    keepers = get_larger_nations(population, THRESH)\n",
    "    power, factor, pop_millions =  per_million_population(population)\n",
    "\n",
    "    # for cases then deaths ...\n",
    "    for mode, index in modes.items():\n",
    "        print(mode)\n",
    "    \n",
    "        # collect the data for plotting\n",
    "        raw_dataframe = adj_daily_data[index].copy()\n",
    "        \n",
    "        # drop World\n",
    "        if 'World' in raw_dataframe.columns:\n",
    "            del raw_dataframe['World']\n",
    "        if 'World' in pop_millions.index:\n",
    "            pop_millions.drop(labels='World', inplace=True)\n",
    "            keepers = keepers.drop(labels='World')\n",
    "    \n",
    "        # - cumulative data\n",
    "        cumulative = raw_dataframe.sum()\n",
    "        cumulative_percapita = (cumulative / pop_millions)[keepers]\n",
    "        log_cumulative_percapita = np.log(cumulative_percapita + 1)\n",
    "        # - latest daily average data\n",
    "        rear_offsets = get_rear_offsets(raw_dataframe, PERIOD)\n",
    "        daily_ave = (get_recent_total(raw_dataframe, rear_offsets, \n",
    "                                      PERIOD) / PERIOD)\n",
    "        daily_ave_percapita = (daily_ave / pop_millions)[keepers]\n",
    "        log_daily_ave_percapita = np.log(daily_ave_percapita + 1)\n",
    "\n",
    "        # bar charts\n",
    "        # - bar chart of the top cumulative performers\n",
    "        top_tier = cumulative.sort_values(ascending=True)[-BAR_N:]\n",
    "        ps.plot_barh(\n",
    "            series = np.round(top_tier.copy(), 0).astype(int), \n",
    "            title=(f'COVID-19: Top cumulative {mode.lower()}'),\n",
    "            xlabel=(f'Cumulative {mode.lower()}'),\n",
    "            lfooter=f'For nations with a population >= {THRESH:,}',\n",
    "            rfooter=f'Source: {source}',\n",
    "            set_size_inches=BAR_PLOT_SIZE,\n",
    "            save_as=f'{CHART_DIRECTORY}{I_PREFIX}Top-{mode.title()} (cum).png'\n",
    "        )\n",
    "\n",
    "        # - bar chart of the top cumulative performers per capita\n",
    "        top_tier = cumulative_percapita.sort_values(ascending=True)[-BAR_N:]\n",
    "        ps.plot_barh(\n",
    "            series = np.round(top_tier.copy(), 1), \n",
    "            title=(f'COVID-19: Top cumulative {mode.lower()} per capita'),\n",
    "            xlabel=(f'Cumulative {mode.lower()} per '\n",
    "                    f'$10^{power}$ population'),\n",
    "            lfooter=f'For nations with a population >= {THRESH:,}',\n",
    "            rfooter=f'Source: {source}',\n",
    "            set_size_inches=BAR_PLOT_SIZE,\n",
    "            save_as=(f'{CHART_DIRECTORY}{I_PREFIX}TOP-{mode.title()}'\n",
    "                     ' per capita (cum).png')\n",
    "        )\n",
    "\n",
    "        # - bar chart of the top daily averages - past week\n",
    "        top_tier = daily_ave.sort_values(ascending=True)[-BAR_N:]\n",
    "        ps.plot_barh(\n",
    "            series = np.round(top_tier.copy(), 1), \n",
    "            title=(f'COVID-19: Top {mode.lower()} - '\n",
    "                  f'past {PERIOD} days'),\n",
    "            xlabel=(f'Average daily {mode.lower()}'),\n",
    "            lfooter=f'For nations with a population >= {THRESH:,}',\n",
    "            rfooter=f'Source: {source}',\n",
    "            set_size_inches=BAR_PLOT_SIZE,\n",
    "            save_as=(f'{CHART_DIRECTORY}{I_PREFIX}Top-{mode.title()} '\n",
    "                     '(recent).png')\n",
    "        ) \n",
    "        \n",
    "        # - bar chart of the top daily averages per capita\n",
    "        top_tier = daily_ave_percapita.sort_values(ascending=True)[-BAR_N:]\n",
    "        ps.plot_barh(\n",
    "            series = np.round(top_tier.copy(), 1), \n",
    "            title=(f'COVID-19: Top {mode.lower()} per capita - '\n",
    "                  f'past {PERIOD} days'),\n",
    "            xlabel=(f'Average daily {mode.lower()} per '\n",
    "                    f'$10^{power}$ population'),\n",
    "            lfooter=f'For nations with a population >= {THRESH:,}',\n",
    "            rfooter=f'Source: {source}',\n",
    "            set_size_inches=BAR_PLOT_SIZE,\n",
    "            save_as=(f'{CHART_DIRECTORY}{I_PREFIX}Top-'\n",
    "                     f'{mode.title()} per capita (recent).png')\n",
    "        )  \n",
    "\n",
    "        # world maps\n",
    "        # - world map - cumulative per capita\n",
    "        title = f'COVID-19 Cumulative {mode.lower()} per capita'\n",
    "        legend = (f'Cumulative {mode.lower()} per '\n",
    "                  f'$10^{power}$ population')\n",
    "        map_world(cumulative_percapita.copy(), title, legend,\n",
    "                  f'Source: {source}')\n",
    "\n",
    "        # - world map - cumulative per capita - log scale\n",
    "        title = (f'COVID-19 Cumulative {mode.lower()} per capita '\n",
    "                 f'(log scale)')\n",
    "        legend = (f'log((cumulative {mode.lower()} per '\n",
    "                  f'$10^{power}$ pop.) + 1)')\n",
    "        map_world(log_cumulative_percapita.copy(), title, legend,\n",
    "                  f'Source: {source}')\n",
    "        \n",
    "        # - world map - average daily per capita past PERIOD days\n",
    "        title = (f'COVID-19 Ave. daily {mode.lower()} per capita '\n",
    "             f'- past {PERIOD} days')\n",
    "        legend = (f'Ave. daily {mode.lower()} per '\n",
    "                  f'$10^{power}$ population')\n",
    "        map_world(daily_ave_percapita.copy(), title, legend, \n",
    "                  f'Source: {source}')\n",
    "\n",
    "        # - world map - average daily per capita past PERIOD days - log scale\n",
    "        title = (f'COVID-19 Ave. daily {mode.lower()} per capita '\n",
    "             f'- past {PERIOD} days (log scale)')\n",
    "        legend = (f'log((average daily {mode.lower()} per '\n",
    "              f'$10^{power}$-population) + 1)')\n",
    "        map_world(log_daily_ave_percapita.copy(), title, legend,\n",
    "                  f'Source: {source}')\n",
    "\n",
    "        # === SWARM plots are broken - need to fix ===\n",
    "        \n",
    "        # swarm plots\n",
    "        ## - swarm plot of cumulative per capita\n",
    "        #title = f'COVID-19 Cumulative {mode.lower()} per capita'\n",
    "        #ylabel = (f'Cumulative {mode.lower()} per '\n",
    "        #          f'$10^{power}$ population')\n",
    "        #swarm(cumulative_percapita.copy(), title, \n",
    "        #      ylabel, f'Source: {source}', color='darkorchid')        \n",
    "        #\n",
    "        ## - swarm plot of cumulative per capita - log scale\n",
    "        #log_cumulative_percapita = np.log(cumulative_percapita + 1)\n",
    "        #title = f'COVID-19 Cumulative {mode.lower()} per capita (log scale)'\n",
    "        #ylabel = (f'log((cumulative {mode.lower()} per '\n",
    "        #          f'$10^{power}$ pop.) + 1)')\n",
    "        #swarm(log_cumulative_percapita.copy(), title, \n",
    "        #      ylabel, f'Source: {source}', color='hotpink')\n",
    "        #\n",
    "        ## - swarm plot of daily average per capita past PERIOD days\n",
    "        #title = (f'COVID-19 Ave. daily {mode.lower()} per capita '\n",
    "        #     f'- past {PERIOD} days')\n",
    "        #ylabel = (f'Ave. daily {mode.lower()} per '\n",
    "        #         f'$10^{power}$ population')\n",
    "        #swarm(daily_ave_percapita.copy(), title, \n",
    "        #      ylabel, f'Source: {source}')\n",
    "        #\n",
    "        ## - swarm plot of daily average per capita past PERIOD days - log scale\n",
    "        #title = (f'COVID-19 Ave. daily {mode.lower()} per capita '\n",
    "        #     f'- past {PERIOD} days (log scale)')\n",
    "        #ylabel = (f'log((ave. daily {mode.lower()} per '\n",
    "        #         f'$10^{power}$ pop.) + 1)')\n",
    "        #swarm(log_daily_ave_percapita.copy(), title, \n",
    "        #      ylabel, f'Source: {source}', color='darkorange')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-log comparison plots of cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_semi_log_trajectory(data, mode, threshold, selections, source):\n",
    "    \"\"\"Produce semi-log plots of cumulative data from the \n",
    "       following inputs:\n",
    "        - data - a pandas dataframe of cumulative data\n",
    "        - mode - a string, either 'Cases' or 'Deaths'\n",
    "        - threshold - starting point (eg. 100th case)\n",
    "        - selections - a python dictionary of \n",
    "         'grouping': ['list', 'of', 'nations'], pairs\n",
    "        - source - string for data source\n",
    "       \"\"\"\n",
    "    \n",
    "    styles = ['-'] #, '--', '-.', ':'] # 4 lines \n",
    "    markers = list('PXo^v<>D*pH.d') # 13 markers\n",
    "    colours = ['blue', 'red', 'maroon', 'darkorange', 'brown', \n",
    "               'olivedrab', 'darkgoldenrod', 'green',  \n",
    "               'purple', 'black', 'teal'] # 11 colours\n",
    "\n",
    "    for tag, nation_list in selections.items():\n",
    "    \n",
    "        # set up for the plot\n",
    "        ax = plt.subplot(111,)\n",
    "        ax.set_title('COVID-19 Semilog plot of selected '\n",
    "                     f'{mode.lower()[:-1]} trajectories')\n",
    "        ax.set_xlabel('Days from the notional '\n",
    "                      f'{int(threshold)}th {mode.lower()[:-1]}')\n",
    "        ax.set_ylabel(f'Cumulative {mode} (log scale)')\n",
    "        ax.set_yscale('log')\n",
    "\n",
    "        # add the data\n",
    "        endpoints = pd.DataFrame()\n",
    "        nation_list.sort()\n",
    "        for i, name in enumerate(nation_list):\n",
    "            if name not in data.columns:\n",
    "                print(f'{name} is not in data')\n",
    "                continue\n",
    "            y = data[name]\n",
    "            y.index = range(len(y))\n",
    "            start = y[y >= threshold]\n",
    "            if len(start) < 5:\n",
    "                continue\n",
    "            start = start.index[0] - 1\n",
    "            if start < 0:\n",
    "                start = 0\n",
    "            y = y[start:].values\n",
    "            x = range(-1, len(y) - 1)\n",
    "            \n",
    "            # plot line\n",
    "            code = get_national_code(name)\n",
    "            label = f'{name} ({code}) {int(y[-1]):,}'\n",
    "            color = colours[i % len(colours)]\n",
    "            ax.plot(x, y, label=label,\n",
    "                    color=color,)\n",
    "            \n",
    "            # plot end text\n",
    "            endpoints = endpoints.append(\n",
    "                pd.Series([x[-1], y[-1], f'{code}', color],\n",
    "                          index=['x', 'y', 'code', 'color'],\n",
    "                          name=name))\n",
    "\n",
    "        # add endpoint labels \n",
    "        EXPANSION = 0.02\n",
    "        additional = endpoints.x.max() * EXPANSION\n",
    "        for row in endpoints.itertuples(): \n",
    "            ax.text(x=row.x+additional, y=row.y, s=row.code,\n",
    "                    size='small', color='black',\n",
    "                    ha='left', va='center',\n",
    "                    bbox={'alpha':0.5, 'facecolor':'white'})\n",
    "\n",
    "        # etc.\n",
    "        min_, max_ = ax.get_xlim()\n",
    "        max_ = max_ + (max_ * EXPANSION)\n",
    "        ax.set_xlim(min_, max_)\n",
    "        ax.legend(loc='lower right', fontsize='8', ncol=3)\n",
    "        fig = ax.figure\n",
    "\n",
    "        # footnote the plot\n",
    "        fig.text(0.99, 0.01, source,\n",
    "            ha='right', va='bottom',\n",
    "            fontsize=9, fontstyle='italic',\n",
    "            color='#999999')\n",
    "\n",
    "        # finalise \n",
    "        fig.set_size_inches(8, 6)\n",
    "        fig.tight_layout(pad=1.2)\n",
    "        fig.savefig(f'{CHART_DIRECTORY}{I_PREFIX}semilog-{mode}-{tag}', dpi=125)\n",
    "        #plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cases\n",
      "Deaths\n",
      "Timor is not in data\n"
     ]
    }
   ],
   "source": [
    "if True: # switch this output on/off\n",
    "\n",
    "    selections = {\n",
    "        'Anglophone':  ['Australia', 'United States', 'Canada', \n",
    "                        'United Kingdom', 'New Zealand', 'Ireland', ],\n",
    "        'Neighbours':  ['Australia', 'New Zealand', 'Papua New Guinea',\n",
    "                        'Indonesia', 'Singapore', 'Malaysia', #'Brunei',\n",
    "                        'Timor', 'China', 'Japan', 'South Korea', 'India'],\n",
    "        \"SelectedEurope\":['Austria', 'Belgium', 'Denmark', \n",
    "                        'France', 'Germany', 'Greece', 'Italy', 'Netherlands', \n",
    "                        'Norway', 'Poland', 'Portugal', 'Russia', 'Spain',  \n",
    "                        'Sweden', 'Switzerland', 'United Kingdom', ],\n",
    "        \"EU-v-US\":     ['United States', \"European Union\"],\n",
    "        \"Italy-v-UK\":  ['Italy', \"United Kingdom\"]\n",
    "    }\n",
    "    \n",
    "    # https://europa.eu/european-union/about-eu/countries_en\n",
    "    EU = [\n",
    "        'Austria', 'Belgium', 'Bulgaria', 'Croatia', \n",
    "        'Cyprus', 'Czechia', 'Denmark',\n",
    "        'Estonia', 'Finland', 'France', 'Germany',\n",
    "        'Greece', 'Hungary', 'Ireland', 'Italy',\n",
    "        'Latvia', 'Lithuania', 'Luxembourg', 'Malta', \n",
    "        'Netherlands', 'Poland', 'Portugal', 'Romania', \n",
    "        'Slovakia', 'Slovenia', 'Spain', 'Sweden', \n",
    "    ]\n",
    "    assert(len(EU) == 27) \n",
    "    \n",
    "    # for cases then deaths ...\n",
    "    for mode, index in modes.items():\n",
    "        print(mode)\n",
    "        cumulative = adj_cum_data[index].copy()\n",
    "        if 'World' in cumulative.columns:\n",
    "            del cumulative['World']\n",
    "        cumulative[\"European Union\"] = cumulative[EU].sum(axis=1)\n",
    "        \n",
    "        # include top N nations as a chart\n",
    "        N = 9\n",
    "        top = cumulative.iloc[-1].sort_values(ascending=False)[:N]\n",
    "        selections['Top'] = top.index.to_list()\n",
    "        \n",
    "        # and plot\n",
    "        thresh = 100 if mode.lower() == 'cases' else 10\n",
    "        plot_semi_log_trajectory(cumulative, mode, thresh, \n",
    "                                 selections, f'Source: {source}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison plots of daily new per capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_daily_comparative(data, population, mode, regions, source, period=14):\n",
    "    \"\"\"Produce daily plots highlighting new cases/deaths for a \n",
    "       specific set of nations against a backdrop of all nations.\n",
    "    Inputs:\n",
    "        - data - pandas DataFrame of daily new cases/deaths\n",
    "        - population - pandas Series of national populations \n",
    "        - mode - string - either \"cases\" or \"deaths\"\n",
    "        - regions - python list of lists of strings \n",
    "          (nation names - same as columns in data)\n",
    "        - source - string for data source\n",
    "        - period - period for the rolling average \"\"\"\n",
    "    \n",
    "    # set-up\n",
    "    colours = ['blue', 'red', 'maroon', 'darkorange', 'brown', \n",
    "               'olivedrab', 'darkgoldenrod', 'green',  \n",
    "               'purple', 'black', 'teal'] # 11 colours\n",
    "    power, factor, pop_millions =  per_million_population(population)\n",
    "    keepers = get_larger_nations(population, 100_000) # used for backgrounds\n",
    "\n",
    "    # get rolling average per capita from start date\n",
    "    df = data.rolling(period).mean().div(other=pop_millions)\n",
    "    df = df[df.index >= pd.Timestamp('2020-02-01')]\n",
    "\n",
    "    for region_list in regions:\n",
    "    \n",
    "        # plot background\n",
    "        ax = df[keepers].plot(c='#aaaaaa', lw=0.5)\n",
    "        ax.get_legend().remove()\n",
    "\n",
    "        # plot highlighted regions\n",
    "        region_list.sort()\n",
    "        ax_new = ax.twinx()        \n",
    "        for i, name in enumerate(region_list):\n",
    "            df[name].plot(c=colours[i], label=name, lw=2.5, ax=ax_new)\n",
    "        ax_new.legend(title=None, loc=\"upper left\")\n",
    "        ax_new.grid(False)\n",
    "        ax_new.set_yticklabels([])\n",
    "        ax_new.set_ylim(ax.get_ylim())\n",
    "\n",
    "        ps.finalise_plot(ax,\n",
    "                      title=f'COVID-19 Daily New {mode.title()}',\n",
    "                      xlabel=None,\n",
    "                      ylabel=f'Daily new {mode.lower()} per $10^{power}$ '\n",
    "                              f'population\\n{period}-day rolling average',\n",
    "                      rfooter=source,\n",
    "                      set_size_inches=(8, 5),\n",
    "                      save_as=f'{CHART_DIRECTORY}{I_PREFIX}'\n",
    "                              f'daily-{mode}-{\" \".join(region_list)}',\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populations:\n",
      "United States: 331,002,647\n",
      "European Union: 444,919,060\n",
      "\n",
      "Cases\n",
      "Deaths\n"
     ]
    }
   ],
   "source": [
    "if True: # switch this output on/off\n",
    "\n",
    "    # identify the regional sets to be plotted\n",
    "    regions = [\n",
    "        ['European Union', 'United States'],\n",
    "        ['Belgium', 'Ireland', 'Netherlands', 'United Kingdom', 'Iceland'],\n",
    "        ['France', 'Italy', 'Portugal', 'Spain'],\n",
    "        ['Denmark', 'Norway', 'Sweden', 'Austria', 'Germany', 'Switzerland'], \n",
    "        ['Finland', 'Estonia', 'Latvia', 'Lithuania', 'Poland'],\n",
    "        ['Belarus', 'Russia', 'Ukraine', 'Romania', 'Bulgaria', 'Moldova', ],\n",
    "        ['Czechia', 'Slovakia', 'Hungary', 'Slovenia'],\n",
    "        ['Croatia', 'Bosnia and Herzegovina', 'Montenegro',\n",
    "            'Serbia', 'Kosovo', 'Albania', 'North Macedonia', 'Greece'],\n",
    "        ['Turkey', 'Syria', 'Lebanon', 'Israel', 'Jordan', \n",
    "             'Egypt', 'Libya', 'Cyprus'],\n",
    "        ['Georgia', 'Armenia', 'Azerbaijan'],\n",
    "        ['Iraq', 'Iran', 'Saudi Arabia', 'Bahrain', 'Qatar', \n",
    "            'United Arab Emirates', 'Kuwait', 'Yemen', 'Oman',], \n",
    "        ['Ghana', 'Ethiopia', 'Kenya', \n",
    "             'Nigeria', 'South Africa', 'Tanzania'],\n",
    "        ['Afghanistan', 'Kazakhstan', 'Kyrgyzstan', 'Pakistan', \n",
    "            'Tajikistan', 'Uzbekistan', ],\n",
    "        ['Bangladesh', 'Nepal', 'India', 'Sri Lanka'], \n",
    "        ['Indonesia', 'Malaysia', 'Philippines', 'Singapore', 'Thailand'],\n",
    "        ['China', 'Japan', 'South Korea', 'Taiwan', 'Vietnam'],\n",
    "        ['Australia', 'New Zealand', 'Papua New Guinea', 'Timor'], \n",
    "        ['Canada', 'Mexico', 'United States'], \n",
    "        ['Costa Rica', 'Guatemala', 'Honduras', 'Nicaragua', 'Panama'], \n",
    "        ['Argentina', 'Brazil', 'Chile', 'Colombia', 'Ecuador', \n",
    "            'Peru', 'Venezuela'], \n",
    "        ['Cuba', 'Dominican Republic', 'Haiti', 'Jamaica'],\n",
    "    ]\n",
    "\n",
    "    # And population for European Union\n",
    "    pop = population.copy()\n",
    "    pop['European Union'] = pop[EU].sum()\n",
    "    # FYI only ...\n",
    "    print('Populations:\\n'\n",
    "          f'United States: {int(pop[\"United States\"]):,}\\n'\n",
    "          f'European Union: {int(pop[\"European Union\"]):,}\\n')\n",
    "\n",
    "    # for cases then deaths ...\n",
    "    for mode, index in modes.items():\n",
    "        print(mode)\n",
    "        daily = adj_daily_data[index].copy()\n",
    "        daily['European Union'] = daily[EU].sum(axis=1)\n",
    "        plot_daily_comparative(daily, pop, mode, regions, f'Source: {source}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_growth_factor(data, mode, source): \n",
    "    #data, _ = limit_data_cols_to_threshold(data, mode)\n",
    "\n",
    "    for name in data.columns:\n",
    "        ps.plot_growth_factor(data[name], \n",
    "            title=f'{name}: w/w growth in new COVID-19 {mode.lower()}',\n",
    "            ylabel='Growth factor',\n",
    "            xlabel=None,\n",
    "            save_as=f'{CHART_DIRECTORY}/{name}-{mode}-growth-factor-{source}.png',\n",
    "            rfooter=source,\n",
    "            lfooter=f'Weekly rolling average daily new {mode.lower()} this week / last week'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True: # switch this output on/off\n",
    "    # for cases then deaths ...\n",
    "    for mode, index in modes.items():\n",
    "        daily = adj_daily_data[index].copy()\n",
    "        plot_growth_factor(daily, mode, source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "print('Finished')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "209px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
