{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID19 International"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Python-setup\" data-toc-modified-id=\"Python-setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Python setup</a></span></li><li><span><a href=\"#Get-the-raw-data-and-adjust-for-anomalies\" data-toc-modified-id=\"Get-the-raw-data-and-adjust-for-anomalies-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Get the raw data and adjust for anomalies</a></span><ul class=\"toc-item\"><li><span><a href=\"#Nation-naming-stuff\" data-toc-modified-id=\"Nation-naming-stuff-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Nation naming stuff</a></span></li><li><span><a href=\"#COVID-data-retrieval\" data-toc-modified-id=\"COVID-data-retrieval-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>COVID data retrieval</a></span></li><li><span><a href=\"#Check-for-missing/odd-data\" data-toc-modified-id=\"Check-for-missing/odd-data-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Check for missing/odd data</a></span></li><li><span><a href=\"#Adjust-the-data-for-negative-growth-and-outlier-spikes\" data-toc-modified-id=\"Adjust-the-data-for-negative-growth-and-outlier-spikes-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Adjust the data for negative growth and outlier spikes</a></span></li></ul></li><li><span><a href=\"#International-comparisons---maps/leader-boards/swarms\" data-toc-modified-id=\"International-comparisons---maps/leader-boards/swarms-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>International comparisons - maps/leader-boards/swarms</a></span><ul class=\"toc-item\"><li><span><a href=\"#supporting-functions\" data-toc-modified-id=\"supporting-functions-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>supporting functions</a></span></li><li><span><a href=\"#Bar-charts-of-top-performers\" data-toc-modified-id=\"Bar-charts-of-top-performers-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Bar charts of top performers</a></span></li><li><span><a href=\"#Maps\" data-toc-modified-id=\"Maps-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Maps</a></span></li><li><span><a href=\"#Swarm-plots\" data-toc-modified-id=\"Swarm-plots-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Swarm plots</a></span></li></ul></li><li><span><a href=\"#Semi-log-comparison-plots-of-cumulative\" data-toc-modified-id=\"Semi-log-comparison-plots-of-cumulative-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Semi-log comparison plots of cumulative</a></span></li><li><span><a href=\"#Comparison-plots-of-daily-new-per-capita\" data-toc-modified-id=\"Comparison-plots-of-daily-new-per-capita-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Comparison plots of daily new per capita</a></span></li><li><span><a href=\"#Plot-weekly-new-case/deaths-data-from-January-2020\" data-toc-modified-id=\"Plot-weekly-new-case/deaths-data-from-January-2020-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Plot weekly new-case/deaths data from January 2020</a></span></li><li><span><a href=\"#Plot-new-vs-cumulative-(all-and-last-3-months)\" data-toc-modified-id=\"Plot-new-vs-cumulative-(all-and-last-3-months)-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Plot new-vs-cumulative (all and last 3 months)</a></span></li><li><span><a href=\"#Growth\" data-toc-modified-id=\"Growth-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Growth</a></span></li><li><span><a href=\"#The-End\" data-toc-modified-id=\"The-End-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>The End</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "#analytic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.units as munits\n",
    "import seaborn as sns\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import geopandas as gpd\n",
    "import iso3166\n",
    "\n",
    "# COVID19 specific imports\n",
    "sys.path.append(r'../bin')\n",
    "import plotstuff as ps\n",
    "\n",
    "# directory\n",
    "CHART_DIRECTORY = '../charts'\n",
    "Path(CHART_DIRECTORY).mkdir(parents=True, exist_ok=True)\n",
    "CHART_DIRECTORY += '/'\n",
    "I_PREFIX = '!I-'\n",
    "\n",
    "# display settings\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "# plotting stuff\n",
    "plt.style.use('ggplot')\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the raw data and adjust for anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nation naming stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make country names ISO compliant\n",
    "iso_name_map = {\n",
    "    # from              # to\n",
    "    \"Bolivia\":          \"Bolivia, Plurinational State of\",\n",
    "    \"Bonaire, Saint Eustatius And Saba\": \"Bonaire, Sint Eustatius and Saba\",\n",
    "    \"British Virgin Islands\": \"Virgin Islands, British\",\n",
    "    \"Brunei\":           \"Brunei Darussalam\",\n",
    "    \"Cape Verde\":       \"Cabo Verde\",\n",
    "    \"Cote D'Ivoire\":    \"Côte d'Ivoire\",\n",
    "    \"Cote d'Ivoire\":    \"Côte d'Ivoire\",\n",
    "    \"Curaã§Ao\":         \"Curaçao\",\n",
    "    \"Democratic Republic Of Congo\": \"Congo, Democratic Republic of the\",\n",
    "    \"Democratic Republic of Congo\": \"Congo, Democratic Republic of the\",\n",
    "    \"Guinea Bissau\":    \"Guinea-Bissau\",\n",
    "    \"Vatican\":          \"Holy See\",\n",
    "    \"Iran\":             \"Iran, Islamic Republic of\",\n",
    "    \"Laos\":             \"Lao People's Democratic Republic\",\n",
    "    \"Moldova\":          \"Moldova, Republic of\",\n",
    "    \"Russia\":           \"Russian Federation\",\n",
    "    \"Sint Maarten\":     \"Sint Maarten (Dutch part)\",\n",
    "    \"South Korea\":      \"Korea, Republic of\",\n",
    "    \"Syria\":            \"Syrian Arab Republic\",\n",
    "    \"Tanzania\":         \"Tanzania, United Republic of\",\n",
    "    \"Timor\":            \"Timor-Leste\",\n",
    "    \"Timor Leste\":      \"Timor-Leste\",\n",
    "    \"United Kingdom\":   \"United Kingdom of Great Britain and Northern Ireland\",\n",
    "    \"United Republic Of Tanzania\": \"Tanzania, United Republic of\",\n",
    "    \"United States\":    \"United States of America\",\n",
    "    \"United States Virgin Islands\":   \"Virgin Islands, U.S.\",\n",
    "    \"Venezuela\":        \"Venezuela, Bolivarian Republic of\",\n",
    "    \"Vietnam\":          \"Viet Nam\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_map(object_, map_):\n",
    "    \"\"\"Rename the index of a Series or the columns of a DataFrame\n",
    "       The renaming is done in place.\n",
    "       Parameters\n",
    "       - object_ - the pandas Series or DataFrame\n",
    "       - map_ - a dictionary of old to new mappings \n",
    "       Returns: None \"\"\"\n",
    "\n",
    "    fixing = {}\n",
    "    if isinstance(object_, pd.Series):\n",
    "        for name in map_:\n",
    "            if name in object_.index:\n",
    "                fixing[name] = map_[name]\n",
    "        object_.rename(index=fixing, inplace=True)\n",
    "    else:\n",
    "        for name in map_:\n",
    "            if name in object_.columns:\n",
    "                fixing[name] = map_[name]\n",
    "        object_.rename(columns=fixing, inplace=True)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_national_code(nation):\n",
    "    if nation in iso_name_map.keys():\n",
    "        nation = iso_name_map[nation]\n",
    "    if nation == 'European Union':\n",
    "        return 'EU'\n",
    "    code = iso3166.countries.get(nation).alpha2\n",
    "    return code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COVID data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data_lake = {}\n",
    "def get_OWID_data():\n",
    "    URL = ('https://github.com/owid/covid-19-data/raw/master/'\n",
    "           'public/data/owid-covid-data.csv')\n",
    "\n",
    "    if URL in _data_lake:\n",
    "        df =  _data_lake[URL].copy()\n",
    "        print('Data retrieved from the lake')\n",
    "    else:\n",
    "        print(URL)\n",
    "        df = pd.read_csv(URL, header=0)\n",
    "        print('We have the data')\n",
    "        _data_lake[URL] = df.copy()\n",
    "\n",
    "    # get cases and deaths, \n",
    "    # remove null columns\n",
    "    # remove null rows (largely affects the last row when not populated)\n",
    "    # make index a DatetimeIndex\n",
    "    cases = df.pivot(columns='location', index='date', values='total_cases')\n",
    "    cases = cases.dropna(axis='columns', how='all')\n",
    "    cases = cases.dropna(axis='index', how='all')\n",
    "    source = f'OWID {cases.index[-1]}'\n",
    "    cases.index = pd.DatetimeIndex(cases.index)\n",
    "\n",
    "    deaths = df.pivot(columns='location', index='date', values='total_deaths')\n",
    "    deaths = deaths.dropna(axis='columns', how='all')\n",
    "    deaths.index = pd.DatetimeIndex(deaths.index)\n",
    "    deaths = deaths.dropna(axis='index', how='all')\n",
    "    \n",
    "    # population data for each country\n",
    "    population = df.pivot(columns='location', index='date', values='population')\n",
    "    populations = {}\n",
    "    for p in population.columns:\n",
    "        address = population[p].last_valid_index()\n",
    "        if address is None:\n",
    "            continue\n",
    "        populations[p] = population[p].loc[address]\n",
    "    \n",
    "    # return the lot\n",
    "    return cases, deaths, pd.Series(populations).astype(int), source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/owid/covid-19-data/raw/master/public/data/owid-covid-data.csv\n",
      "We have the data\n"
     ]
    }
   ],
   "source": [
    "# retrieve raw\n",
    "raw_cum_cases, raw_cum_deaths, population, source = get_OWID_data()\n",
    "SOURCE = f'Source: {source}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for missing/odd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In respect of data from OWID 2020-12-31\n",
      "All cases data on last day appear to be present\n",
      "All deaths data on last day appear to be present\n"
     ]
    }
   ],
   "source": [
    "# Check for missing data (NAN) in the last row.\n",
    "# My experience is that these are usually plentiful in\n",
    "# the early morning but resolved by the afternoon/evening \n",
    "# (Sydney time). \n",
    "\n",
    "print(f'In respect of data from {source}')\n",
    "for mode, data in zip(['cases', 'deaths'],\n",
    "                      [raw_cum_cases, raw_cum_deaths]):\n",
    "    missing = data.iloc[-1]\n",
    "    missing = missing[missing.isna()]\n",
    "    if len(missing):\n",
    "        print(f'{len(missing)} missing {mode} on last day')\n",
    "    else: \n",
    "        print(f'All {mode} data on last day appear to be present')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 11 odd, zero-growth in cases on the last day\n",
      "They are:  ['Bosnia and Herzegovina' 'Cyprus' 'El Salvador' 'Eritrea' 'Gabon' 'Ghana'\n",
      " 'India' 'Lesotho' 'Luxembourg' 'Sweden' 'Tajikistan']\n",
      "Their last week of data is as follows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>location</th>\n",
       "      <th>Bosnia and Herzegovina</th>\n",
       "      <th>Cyprus</th>\n",
       "      <th>El Salvador</th>\n",
       "      <th>Eritrea</th>\n",
       "      <th>Gabon</th>\n",
       "      <th>Ghana</th>\n",
       "      <th>India</th>\n",
       "      <th>Lesotho</th>\n",
       "      <th>Luxembourg</th>\n",
       "      <th>Sweden</th>\n",
       "      <th>Tajikistan</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-12-24</th>\n",
       "      <td>108298.0</td>\n",
       "      <td>19316.0</td>\n",
       "      <td>44619.0</td>\n",
       "      <td>951.0</td>\n",
       "      <td>9469.0</td>\n",
       "      <td>54043.0</td>\n",
       "      <td>10146845.0</td>\n",
       "      <td>2725.0</td>\n",
       "      <td>45209.0</td>\n",
       "      <td>396048.0</td>\n",
       "      <td>13106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-25</th>\n",
       "      <td>108891.0</td>\n",
       "      <td>19366.0</td>\n",
       "      <td>44619.0</td>\n",
       "      <td>992.0</td>\n",
       "      <td>9497.0</td>\n",
       "      <td>54043.0</td>\n",
       "      <td>10169118.0</td>\n",
       "      <td>2725.0</td>\n",
       "      <td>45209.0</td>\n",
       "      <td>396048.0</td>\n",
       "      <td>13138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-26</th>\n",
       "      <td>109330.0</td>\n",
       "      <td>19391.0</td>\n",
       "      <td>44619.0</td>\n",
       "      <td>992.0</td>\n",
       "      <td>9497.0</td>\n",
       "      <td>54286.0</td>\n",
       "      <td>10187850.0</td>\n",
       "      <td>2725.0</td>\n",
       "      <td>45209.0</td>\n",
       "      <td>396048.0</td>\n",
       "      <td>13172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-27</th>\n",
       "      <td>109691.0</td>\n",
       "      <td>19657.0</td>\n",
       "      <td>44619.0</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>9497.0</td>\n",
       "      <td>54401.0</td>\n",
       "      <td>10207871.0</td>\n",
       "      <td>2725.0</td>\n",
       "      <td>45209.0</td>\n",
       "      <td>396048.0</td>\n",
       "      <td>13205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>109911.0</td>\n",
       "      <td>20408.0</td>\n",
       "      <td>45415.0</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>9510.0</td>\n",
       "      <td>54503.0</td>\n",
       "      <td>10224303.0</td>\n",
       "      <td>2956.0</td>\n",
       "      <td>45849.0</td>\n",
       "      <td>396048.0</td>\n",
       "      <td>13237.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>110454.0</td>\n",
       "      <td>21315.0</td>\n",
       "      <td>45415.0</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>9510.0</td>\n",
       "      <td>54681.0</td>\n",
       "      <td>10244852.0</td>\n",
       "      <td>3005.0</td>\n",
       "      <td>46088.0</td>\n",
       "      <td>428533.0</td>\n",
       "      <td>13265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>110985.0</td>\n",
       "      <td>22019.0</td>\n",
       "      <td>45960.0</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>9571.0</td>\n",
       "      <td>54771.0</td>\n",
       "      <td>10266674.0</td>\n",
       "      <td>3094.0</td>\n",
       "      <td>46415.0</td>\n",
       "      <td>437379.0</td>\n",
       "      <td>13296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>110985.0</td>\n",
       "      <td>22019.0</td>\n",
       "      <td>45960.0</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>9571.0</td>\n",
       "      <td>54771.0</td>\n",
       "      <td>10266674.0</td>\n",
       "      <td>3094.0</td>\n",
       "      <td>46415.0</td>\n",
       "      <td>437379.0</td>\n",
       "      <td>13296.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "location    Bosnia and Herzegovina   Cyprus  El Salvador  Eritrea   Gabon  \\\n",
       "date                                                                        \n",
       "2020-12-24                108298.0  19316.0      44619.0    951.0  9469.0   \n",
       "2020-12-25                108891.0  19366.0      44619.0    992.0  9497.0   \n",
       "2020-12-26                109330.0  19391.0      44619.0    992.0  9497.0   \n",
       "2020-12-27                109691.0  19657.0      44619.0   1039.0  9497.0   \n",
       "2020-12-28                109911.0  20408.0      45415.0   1039.0  9510.0   \n",
       "2020-12-29                110454.0  21315.0      45415.0   1220.0  9510.0   \n",
       "2020-12-30                110985.0  22019.0      45960.0   1252.0  9571.0   \n",
       "2020-12-31                110985.0  22019.0      45960.0   1252.0  9571.0   \n",
       "\n",
       "location      Ghana       India  Lesotho  Luxembourg    Sweden  Tajikistan  \n",
       "date                                                                        \n",
       "2020-12-24  54043.0  10146845.0   2725.0     45209.0  396048.0     13106.0  \n",
       "2020-12-25  54043.0  10169118.0   2725.0     45209.0  396048.0     13138.0  \n",
       "2020-12-26  54286.0  10187850.0   2725.0     45209.0  396048.0     13172.0  \n",
       "2020-12-27  54401.0  10207871.0   2725.0     45209.0  396048.0     13205.0  \n",
       "2020-12-28  54503.0  10224303.0   2956.0     45849.0  396048.0     13237.0  \n",
       "2020-12-29  54681.0  10244852.0   3005.0     46088.0  428533.0     13265.0  \n",
       "2020-12-30  54771.0  10266674.0   3094.0     46415.0  437379.0     13296.0  \n",
       "2020-12-31  54771.0  10266674.0   3094.0     46415.0  437379.0     13296.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 3 odd, zero-growth in deaths on the last day\n",
      "They are:  ['Bosnia and Herzegovina' 'India' 'Sweden']\n",
      "Their last week of data is as follows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>location</th>\n",
       "      <th>Bosnia and Herzegovina</th>\n",
       "      <th>India</th>\n",
       "      <th>Sweden</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-12-24</th>\n",
       "      <td>3878.0</td>\n",
       "      <td>147092.0</td>\n",
       "      <td>8279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-25</th>\n",
       "      <td>3901.0</td>\n",
       "      <td>147343.0</td>\n",
       "      <td>8279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-26</th>\n",
       "      <td>3923.0</td>\n",
       "      <td>147622.0</td>\n",
       "      <td>8279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-27</th>\n",
       "      <td>3953.0</td>\n",
       "      <td>147901.0</td>\n",
       "      <td>8279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>3942.0</td>\n",
       "      <td>148153.0</td>\n",
       "      <td>8279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>4024.0</td>\n",
       "      <td>148439.0</td>\n",
       "      <td>8484.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>4050.0</td>\n",
       "      <td>148738.0</td>\n",
       "      <td>8727.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>4050.0</td>\n",
       "      <td>148738.0</td>\n",
       "      <td>8727.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "location    Bosnia and Herzegovina     India  Sweden\n",
       "date                                                \n",
       "2020-12-24                  3878.0  147092.0  8279.0\n",
       "2020-12-25                  3901.0  147343.0  8279.0\n",
       "2020-12-26                  3923.0  147622.0  8279.0\n",
       "2020-12-27                  3953.0  147901.0  8279.0\n",
       "2020-12-28                  3942.0  148153.0  8279.0\n",
       "2020-12-29                  4024.0  148439.0  8484.0\n",
       "2020-12-30                  4050.0  148738.0  8727.0\n",
       "2020-12-31                  4050.0  148738.0  8727.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for unusual no-growth patterns in last row of the \n",
    "# cumulative data when there is substantial growth (of more \n",
    "# than 100) over the past week. \n",
    "# Note: this often just exposes those nations that do not \n",
    "# have a practice of daily reporting their cumulative cases \n",
    "# and deaths.\n",
    "\n",
    "WEEKLY_THRESHOLD = 100\n",
    "\n",
    "for mode, data in zip(['cases', 'deaths'],\n",
    "                      [raw_cum_cases.copy(), \n",
    "                       raw_cum_deaths.copy()]):\n",
    "    \n",
    "    # ignore NANs - as they are picked up in the previous cell. \n",
    "    nan_last = data.iloc[-1].isna()\n",
    "    data = data.drop(columns=nan_last[nan_last].index)\n",
    "\n",
    "    # identify columns of concern in respct of absent last-day growth \n",
    "    last_day_growth = data.iloc[-1] - data.iloc[-2]\n",
    "    week_growth = data.iloc[-1] - data.iloc[-8]\n",
    "    odd = (week_growth > WEEKLY_THRESHOLD) & (last_day_growth == 0)\n",
    "    if len(odd):\n",
    "        print(f'\\nThere are {odd.sum()} odd, zero-growth in {mode} on the last day')\n",
    "        print('They are: ', odd[odd].index.values)\n",
    "        print('Their last week of data is as follows:')\n",
    "        display(data[odd[odd].index].iloc[-8:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust the data for negative growth and outlier spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spikes in Andorra\n",
      "date   2020-06-02\n",
      "spike   79.000000\n",
      "mean     0.714286\n",
      "zeros   10.000000\n",
      "There are negatives in Antigua and Barbuda\n",
      "date\n",
      "2020-07-03   -1.0\n",
      "Name: Antigua and Barbuda, dtype: float64\n",
      "Data too sparse in Antigua and Barbuda (max_consecutive=2)\n",
      "Data too sparse in Barbados (max_consecutive=11)\n",
      "Spikes in Belize\n",
      "date    2020-12-03\n",
      "spike  1382.000000\n",
      "mean    142.857143\n",
      "zeros     2.000000\n",
      "There are negatives in Benin\n",
      "date\n",
      "2020-05-19   -209.0\n",
      "Name: Benin, dtype: float64\n",
      "Data too sparse in Benin (max_consecutive=10)\n",
      "Data too sparse in Bhutan (max_consecutive=9)\n",
      "Data too sparse in Botswana (max_consecutive=2)\n",
      "Spikes in Burkina Faso\n",
      "date   2020-05-06  2020-06-02  2020-09-13\n",
      "spike   41.000000   34.000000       193.0\n",
      "mean     6.714286    1.785714        17.5\n",
      "zeros    0.000000    6.000000         0.0\n",
      "Data too sparse in Burundi (max_consecutive=10)\n",
      "Data too sparse in Cambodia (max_consecutive=14)\n",
      "Data too sparse in Cameroon (max_consecutive=7)\n",
      "Spikes in Cape Verde\n",
      "date   2020-04-15\n",
      "spike        45.0\n",
      "mean          1.5\n",
      "zeros         6.0\n",
      "Data too sparse in Central African Republic (max_consecutive=14)\n",
      "There are negatives in China\n",
      "date\n",
      "2020-06-03   -1.0\n",
      "Name: China, dtype: float64\n",
      "Spikes in China\n",
      "date   2020-02-13  2020-04-17\n",
      "spike     15136.0  357.000000\n",
      "mean       2321.5   47.071429\n",
      "zeros         0.0    0.000000\n",
      "Data too sparse in Comoros (max_consecutive=2)\n",
      "Data too sparse in Congo (max_consecutive=3)\n",
      "There are negatives in Cote d'Ivoire\n",
      "date\n",
      "2020-12-16   -34.0\n",
      "Name: Cote d'Ivoire, dtype: float64\n",
      "There are negatives in Cyprus\n",
      "date\n",
      "2020-08-27   -17.0\n",
      "Name: Cyprus, dtype: float64\n",
      "Data too sparse in Dominica (max_consecutive=2)\n",
      "There are negatives in Ecuador\n",
      "date\n",
      "2020-05-07   -1583.0\n",
      "2020-05-08   -1480.0\n",
      "2020-05-11     -50.0\n",
      "2020-09-07   -7953.0\n",
      "Name: Ecuador, dtype: float64\n",
      "Spikes in Ecuador\n",
      "date    2020-04-10   2020-04-24\n",
      "spike  1727.637828  9075.605639\n",
      "mean    173.696608   369.477580\n",
      "zeros     1.000000     2.000000\n",
      "Data too sparse in Equatorial Guinea (max_consecutive=5)\n",
      "Data too sparse in Eritrea (max_consecutive=6)\n",
      "Data too sparse in Fiji (max_consecutive=4)\n",
      "There are negatives in Finland\n",
      "date\n",
      "2020-07-15   -5.0\n",
      "2020-07-16   -3.0\n",
      "Name: Finland, dtype: float64\n",
      "There are negatives in France\n",
      "date\n",
      "2020-04-04   -17074.0\n",
      "2020-04-07    -3491.0\n",
      "2020-04-23    -1710.0\n",
      "2020-04-29    -1455.0\n",
      "2020-05-24     -439.0\n",
      "2020-06-02     -647.0\n",
      "2020-06-03    -3226.0\n",
      "2020-06-28     -406.0\n",
      "2020-11-04   -46076.0\n",
      "Name: France, dtype: float64\n",
      "Spikes in France\n",
      "date     2020-04-12   2020-05-06   2020-06-04\n",
      "spike  43806.856125  3740.300520  4090.739838\n",
      "mean    3870.077783   632.317632   763.252686\n",
      "zeros      0.000000     0.000000     0.000000\n",
      "Data too sparse in Gabon (max_consecutive=7)\n",
      "There are negatives in Gambia\n",
      "date\n",
      "2020-08-24   -100.0\n",
      "Name: Gambia, dtype: float64\n",
      "Data too sparse in Gambia (max_consecutive=8)\n",
      "Spikes in Greece\n",
      "date   2020-04-21\n",
      "spike  156.000000\n",
      "mean    18.928571\n",
      "zeros    1.000000\n",
      "Data too sparse in Grenada (max_consecutive=2)\n",
      "Data too sparse in Guinea-Bissau (max_consecutive=9)\n",
      "There are negatives in Guyana\n",
      "date\n",
      "2020-03-24   -15.0\n",
      "Name: Guyana, dtype: float64\n",
      "There are negatives in Honduras\n",
      "date\n",
      "2020-05-12   -20.0\n",
      "Name: Honduras, dtype: float64\n",
      "Data too sparse in International (max_consecutive=7)\n",
      "There are negatives in Israel\n",
      "date\n",
      "2020-03-11   -28.0\n",
      "Name: Israel, dtype: float64\n",
      "There are negatives in Italy\n",
      "date\n",
      "2020-06-19   -148.0\n",
      "Name: Italy, dtype: float64\n",
      "There are negatives in Jordan\n",
      "date\n",
      "2020-07-21   -110.0\n",
      "Name: Jordan, dtype: float64\n",
      "Spikes in Kazakhstan\n",
      "date     2020-07-01\n",
      "spike  18757.000000\n",
      "mean     966.928571\n",
      "zeros      2.000000\n",
      "Spikes in Kyrgyzstan\n",
      "date     2020-07-18\n",
      "spike  11505.000000\n",
      "mean     764.928571\n",
      "zeros      3.000000\n",
      "Data too sparse in Laos (max_consecutive=5)\n",
      "Data too sparse in Lesotho (max_consecutive=6)\n",
      "Spikes in Liberia\n",
      "date   2020-12-03  2020-12-16\n",
      "spike   68.000000   97.000000\n",
      "mean     2.142857    0.428571\n",
      "zeros   11.000000   13.000000\n",
      "There are negatives in Lithuania\n",
      "date\n",
      "2020-04-28   -105.0\n",
      "Name: Lithuania, dtype: float64\n",
      "There are negatives in Luxembourg\n",
      "date\n",
      "2020-08-28   -1348.0\n",
      "Name: Luxembourg, dtype: float64\n",
      "There are negatives in Madagascar\n",
      "date\n",
      "2020-05-11   -7.0\n",
      "Name: Madagascar, dtype: float64\n",
      "Spikes in Malaysia\n",
      "date   2020-06-04\n",
      "spike  277.000000\n",
      "mean    33.785714\n",
      "zeros    0.000000\n",
      "Spikes in Maldives\n",
      "date   2020-04-30\n",
      "spike  190.000000\n",
      "mean    26.571429\n",
      "zeros    0.000000\n",
      "There are negatives in Malta\n",
      "date\n",
      "2020-08-16   -42.0\n",
      "Name: Malta, dtype: float64\n",
      "Spikes in Malta\n",
      "date   2020-07-30\n",
      "spike   88.178954\n",
      "mean    11.591914\n",
      "zeros    1.000000\n",
      "There are negatives in Marshall Islands\n",
      "date\n",
      "2020-11-05   -1.0\n",
      "Name: Marshall Islands, dtype: float64\n",
      "Data too sparse in Marshall Islands (max_consecutive=1)\n",
      "There are negatives in Mauritius\n",
      "date\n",
      "2020-04-29   -2.0\n",
      "Name: Mauritius, dtype: float64\n",
      "Spikes in Mexico\n",
      "date     2020-10-05\n",
      "spike  28115.000000\n",
      "mean    4472.357143\n",
      "zeros      0.000000\n",
      "There are negatives in Monaco\n",
      "date\n",
      "2020-09-02   -12.0\n",
      "Name: Monaco, dtype: float64\n",
      "Spikes in Mongolia\n",
      "date   2020-12-06\n",
      "spike   38.000000\n",
      "mean     6.428571\n",
      "zeros    0.000000\n",
      "There are negatives in Nepal\n",
      "date\n",
      "2020-05-14   -1.0\n",
      "Name: Nepal, dtype: float64\n",
      "There are negatives in New Zealand\n",
      "date\n",
      "2020-04-26   -1.0\n",
      "2020-05-04   -1.0\n",
      "Name: New Zealand, dtype: float64\n",
      "Data too sparse in Nicaragua (max_consecutive=2)\n",
      "There are negatives in Niger\n",
      "date\n",
      "2020-07-27   -4.0\n",
      "Name: Niger, dtype: float64\n",
      "There are negatives in Papua New Guinea\n",
      "date\n",
      "2020-08-13   -16.0\n",
      "Name: Papua New Guinea, dtype: float64\n",
      "Data too sparse in Papua New Guinea (max_consecutive=8)\n",
      "Spikes in Paraguay\n",
      "date   2020-05-09  2020-05-19\n",
      "spike  126.000000        41.0\n",
      "mean    22.785714         8.0\n",
      "zeros    0.000000         0.0\n",
      "There are negatives in Portugal\n",
      "date\n",
      "2020-05-02   -161.0\n",
      "Name: Portugal, dtype: float64\n",
      "Spikes in Qatar\n",
      "date   2020-03-11\n",
      "spike  238.000000\n",
      "mean    14.785714\n",
      "zeros    5.000000\n",
      "Data too sparse in Saint Kitts and Nevis (max_consecutive=2)\n",
      "Data too sparse in Saint Lucia (max_consecutive=10)\n",
      "Data too sparse in Saint Vincent and the Grenadines (max_consecutive=3)\n",
      "Data too sparse in Samoa (max_consecutive=1)\n",
      "There are negatives in San Marino\n",
      "date\n",
      "2020-05-10    -9.0\n",
      "2020-09-05   -19.0\n",
      "Name: San Marino, dtype: float64\n",
      "Data too sparse in San Marino (max_consecutive=11)\n",
      "Data too sparse in Sao Tome and Principe (max_consecutive=12)\n",
      "Spikes in Senegal\n",
      "date   2020-09-15\n",
      "spike  223.000000\n",
      "mean    37.285714\n",
      "zeros    0.000000\n",
      "Data too sparse in Seychelles (max_consecutive=4)\n",
      "Data too sparse in Solomon Islands (max_consecutive=1)\n",
      "Data too sparse in Somalia (max_consecutive=6)\n",
      "Data too sparse in South Sudan (max_consecutive=9)\n",
      "There are negatives in Spain\n",
      "date\n",
      "2020-04-24   -10034.0\n",
      "2020-05-25     -372.0\n",
      "Name: Spain, dtype: float64\n",
      "Spikes in Sri Lanka\n",
      "date   2020-07-10  2020-10-06\n",
      "spike  300.000000  739.000000\n",
      "mean    23.642857   66.857143\n",
      "zeros    0.000000    0.000000\n",
      "Data too sparse in Sudan (max_consecutive=13)\n",
      "There are negatives in Taiwan\n",
      "date\n",
      "2020-08-03   -1.0\n",
      "2020-08-09   -2.0\n",
      "Name: Taiwan, dtype: float64\n",
      "Data too sparse in Tanzania (max_consecutive=5)\n",
      "Spikes in Thailand\n",
      "date   2020-09-28\n",
      "spike   36.000000\n",
      "mean     4.142857\n",
      "zeros    1.000000\n",
      "Data too sparse in Timor (max_consecutive=4)\n",
      "Spikes in Trinidad and Tobago\n",
      "date   2020-03-21\n",
      "spike   40.000000\n",
      "mean     2.428571\n",
      "zeros    2.000000\n",
      "Spikes in Turkey\n",
      "date      2020-12-10\n",
      "spike  823225.000000\n",
      "mean    30826.785714\n",
      "zeros       0.000000\n",
      "There are negatives in Uganda\n",
      "date\n",
      "2020-04-18     -1.0\n",
      "2020-05-21   -104.0\n",
      "Name: Uganda, dtype: float64\n",
      "There are negatives in Uruguay\n",
      "date\n",
      "2020-04-12   -21.0\n",
      "Name: Uruguay, dtype: float64\n",
      "Data too sparse in Vanuatu (max_consecutive=1)\n",
      "Data too sparse in Vatican (max_consecutive=1)\n",
      "Spikes in World\n",
      "date     2020-02-13\n",
      "spike  15153.000000\n",
      "mean    2386.857143\n",
      "zeros      0.000000\n",
      "There are negatives in Yemen\n",
      "date\n",
      "2020-08-11     -1.0\n",
      "2020-12-08   -305.0\n",
      "Name: Yemen, dtype: float64\n",
      "Spikes in Zambia\n",
      "date   2020-07-07\n",
      "spike  263.000000\n",
      "mean     4.571429\n",
      "zeros   12.000000\n",
      "There are negatives in Zimbabwe\n",
      "date\n",
      "2020-05-02   -6.0\n",
      "Name: Zimbabwe, dtype: float64\n",
      "Spikes in Zimbabwe\n",
      "date   2020-09-07\n",
      "spike       461.0\n",
      "mean         47.0\n",
      "zeros         2.0\n",
      "Data too sparse in Andorra (max_consecutive=13)\n",
      "There are negatives in Angola\n",
      "date\n",
      "2020-10-08   -3.0\n",
      "Name: Angola, dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data too sparse in Antigua and Barbuda (max_consecutive=2)\n",
      "Spikes in Argentina\n",
      "date    2020-10-01\n",
      "spike  3351.000000\n",
      "mean    355.928571\n",
      "zeros     0.000000\n",
      "There are negatives in Australia\n",
      "date\n",
      "2020-06-01   -1.0\n",
      "Name: Australia, dtype: float64\n",
      "There are negatives in Austria\n",
      "date\n",
      "2020-07-21   -1.0\n",
      "2020-10-11   -1.0\n",
      "Name: Austria, dtype: float64\n",
      "Data too sparse in Bahamas (max_consecutive=9)\n",
      "Data too sparse in Barbados (max_consecutive=3)\n",
      "There are negatives in Belgium\n",
      "date\n",
      "2020-08-26   -117.0\n",
      "Name: Belgium, dtype: float64\n",
      "Data too sparse in Benin (max_consecutive=3)\n",
      "Spikes in Bolivia\n",
      "date    2020-09-07\n",
      "spike  1656.000000\n",
      "mean     55.142857\n",
      "zeros     1.000000\n",
      "There are negatives in Bosnia and Herzegovina\n",
      "date\n",
      "2020-12-28   -11.0\n",
      "Name: Bosnia and Herzegovina, dtype: float64\n",
      "Data too sparse in Botswana (max_consecutive=1)\n",
      "Data too sparse in Brunei (max_consecutive=1)\n",
      "Data too sparse in Burkina Faso (max_consecutive=5)\n",
      "Data too sparse in Burundi (max_consecutive=1)\n",
      "Data too sparse in Cameroon (max_consecutive=5)\n",
      "Spikes in Canada\n",
      "date   2020-10-02\n",
      "spike   98.000000\n",
      "mean    17.357143\n",
      "zeros    0.000000\n",
      "Data too sparse in Cape Verde (max_consecutive=5)\n",
      "Data too sparse in Central African Republic (max_consecutive=5)\n",
      "Data too sparse in Chad (max_consecutive=6)\n",
      "Spikes in Chile\n",
      "date   2020-06-08   2020-07-17\n",
      "spike  627.000000  1057.000000\n",
      "mean   120.071429    83.928571\n",
      "zeros    0.000000     0.000000\n",
      "Spikes in China\n",
      "date   2020-04-17\n",
      "spike      1290.0\n",
      "mean          0.5\n",
      "zeros        10.0\n",
      "Data too sparse in Comoros (max_consecutive=1)\n",
      "There are negatives in Congo\n",
      "date\n",
      "2020-09-10   -31.0\n",
      "Name: Congo, dtype: float64\n",
      "Data too sparse in Congo (max_consecutive=2)\n",
      "Data too sparse in Cote d'Ivoire (max_consecutive=10)\n",
      "There are negatives in Cuba\n",
      "date\n",
      "2020-08-14   -1.0\n",
      "Name: Cuba, dtype: float64\n",
      "Data too sparse in Cuba (max_consecutive=14)\n",
      "There are negatives in Cyprus\n",
      "date\n",
      "2020-04-05   -2.0\n",
      "2020-11-08   -7.0\n",
      "Name: Cyprus, dtype: float64\n",
      "Data too sparse in Cyprus (max_consecutive=8)\n",
      "There are negatives in Czechia\n",
      "date\n",
      "2020-05-18   -1.0\n",
      "2020-06-11   -2.0\n",
      "2020-06-13   -1.0\n",
      "2020-06-28   -1.0\n",
      "2020-07-04   -2.0\n",
      "2020-07-05   -3.0\n",
      "2020-08-04   -3.0\n",
      "2020-08-07   -1.0\n",
      "Name: Czechia, dtype: float64\n",
      "Data too sparse in Democratic Republic of Congo (max_consecutive=13)\n",
      "There are negatives in Denmark\n",
      "date\n",
      "2020-05-12   -6.0\n",
      "Name: Denmark, dtype: float64\n",
      "Data too sparse in Djibouti (max_consecutive=4)\n",
      "Spikes in Ecuador\n",
      "date    2020-09-07  2020-10-08\n",
      "spike  3852.000000       398.0\n",
      "mean     36.785714        39.5\n",
      "zeros     1.000000         0.0\n",
      "Data too sparse in Equatorial Guinea (max_consecutive=2)\n",
      "Data too sparse in Eritrea (max_consecutive=1)\n",
      "There are negatives in Estonia\n",
      "date\n",
      "2020-08-02   -6.0\n",
      "Name: Estonia, dtype: float64\n",
      "Data too sparse in Eswatini (max_consecutive=8)\n",
      "Data too sparse in Fiji (max_consecutive=1)\n",
      "There are negatives in Finland\n",
      "date\n",
      "2020-04-06   -1.0\n",
      "2020-06-01   -2.0\n",
      "2020-07-15   -1.0\n",
      "2020-09-30   -1.0\n",
      "2020-10-23   -2.0\n",
      "Name: Finland, dtype: float64\n",
      "Spikes in Finland\n",
      "date   2020-04-21\n",
      "spike   43.000000\n",
      "mean     6.928571\n",
      "zeros    0.000000\n",
      "There are negatives in France\n",
      "date\n",
      "2020-05-19   -217.0\n",
      "2020-05-24    -80.0\n",
      "2020-07-05     -1.0\n",
      "2020-07-21    -13.0\n",
      "2020-09-04    -21.0\n",
      "2020-10-25    -21.0\n",
      "2020-11-04    -31.0\n",
      "2020-12-12     -1.0\n",
      "Name: France, dtype: float64\n",
      "Data too sparse in Gabon (max_consecutive=5)\n",
      "Data too sparse in Gambia (max_consecutive=6)\n",
      "There are negatives in Germany\n",
      "date\n",
      "2020-04-11   -31.0\n",
      "2020-07-06    -1.0\n",
      "Name: Germany, dtype: float64\n",
      "Data too sparse in Ghana (max_consecutive=4)\n",
      "Data too sparse in Guinea (max_consecutive=3)\n",
      "Data too sparse in Guinea-Bissau (max_consecutive=1)\n",
      "Data too sparse in Guyana (max_consecutive=10)\n",
      "Data too sparse in Haiti (max_consecutive=6)\n",
      "Data too sparse in Iceland (max_consecutive=3)\n",
      "There are negatives in India\n",
      "date\n",
      "2020-03-21   -1.0\n",
      "Name: India, dtype: float64\n",
      "Spikes in India\n",
      "date    2020-06-16\n",
      "spike  2003.000000\n",
      "mean    357.142857\n",
      "zeros     0.000000\n",
      "Data too sparse in International (max_consecutive=1)\n",
      "There are negatives in Ireland\n",
      "date\n",
      "2020-05-25   -2.0\n",
      "2020-06-01   -2.0\n",
      "2020-07-08   -4.0\n",
      "2020-07-30   -1.0\n",
      "2020-10-02   -5.0\n",
      "2020-12-08   -2.0\n",
      "Name: Ireland, dtype: float64\n",
      "Spikes in Ireland\n",
      "date   2020-04-24\n",
      "spike  220.000000\n",
      "mean    39.928571\n",
      "zeros    0.000000\n",
      "There are negatives in Italy\n",
      "date\n",
      "2020-06-24   -31.0\n",
      "Name: Italy, dtype: float64\n",
      "Spikes in Italy\n",
      "date   2020-08-15\n",
      "spike  158.000000\n",
      "mean     5.857143\n",
      "zeros    0.000000\n",
      "There are negatives in Japan\n",
      "date\n",
      "2020-06-06   -1.0\n",
      "Name: Japan, dtype: float64\n",
      "There are negatives in Kazakhstan\n",
      "date\n",
      "2020-04-04   -1.0\n",
      "Name: Kazakhstan, dtype: float64\n",
      "Spikes in Kazakhstan\n",
      "date   2020-07-20  2020-09-16  2020-11-03  2020-11-25\n",
      "spike       210.0   38.000000   34.000000   49.000000\n",
      "mean          0.0    7.357143    3.071429    4.785714\n",
      "zeros        14.0    0.000000    3.000000    2.000000\n",
      "There are negatives in Kyrgyzstan\n",
      "date\n",
      "2020-08-21   -443.0\n",
      "Name: Kyrgyzstan, dtype: float64\n",
      "Spikes in Kyrgyzstan\n",
      "date   2020-07-18\n",
      "spike  511.688825\n",
      "mean    19.958780\n",
      "zeros    3.000000\n",
      "Data too sparse in Lesotho (max_consecutive=3)\n",
      "Data too sparse in Liberia (max_consecutive=3)\n",
      "There are negatives in Libya\n",
      "date\n",
      "2020-07-30   -3.0\n",
      "Name: Libya, dtype: float64\n",
      "Data too sparse in Liechtenstein (max_consecutive=3)\n",
      "There are negatives in Luxembourg\n",
      "date\n",
      "2020-04-14   -2.0\n",
      "Name: Luxembourg, dtype: float64\n",
      "Data too sparse in Luxembourg (max_consecutive=9)\n",
      "Data too sparse in Malawi (max_consecutive=10)\n",
      "Data too sparse in Maldives (max_consecutive=4)\n",
      "There are negatives in Malta\n",
      "date\n",
      "2020-11-03   -2.0\n",
      "Name: Malta, dtype: float64\n",
      "Data too sparse in Malta (max_consecutive=12)\n",
      "Data too sparse in Mauritius (max_consecutive=3)\n",
      "Spikes in Mexico\n",
      "date    2020-10-05\n",
      "spike  2789.000000\n",
      "mean    337.571429\n",
      "zeros     0.000000\n",
      "There are negatives in Monaco\n",
      "date\n",
      "2020-09-02   -3.0\n",
      "Name: Monaco, dtype: float64\n",
      "Data too sparse in Monaco (max_consecutive=1)\n",
      "Data too sparse in Mongolia (max_consecutive=1)\n",
      "Data too sparse in Mozambique (max_consecutive=11)\n",
      "There are negatives in Netherlands\n",
      "date\n",
      "2020-07-10    -1.0\n",
      "2020-07-14    -2.0\n",
      "2020-07-18    -2.0\n",
      "2020-07-27   -18.0\n",
      "2020-08-11   -16.0\n",
      "Name: Netherlands, dtype: float64\n",
      "Data too sparse in New Zealand (max_consecutive=4)\n",
      "Data too sparse in Nicaragua (max_consecutive=1)\n",
      "Data too sparse in Niger (max_consecutive=6)\n",
      "There are negatives in Nigeria\n",
      "date\n",
      "2020-11-08   -1.0\n",
      "Name: Nigeria, dtype: float64\n",
      "Spikes in Pakistan\n",
      "date   2020-11-19\n",
      "spike  313.000000\n",
      "mean    37.785714\n",
      "zeros    0.000000\n",
      "Data too sparse in Papua New Guinea (max_consecutive=2)\n",
      "Spikes in Peru\n",
      "date    2020-07-23   2020-08-14\n",
      "spike  3887.000000  4143.000000\n",
      "mean    179.428571   176.214286\n",
      "zeros     3.000000     3.000000\n",
      "There are negatives in Philippines\n",
      "date\n",
      "2020-03-19   -2.0\n",
      "Name: Philippines, dtype: float64\n",
      "Data too sparse in Qatar (max_consecutive=12)\n",
      "Data too sparse in Rwanda (max_consecutive=6)\n",
      "Data too sparse in Saint Lucia (max_consecutive=2)\n",
      "Data too sparse in San Marino (max_consecutive=2)\n",
      "Data too sparse in Sao Tome and Principe (max_consecutive=2)\n",
      "There are negatives in Serbia\n",
      "date\n",
      "2020-03-26   -3.0\n",
      "Name: Serbia, dtype: float64\n",
      "Data too sparse in Sierra Leone (max_consecutive=8)\n",
      "Data too sparse in Singapore (max_consecutive=4)\n",
      "There are negatives in Somalia\n",
      "date\n",
      "2020-09-04   -1.0\n",
      "Name: Somalia, dtype: float64\n",
      "Data too sparse in Somalia (max_consecutive=6)\n",
      "Data too sparse in South Sudan (max_consecutive=4)\n",
      "There are negatives in Spain\n",
      "date\n",
      "2020-05-25   -1918.0\n",
      "2020-08-12      -2.0\n",
      "Name: Spain, dtype: float64\n",
      "Spikes in Spain\n",
      "date    2020-06-19\n",
      "spike  1179.000000\n",
      "mean      1.642857\n",
      "zeros     7.000000\n",
      "Data too sparse in Sudan (max_consecutive=10)\n",
      "Data too sparse in Suriname (max_consecutive=8)\n",
      "There are negatives in Sweden\n",
      "date\n",
      "2020-08-31   -13.0\n",
      "2020-10-06   -12.0\n",
      "Name: Sweden, dtype: float64\n",
      "There are negatives in Switzerland\n",
      "date\n",
      "2020-10-21   -106.0\n",
      "Name: Switzerland, dtype: float64\n",
      "Data too sparse in Taiwan (max_consecutive=1)\n",
      "There are negatives in Tajikistan\n",
      "date\n",
      "2020-12-13   -1.0\n",
      "Name: Tajikistan, dtype: float64\n",
      "Data too sparse in Tajikistan (max_consecutive=6)\n",
      "Data too sparse in Tanzania (max_consecutive=2)\n",
      "Data too sparse in Togo (max_consecutive=4)\n",
      "Data too sparse in Trinidad and Tobago (max_consecutive=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data too sparse in Uganda (max_consecutive=9)\n",
      "Data too sparse in Uruguay (max_consecutive=10)\n",
      "There are negatives in Venezuela\n",
      "date\n",
      "2020-05-01   -6.0\n",
      "Name: Venezuela, dtype: float64\n",
      "There are negatives in Vietnam\n",
      "date\n",
      "2020-08-19   -1.0\n",
      "Name: Vietnam, dtype: float64\n",
      "Data too sparse in Vietnam (max_consecutive=7)\n",
      "There are negatives in Yemen\n",
      "date\n",
      "2020-12-08   -43.0\n",
      "Name: Yemen, dtype: float64\n",
      "Spikes in Yemen\n",
      "date   2020-07-12\n",
      "spike   48.394910\n",
      "mean     3.722685\n",
      "zeros    0.000000\n",
      "Spikes in Zambia\n",
      "date   2020-07-17\n",
      "spike   67.000000\n",
      "mean     1.928571\n",
      "zeros   10.000000\n",
      "Data too sparse in Zimbabwe (max_consecutive=12)\n"
     ]
    }
   ],
   "source": [
    "# make adjustments to the data\n",
    "CASES = 0\n",
    "DEATHS = 1\n",
    "modes = {\n",
    "    'Cases': CASES,\n",
    "    'Deaths': DEATHS,\n",
    "}\n",
    "raw_cum_data = [raw_cum_cases, raw_cum_deaths]\n",
    "raw_daily_data = [None, None]\n",
    "adj_daily_data = [None, None]\n",
    "adj_cum_data = [None, None]\n",
    "\n",
    "data_quality = [None, None]\n",
    "\n",
    "for mode, index in modes.items():\n",
    "    \n",
    "    # adjust raw data for anomalies\n",
    "    (raw_daily_data[index], \n",
    "        adj_daily_data[index], \n",
    "        adj_cum_data[index]) = ps.dataframe_correction(\n",
    "                                    raw_cum_data[index])\n",
    "\n",
    "    # identify whether the adjustment for anomalies \n",
    "    # changed the data\n",
    "    data_quality[index] = pd.Series(None, \n",
    "                            index=raw_cum_data[index].columns,\n",
    "                            dtype='str')\n",
    "    for col in raw_cum_data[index].columns:\n",
    "        if (raw_daily_data[index][col] == \n",
    "            adj_daily_data[index][col]).all():\n",
    "            data_quality[index][col] = (f'{SOURCE}; original data')\n",
    "        else:\n",
    "            data_quality[index][col] = (f'{SOURCE}, '\n",
    "                            'data adjusted for extreme outliers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## International comparisons - maps/leader-boards/swarms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### supporting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_million_population(population: pd.Series, power:int = 6):\n",
    "    \"\"\"Take a population series and a power and return in a tuple:\n",
    "       - the power\n",
    "       - the factor (which is 10 ** power)\n",
    "       - an updated population series (which is population / factor)\"\"\"\n",
    "    \n",
    "    factor = 10 ** power\n",
    "    return power, factor, population / factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rear_offsets(dataframe, period):\n",
    "    \"\"\"Get offset to last non-zero values in dataframe by col\n",
    "       provided offset is within period, otherwise zero offset\n",
    "       [We do this becuase some nations are slow in reporting,\n",
    "       and without this adjustment late reporting nations would \n",
    "       look better than they actually are.]\"\"\"\n",
    "    \n",
    "    nrows = len(dataframe)\n",
    "    rear_offsets = pd.Series(0, index=dataframe.columns)\n",
    "    for col in dataframe.columns:\n",
    "        index_array = (np.nonzero(dataframe[col].to_numpy()))[0]\n",
    "        if len(index_array) > 0:\n",
    "            last = index_array[-1]\n",
    "            rear_offsets[col] = nrows - last - 1\n",
    "            # Note: rear_offsets[col] is 0 if len(index_array) == 0\n",
    "    rear_offsets = rear_offsets.where(rear_offsets<=period, other=0)\n",
    "    return rear_offsets\n",
    "\n",
    "def get_recent_total(dataframe, rear_offsets, period):\n",
    "    \"\"\"Sum the last rows of a dataframe, making adjustments\n",
    "       for zero rows at the very end\"\"\"\n",
    "    \n",
    "    daily_sum = pd.Series(0.0, index=dataframe.columns)\n",
    "    for col in dataframe.columns:\n",
    "        p = 0 - (period+rear_offsets[col])\n",
    "        daily_sum[col] = dataframe[col].iloc[p:].sum()\n",
    "    return daily_sum\n",
    "\n",
    "def get_larger_nations(population, thresh=100_000):\n",
    "    \"\"\"return a list of nations with a population exceeding thresh\"\"\"\n",
    "    \n",
    "    return population[population >= thresh].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_comapative(mode, index, data, population):\n",
    "\n",
    "    PERIOD = 7 # days (recent data period for daily averages)\n",
    "    THRESH = 100_000 # people (minimum nation size for plotting)\n",
    "    \n",
    "    # drop World\n",
    "    if 'World' in data.columns:\n",
    "        del data['World']\n",
    "    if 'World' in population.index:\n",
    "        population.drop(labels='World', inplace=True)\n",
    "\n",
    "    keepers = get_larger_nations(population, THRESH)\n",
    "    power, factor, pop_millions =  per_million_population(population)\n",
    "\n",
    "    # cumulative data\n",
    "    cumulative = data.sum()\n",
    "    cumulative_percapita = (cumulative / pop_millions)[keepers]\n",
    "    log_cumulative_percapita = np.log(cumulative_percapita + 1)\n",
    "\n",
    "    # latest daily average data\n",
    "    rear_offsets = get_rear_offsets(data, PERIOD)\n",
    "    daily_ave = (get_recent_total(data, rear_offsets, PERIOD) / PERIOD)\n",
    "    daily_ave_percapita = (daily_ave / pop_millions)[keepers]\n",
    "    log_daily_ave_percapita = np.log(daily_ave_percapita + 1)\n",
    "\n",
    "    return (power, THRESH, PERIOD, cumulative, cumulative_percapita, \n",
    "            log_cumulative_percapita, daily_ave, \n",
    "            daily_ave_percapita, log_daily_ave_percapita)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar charts of top performers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cases\n",
      "Deaths\n"
     ]
    }
   ],
   "source": [
    "if True: # switch this output on/off\n",
    "    \n",
    "    BAR_N = 40 # maximum bars on chart\n",
    "    BAR_PLOT_SIZE = (8, 8)\n",
    "\n",
    "    for mode, index in modes.items():\n",
    "        print(mode)\n",
    "\n",
    "        # get the data\n",
    "        (power, THRESH, PERIOD, cumulative, cumulative_percapita, \n",
    "            log_cumulative_percapita, daily_ave, \n",
    "            daily_ave_percapita, log_daily_ave_percapita) = (\n",
    "            get_data_for_comapative(mode, index, \n",
    "                                    adj_daily_data[index].copy(),\n",
    "                                    population.copy())\n",
    "        )\n",
    "        lfooter = f'For nations with a population >= {THRESH:,}'\n",
    "        \n",
    "        # bar charts\n",
    "        # - bar chart of the top cumulative performers\n",
    "        top_tier = (cumulative.dropna()\n",
    "                    .sort_values(ascending=True)[-BAR_N:])\n",
    "        series = np.round(top_tier.copy(), 0).astype(int)\n",
    "        ps.plot_barh(\n",
    "            series=series, \n",
    "            title=(f'COVID-19: Top cumulative {mode.lower()}'),\n",
    "            xlabel=(f'Cumulative {mode.lower()}'),\n",
    "            lfooter=lfooter, rfooter=SOURCE,\n",
    "            set_size_inches=BAR_PLOT_SIZE,\n",
    "            chart_directory=CHART_DIRECTORY + I_PREFIX,\n",
    "        )\n",
    "\n",
    "        # - bar chart of the top cumulative performers per capita\n",
    "        top_tier = (cumulative_percapita.dropna()\n",
    "                    .sort_values(ascending=True)[-BAR_N:])\n",
    "        series = np.round(top_tier.copy(), 1)\n",
    "        ps.plot_barh(\n",
    "            series=series, \n",
    "            title=(f'COVID-19: Top cumulative {mode.lower()} per capita'),\n",
    "            xlabel=(f'Cumulative {mode.lower()} per '\n",
    "                    f'$10^{power}$ population'),\n",
    "            lfooter=lfooter, rfooter=SOURCE,\n",
    "            set_size_inches=BAR_PLOT_SIZE,\n",
    "            chart_directory=CHART_DIRECTORY + I_PREFIX,\n",
    "        )\n",
    "\n",
    "        # - bar chart of the top daily averages - past week\n",
    "        top_tier = (daily_ave.dropna()\n",
    "                    .sort_values(ascending=True)[-BAR_N:])\n",
    "        series = np.round(top_tier.copy(), 1)\n",
    "        ps.plot_barh(\n",
    "            series=series,\n",
    "            title=(f'COVID-19: Top {mode.lower()} - '\n",
    "                  f'past {PERIOD} days'),\n",
    "            xlabel=(f'Average daily {mode.lower()}'),\n",
    "            lfooter=lfooter, rfooter=SOURCE,\n",
    "            set_size_inches=BAR_PLOT_SIZE,\n",
    "            chart_directory=CHART_DIRECTORY + I_PREFIX,\n",
    "        ) \n",
    "        \n",
    "        # - bar chart of the top daily averages per capita\n",
    "        top_tier = (daily_ave_percapita.dropna()\n",
    "                    .sort_values(ascending=True)[-BAR_N:])\n",
    "        series = np.round(top_tier.copy(), 1)\n",
    "        ps.plot_barh(\n",
    "            series=series,\n",
    "            title=(f'COVID-19: Top {mode.lower()} per capita - '\n",
    "                  f'past {PERIOD} days'),\n",
    "            xlabel=(f'Average daily {mode.lower()} per '\n",
    "                    f'$10^{power}$ population'),\n",
    "            lfooter=lfooter, rfooter=SOURCE,\n",
    "            set_size_inches=BAR_PLOT_SIZE,\n",
    "            chart_directory=CHART_DIRECTORY + I_PREFIX,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_world(series, title, legend_title, source):\n",
    "    \n",
    "    # prepare data for mapping\n",
    "    name_map(series, iso_name_map)\n",
    "    score = pd.DataFrame(series) # back to DataFrame\n",
    "    score.columns = ['Score']\n",
    "    score['country'] = score.index\n",
    "    score['code'] = [iso3166.countries.get(x.upper())[2] \n",
    "                     for x in score['country']]\n",
    "    \n",
    "    # get map data\n",
    "    shapefile = ('../geo-data/ne_110m_admin_0_countries/'\n",
    "        'ne_110m_admin_0_countries.shp')\n",
    "    gdf = gpd.read_file(shapefile)[['ADMIN', 'ADM0_A3', 'geometry']]\n",
    "    gdf.columns = ['country', 'country_code', 'geometry']\n",
    "    gdf = gdf[gdf['country'] != 'Antarctica'] \n",
    "    \n",
    "    merged = gdf.merge(score,\n",
    "                       left_on='country_code', \n",
    "                       right_on='code', how='left')\n",
    "\n",
    "    variable = 'Score'\n",
    "    cmap = mpl.cm.get_cmap('viridis').reversed()\n",
    "    cmap.set_bad('white')\n",
    "    cmap.set_under('white')\n",
    "    ax = merged.plot(column=variable, cmap=cmap, legend=False)\n",
    "    \n",
    "    # colorbar\n",
    "    world_map = ax.collections[0]\n",
    "    cb = plt.colorbar(world_map, ax=ax, orientation='horizontal')\n",
    "    \n",
    "    # legend title\n",
    "    fig = ax.figure\n",
    "    fig.text(0.5, 0.175, legend_title,\n",
    "        ha='center', va='bottom',\n",
    "        fontsize=12, # fontstyle='italic',\n",
    "        color='#222222')\n",
    "    \n",
    "    ps.finalise_plot(ax, title=title,\n",
    "                     xticklabels=[], yticklabels=[],\n",
    "                     xticks=[], yticks=[],\n",
    "                     rfooter=source,\n",
    "                     set_size_inches=(8,5),\n",
    "                     save_as=f'{CHART_DIRECTORY}'\n",
    "                             f'{I_PREFIX}MAP-{title}.png',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cases\n",
      "Deaths\n"
     ]
    }
   ],
   "source": [
    "if True: # switch this output on/off\n",
    "    \n",
    "    for mode, index in modes.items():\n",
    "        print(mode)\n",
    "\n",
    "        # get the data\n",
    "        (power, THRESH, PERIOD, cumulative, cumulative_percapita, \n",
    "            log_cumulative_percapita, daily_ave, \n",
    "            daily_ave_percapita, log_daily_ave_percapita) = (\n",
    "            get_data_for_comapative(mode, index, \n",
    "                                    adj_daily_data[index].copy(),\n",
    "                                    population.copy())\n",
    "        )\n",
    "        \n",
    "        # world maps\n",
    "        # - world map - cumulative per capita\n",
    "        title = f'COVID-19 Cumulative {mode.lower()} per capita'\n",
    "        legend = (f'Cumulative {mode.lower()} per '\n",
    "                  f'$10^{power}$ population')\n",
    "        map_world(cumulative_percapita.copy(), title, legend, SOURCE)\n",
    "\n",
    "        # - world map - cumulative per capita - log scale\n",
    "        title = (f'COVID-19 Cumulative {mode.lower()} per capita '\n",
    "                 f'(log scale)')\n",
    "        legend = (f'log((cumulative {mode.lower()} per '\n",
    "                  f'$10^{power}$ pop.) + 1)')\n",
    "        map_world(log_cumulative_percapita.copy(), title, legend, SOURCE)\n",
    "        \n",
    "        # - world map - average daily per capita past PERIOD days\n",
    "        title = (f'COVID-19 Ave. daily {mode.lower()} per capita '\n",
    "             f'- past {PERIOD} days')\n",
    "        legend = (f'Ave. daily {mode.lower()} per '\n",
    "                  f'$10^{power}$ population')\n",
    "        map_world(daily_ave_percapita.copy(), title, legend, SOURCE)\n",
    "\n",
    "        # - world map - average daily per capita past PERIOD days - log scale\n",
    "        title = (f'COVID-19 Ave. daily {mode.lower()} per capita '\n",
    "             f'- past {PERIOD} days (log scale)')\n",
    "        legend = (f'log((average daily {mode.lower()} per '\n",
    "              f'$10^{power}$-population) + 1)')\n",
    "        map_world(log_daily_ave_percapita.copy(), title, legend, SOURCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swarm plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swarm(data: pd.Series,\n",
    "          title=\"Don't forget the title\",\n",
    "          ylabel=\"Don't forget the ylabel\",\n",
    "          source=\"Don't forget the source\",\n",
    "          color='cornflowerblue'):\n",
    "    \"\"\"Produce a swarm plot from the following input:\n",
    "        - data - a pandas Series of values, with an index of nations\n",
    "        - title - plot title\n",
    "        - ylabel - label for the y axis\n",
    "        - source - string for data source - becomes right footer\n",
    "        - color - colour of swarm plot dots\n",
    "       \"\"\"\n",
    "    \n",
    "    DEFAULT_SIZE = (8, 6)\n",
    "    \n",
    "    # get country information\n",
    "    wbd = pd.read_excel('../data/CLASS.xls', header=4, index_col=0, \n",
    "                        ).iloc[1:219].dropna(how='all', axis=1)\n",
    "    mapping = wbd['Income group']\n",
    "    mapping.index = wbd['Code']\n",
    "    \n",
    "    # prepare for plot\n",
    "    name_map(data, iso_name_map)\n",
    "    data = pd.DataFrame(data)\n",
    "    data.columns = ['Rate']\n",
    "    data['alpha3'] = [iso3166.countries.get(x).alpha3 for x in data.index]\n",
    "    data['alpha2'] = [iso3166.countries.get(x).alpha2 for x in data.index]\n",
    "    data['Income Group'] = data.alpha3.map(mapping)\n",
    "    data = data[data['Income Group'].notna()]\n",
    "    \n",
    "    # labels \n",
    "    data['alpha2'] = data['alpha2'].where(data['alpha2'].notna(), other='')\n",
    "    \n",
    "    # swarm plot\n",
    "    # - set up\n",
    "    categories = ['Low income', 'Lower middle income',\n",
    "                  'Upper middle income', 'High income']\n",
    "    # - plot\n",
    "    fig, ax = plt.subplots(figsize=DEFAULT_SIZE)\n",
    "    ax.margins(0.02)\n",
    "    sns.swarmplot(x='Income Group',\n",
    "                  y='Rate', \n",
    "                  data=data, \n",
    "                    size=10,\n",
    "                       dodge=True, \n",
    "                       color=color, alpha=0.5,\n",
    "                       order=categories,\n",
    "                       ax=ax)\n",
    "    \n",
    "    # - point annotation - this is one ugly hack\n",
    "    for collect, name in zip(ax.collections, categories):\n",
    "        \n",
    "        # retrieve positional data from plot\n",
    "        retrieved_xy_pairs = collect.get_offsets()\n",
    "        \n",
    "        # build an xy map with duplicate keys\n",
    "        THRESH = 7\n",
    "        dup_map = {}\n",
    "        for x, y in retrieved_xy_pairs:\n",
    "            yy = np.round(y, THRESH)\n",
    "            if yy in dup_map:\n",
    "                dup_map[yy].append(x)\n",
    "            else:\n",
    "                dup_map[yy] = [x]\n",
    "        \n",
    "        # use this map to plot in the data labels\n",
    "        for index, row in data[data['Income Group'] == name].iterrows():\n",
    "            lookup = np.round(row['Rate'], THRESH)\n",
    "            if lookup in dup_map:\n",
    "               ax.text(dup_map[lookup].pop(), row['Rate'], row['alpha2'],\n",
    "                       ha='center', va='center', fontsize='xx-small', \n",
    "                        color='#333333')\n",
    "        \n",
    "    ps.finalise_plot(ax, title=title,\n",
    "                     xlabel=None, ylabel=ylabel,\n",
    "                     rfooter=SOURCE,\n",
    "                     set_size_inches=DEFAULT_SIZE,\n",
    "                     chart_directory=CHART_DIRECTORY\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryanpalmer/anaconda3/lib/python3.8/site-packages/seaborn/categorical.py:1296: UserWarning: 67.9% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/bryanpalmer/anaconda3/lib/python3.8/site-packages/seaborn/categorical.py:1296: UserWarning: 35.4% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/bryanpalmer/anaconda3/lib/python3.8/site-packages/seaborn/categorical.py:1296: UserWarning: 13.2% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/bryanpalmer/anaconda3/lib/python3.8/site-packages/seaborn/categorical.py:1296: UserWarning: 67.9% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/bryanpalmer/anaconda3/lib/python3.8/site-packages/seaborn/categorical.py:1296: UserWarning: 50.0% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/bryanpalmer/anaconda3/lib/python3.8/site-packages/seaborn/categorical.py:1296: UserWarning: 6.0% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deaths\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryanpalmer/anaconda3/lib/python3.8/site-packages/seaborn/categorical.py:1296: UserWarning: 60.7% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/bryanpalmer/anaconda3/lib/python3.8/site-packages/seaborn/categorical.py:1296: UserWarning: 31.0% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/bryanpalmer/anaconda3/lib/python3.8/site-packages/seaborn/categorical.py:1296: UserWarning: 64.3% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/bryanpalmer/anaconda3/lib/python3.8/site-packages/seaborn/categorical.py:1296: UserWarning: 50.0% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/bryanpalmer/anaconda3/lib/python3.8/site-packages/seaborn/categorical.py:1296: UserWarning: 8.5% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/bryanpalmer/anaconda3/lib/python3.8/site-packages/seaborn/categorical.py:1296: UserWarning: 17.0% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/bryanpalmer/anaconda3/lib/python3.8/site-packages/seaborn/categorical.py:1296: UserWarning: 50.0% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/bryanpalmer/anaconda3/lib/python3.8/site-packages/seaborn/categorical.py:1296: UserWarning: 19.0% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "if True: # switch this output on/off\n",
    "    \n",
    "    for mode, index in modes.items():\n",
    "        print(mode)\n",
    "\n",
    "        # get the data\n",
    "        (power, THRESH, PERIOD, cumulative, cumulative_percapita, \n",
    "            log_cumulative_percapita, daily_ave, \n",
    "            daily_ave_percapita, log_daily_ave_percapita) = (\n",
    "            get_data_for_comapative(mode, index, \n",
    "                                    adj_daily_data[index].copy(),\n",
    "                                    population.copy())\n",
    "        )\n",
    "        \n",
    "        # swarm plots\n",
    "        # - swarm plot of cumulative per capita\n",
    "        title = f'COVID-19 Cumulative {mode.lower()} per capita'\n",
    "        ylabel = (f'Cumulative {mode.lower()} per '\n",
    "                  f'$10^{power}$ population')\n",
    "        swarm(cumulative_percapita.dropna().copy(), title, \n",
    "              ylabel, SOURCE, color='darkorchid')        \n",
    "        \n",
    "        # - swarm plot of cumulative per capita - log scale\n",
    "        log_cumulative_percapita = np.log(cumulative_percapita + 1)\n",
    "        title = f'COVID-19 Cumulative {mode.lower()} per capita (log scale)'\n",
    "        ylabel = (f'log((cumulative {mode.lower()} per '\n",
    "                  f'$10^{power}$ pop.) + 1)')\n",
    "        swarm(log_cumulative_percapita.dropna().copy(), title, \n",
    "              ylabel, SOURCE, color='hotpink')\n",
    "        \n",
    "        # - swarm plot of daily average per capita past PERIOD days\n",
    "        title = (f'COVID-19 Ave. daily {mode.lower()} per capita '\n",
    "             f'- past {PERIOD} days')\n",
    "        ylabel = (f'Ave. daily {mode.lower()} per '\n",
    "                 f'$10^{power}$ population')\n",
    "        swarm(daily_ave_percapita.dropna().copy(), title, \n",
    "              ylabel, SOURCE)\n",
    "        \n",
    "        # - swarm plot of daily average per capita past PERIOD days - log scale\n",
    "        title = (f'COVID-19 Ave. daily {mode.lower()} per capita '\n",
    "             f'- past {PERIOD} days (log scale)')\n",
    "        ylabel = (f'log((ave. daily {mode.lower()} per '\n",
    "                 f'$10^{power}$ pop.) + 1)')\n",
    "        swarm(log_daily_ave_percapita.dropna().copy(), title, \n",
    "              ylabel, SOURCE, color='darkorange')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-log comparison plots of cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_semi_log_trajectory(data, mode, threshold, selections, source):\n",
    "    \"\"\"Produce semi-log plots of cumulative data from the \n",
    "       following inputs:\n",
    "        - data - a pandas dataframe of cumulative data\n",
    "        - mode - a string, either 'Cases' or 'Deaths'\n",
    "        - threshold - starting point (eg. 100th case)\n",
    "        - selections - a python dictionary of \n",
    "         'grouping': ['list', 'of', 'nations'], pairs\n",
    "        - source - string for data source\n",
    "       \"\"\"\n",
    "    \n",
    "    styles = ['-'] #, '--', '-.', ':'] # 4 lines \n",
    "    markers = list('PXo^v<>D*pH.d') # 13 markers\n",
    "    colours = ['blue', 'red', 'maroon', 'darkorange', 'brown', \n",
    "               'olivedrab', 'darkgoldenrod', 'green',  \n",
    "               'purple', 'black', 'teal'] # 11 colours\n",
    "\n",
    "    for tag, nation_list in selections.items():\n",
    "    \n",
    "        # set up for the plot\n",
    "        ax = plt.subplot(111,)\n",
    "\n",
    "        # add the data\n",
    "        endpoints = pd.DataFrame()\n",
    "        nation_list.sort()\n",
    "        for i, name in enumerate(nation_list):\n",
    "            if name not in data.columns:\n",
    "                print(f'{name} is not in data')\n",
    "                continue\n",
    "            y = data[name]\n",
    "            y.index = range(len(y))\n",
    "            start = y[y >= threshold]\n",
    "            if len(start) < 5:\n",
    "                continue\n",
    "            start = start.index[0] - 1\n",
    "            if start < 0:\n",
    "                start = 0\n",
    "            y = y[start:].values\n",
    "            x = range(-1, len(y) - 1)\n",
    "            \n",
    "            # plot line\n",
    "            code = get_national_code(name)\n",
    "            label = f'{name} ({code}) {int(y[-1]):,}'\n",
    "            color = colours[i % len(colours)]\n",
    "            ax.plot(x, y, label=label,\n",
    "                    color=color,)\n",
    "            \n",
    "            # plot end text\n",
    "            endpoints = endpoints.append(\n",
    "                pd.Series([x[-1], y[-1], f'{code}', color],\n",
    "                          index=['x', 'y', 'code', 'color'],\n",
    "                          name=name))\n",
    "\n",
    "        # add endpoint labels \n",
    "        EXPANSION = 0.02\n",
    "        additional = endpoints.x.max() * EXPANSION\n",
    "        for row in endpoints.itertuples(): \n",
    "            ax.text(x=row.x+additional, y=row.y, s=row.code,\n",
    "                    size='small', color='black',\n",
    "                    ha='left', va='center',\n",
    "                    bbox={'alpha':0.5, 'facecolor':'white'})\n",
    "\n",
    "        # etc.\n",
    "        min_, max_ = ax.get_xlim()\n",
    "        max_ = max_ + (max_ * EXPANSION)\n",
    "        ax.set_xlim(min_, max_)\n",
    "        ax.legend(loc='lower right', fontsize='8', ncol=3)\n",
    " \n",
    "        ps.finalise_plot(ax,\n",
    "                         title='COVID-19 Semilog plot of selected '\n",
    "                               f'{mode.lower()[:-1]} trajectories',\n",
    "                         xlabel='Days from the notional '\n",
    "                                f'{int(threshold)}th {mode.lower()[:-1]}',\n",
    "                         ylabel=f'Cumulative {mode} (log scale)',\n",
    "                         yscale='log',\n",
    "                         rfooter=source,\n",
    "                         set_size_inches=(8,6),\n",
    "                         chart_directory=CHART_DIRECTORY+I_PREFIX,\n",
    "                         save_tag=tag,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cases\n",
      "Deaths\n",
      "Timor is not in data\n"
     ]
    }
   ],
   "source": [
    "if True: # switch this output on/off\n",
    "\n",
    "    selections = {\n",
    "        'Anglophone':  ['Australia', 'United States', 'Canada', \n",
    "                        'United Kingdom', 'New Zealand', 'Ireland', ],\n",
    "        'Neighbours':  ['Australia', 'New Zealand', 'Papua New Guinea',\n",
    "                        'Indonesia', 'Singapore', 'Malaysia', #'Brunei',\n",
    "                        'Timor', 'China', 'Japan', 'South Korea', 'India'],\n",
    "        \"SelectedEurope\":['Austria', 'Belgium', 'Denmark', \n",
    "                        'France', 'Germany', 'Greece', 'Italy', 'Netherlands', \n",
    "                        'Norway', 'Poland', 'Portugal', 'Russia', 'Spain',  \n",
    "                        'Sweden', 'Switzerland', 'United Kingdom', ],\n",
    "        \"EU-v-US\":     ['United States', \"European Union\"],\n",
    "        \"Italy-v-UK\":  ['Italy', \"United Kingdom\"]\n",
    "    }\n",
    "    \n",
    "    # https://europa.eu/european-union/about-eu/countries_en\n",
    "    EU = [\n",
    "        'Austria', 'Belgium', 'Bulgaria', 'Croatia', \n",
    "        'Cyprus', 'Czechia', 'Denmark',\n",
    "        'Estonia', 'Finland', 'France', 'Germany',\n",
    "        'Greece', 'Hungary', 'Ireland', 'Italy',\n",
    "        'Latvia', 'Lithuania', 'Luxembourg', 'Malta', \n",
    "        'Netherlands', 'Poland', 'Portugal', 'Romania', \n",
    "        'Slovakia', 'Slovenia', 'Spain', 'Sweden', \n",
    "    ]\n",
    "    assert(len(EU) == 27) \n",
    "    \n",
    "    # for cases then deaths ...\n",
    "    for mode, index in modes.items():\n",
    "        print(mode)\n",
    "        cumulative = adj_cum_data[index].copy()\n",
    "        if 'World' in cumulative.columns:\n",
    "            del cumulative['World']\n",
    "        cumulative[\"European Union\"] = cumulative[EU].sum(axis=1)\n",
    "        \n",
    "        # include top N nations as a chart\n",
    "        N = 9\n",
    "        top = cumulative.iloc[-1].dropna().sort_values(ascending=False)[:N]\n",
    "        selections['Top'] = top.index.to_list()\n",
    "        \n",
    "        # and plot\n",
    "        thresh = 100 if mode.lower() == 'cases' else 10\n",
    "        plot_semi_log_trajectory(cumulative, mode, thresh, \n",
    "                                 selections, f'Source: {source}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison plots of daily new per capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_daily_comparative(data, population, mode, regions, source, period=14):\n",
    "    \"\"\"Produce daily plots highlighting new cases/deaths for a \n",
    "       specific set of nations against a backdrop of all nations.\n",
    "    Inputs:\n",
    "        - data - pandas DataFrame of daily new cases/deaths\n",
    "        - population - pandas Series of national populations \n",
    "        - mode - string - either \"cases\" or \"deaths\"\n",
    "        - regions - python list of lists of strings \n",
    "          (nation names - same as columns in data)\n",
    "        - source - string for data source\n",
    "        - period - period for the rolling average \"\"\"\n",
    "    \n",
    "    # set-up\n",
    "    colours = ['blue', 'red', 'maroon', 'darkorange', 'brown', \n",
    "               'olivedrab', 'darkgoldenrod', 'green',  \n",
    "               'purple', 'black', 'teal'] # 11 colours\n",
    "    power, factor, pop_millions =  per_million_population(population)\n",
    "    keepers = get_larger_nations(population, 100_000) # used for backgrounds\n",
    "\n",
    "    # get rolling average per capita from start date\n",
    "    df = data.rolling(period).mean().div(other=pop_millions)\n",
    "    df = df[df.index >= pd.Timestamp('2020-02-01')]\n",
    "\n",
    "    for region_list in regions:\n",
    "    \n",
    "        # plot background\n",
    "        ax = df[keepers].plot(c='#aaaaaa', lw=0.5)\n",
    "        ax.get_legend().remove()\n",
    "\n",
    "        # plot highlighted regions\n",
    "        region_list.sort()\n",
    "        ax_new = ax.twinx()        \n",
    "        for i, name in enumerate(region_list):\n",
    "            df[name].plot(c=colours[i], label=name, lw=2.5, ax=ax_new)\n",
    "        ax_new.legend(title=None, loc=\"upper left\")\n",
    "        ax_new.grid(False)\n",
    "        ax_new.set_yticklabels([])\n",
    "        ax_new.set_ylim(ax.get_ylim())\n",
    "\n",
    "        ps.finalise_plot(ax,\n",
    "                      title=f'COVID-19 Daily New {mode.title()}',\n",
    "                      xlabel=None,\n",
    "                      ylabel=f'Daily new {mode.lower()} per $10^{power}$ '\n",
    "                              f'population\\n{period}-day rolling average',\n",
    "                      rfooter=source,\n",
    "                      set_size_inches=(8, 5),\n",
    "                      save_as=f'{CHART_DIRECTORY}{I_PREFIX}'\n",
    "                              f'daily-{mode}-{\" \".join(region_list)}',\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populations:\n",
      "United States: 331,002,647\n",
      "European Union: 444,919,060\n",
      "\n",
      "Cases\n",
      "Deaths\n"
     ]
    }
   ],
   "source": [
    "if True: # switch this output on/off\n",
    "\n",
    "    # identify the regional sets to be plotted\n",
    "    regions = [\n",
    "        ['European Union', 'United States'],\n",
    "        ['Belgium', 'Ireland', 'Netherlands', 'United Kingdom', 'Iceland'],\n",
    "        ['France', 'Italy', 'Portugal', 'Spain'],\n",
    "        ['Denmark', 'Norway', 'Sweden', 'Austria', 'Germany', 'Switzerland'], \n",
    "        ['Finland', 'Estonia', 'Latvia', 'Lithuania', 'Poland'],\n",
    "        ['Belarus', 'Russia', 'Ukraine', 'Romania', 'Bulgaria', 'Moldova', ],\n",
    "        ['Czechia', 'Slovakia', 'Hungary', 'Slovenia'],\n",
    "        ['Croatia', 'Bosnia and Herzegovina', 'Montenegro',\n",
    "            'Serbia', 'Kosovo', 'Albania', 'North Macedonia', 'Greece'],\n",
    "        ['Turkey', 'Syria', 'Lebanon', 'Israel', 'Jordan', \n",
    "             'Egypt', 'Libya', 'Cyprus'],\n",
    "        ['Georgia', 'Armenia', 'Azerbaijan'],\n",
    "        ['Iraq', 'Iran', 'Saudi Arabia', 'Bahrain', 'Qatar', \n",
    "            'United Arab Emirates', 'Kuwait', 'Yemen', 'Oman',], \n",
    "        ['Ghana', 'Ethiopia', 'Kenya', \n",
    "             'Nigeria', 'South Africa', 'Tanzania'],\n",
    "        ['Afghanistan', 'Kazakhstan', 'Kyrgyzstan', 'Pakistan', \n",
    "            'Tajikistan', 'Uzbekistan', ],\n",
    "        ['Bangladesh', 'Nepal', 'India', 'Sri Lanka'], \n",
    "        ['Indonesia', 'Malaysia', 'Philippines', 'Singapore', 'Thailand'],\n",
    "        ['China', 'Japan', 'South Korea', 'Taiwan', 'Vietnam'],\n",
    "        ['Australia', 'New Zealand', 'Papua New Guinea', 'Timor'], \n",
    "        ['Canada', 'Mexico', 'United States'], \n",
    "        ['Costa Rica', 'Guatemala', 'Honduras', 'Nicaragua', 'Panama'], \n",
    "        ['Argentina', 'Brazil', 'Chile', 'Colombia', 'Ecuador', \n",
    "            'Peru', 'Venezuela'], \n",
    "        ['Cuba', 'Dominican Republic', 'Haiti', 'Jamaica'],\n",
    "    ]\n",
    "\n",
    "    # And population for European Union\n",
    "    pop = population.copy()\n",
    "    pop['European Union'] = pop[EU].sum()\n",
    "    # FYI only ...\n",
    "    print('Populations:\\n'\n",
    "          f'United States: {int(pop[\"United States\"]):,}\\n'\n",
    "          f'European Union: {int(pop[\"European Union\"]):,}\\n')\n",
    "\n",
    "    # for cases then deaths ...\n",
    "    for mode, index in modes.items():\n",
    "        print(mode)\n",
    "        daily = adj_daily_data[index].copy()\n",
    "        daily['European Union'] = daily[EU].sum(axis=1)\n",
    "        plot_daily_comparative(daily, pop, mode, regions, SOURCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot weekly new-case/deaths data from January 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True: # switch this output on/off\n",
    "    adj_weekly_data = [None, None]\n",
    "    for (mode, index) in modes.items():\n",
    "        daily = adj_daily_data[index].copy()\n",
    "        adj_weekly_data[index] = ps.plot_weekly(daily, \n",
    "                                    mode.lower(), \n",
    "                                    data_quality[index],\n",
    "                                    chart_directory=CHART_DIRECTORY,\n",
    "                                    save_tag='weekly',\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot new-vs-cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True: # switch this output on/off\n",
    "\n",
    "    for mode, index in modes.items():\n",
    "        for name in adj_cum_data[index].columns:\n",
    "        \n",
    "            # let's not plot empty charts\n",
    "            if adj_daily_data[index][name].sum() == 0: \n",
    "                    continue\n",
    "            \n",
    "            ps.plot_new_cum(\n",
    "                adj_daily_data[index][name].copy(), \n",
    "                adj_cum_data[index][name].copy(), \n",
    "                mode, \n",
    "                name,\n",
    "                'day',\n",
    "                title=f'{name}: COVID-19 {mode.title()}',\n",
    "                rfooter=data_quality[index][name],\n",
    "                save_as=f'{CHART_DIRECTORY}{name}-{mode.lower()}'\n",
    "                        f'-daily-new-vs-cum.png'\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # switch this output on/off\n",
    "    \n",
    "    # for cases then deaths ...\n",
    "    for mode, index in modes.items():\n",
    "        daily = adj_daily_data[index].copy()\n",
    "        \n",
    "        # for each nation\n",
    "        for name in daily.columns:\n",
    "            ps.plot_growth_factor(daily[name], \n",
    "                title=f'{name}: W/W growth in new COVID-19 {mode.lower()}',\n",
    "                ylabel='Week on Week Growth Factor',\n",
    "                xlabel=None,\n",
    "                save_as=f'{CHART_DIRECTORY}/{name}-{mode}-growth-factor.png',\n",
    "                lfooter=f'Ave. daily new {mode.lower()} this-week/last-week; '\n",
    "                        + data_quality[index][name],\n",
    "        )        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "209px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
