{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 in Australia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Python-set-up\" data-toc-modified-id=\"Python-set-up-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Python set-up</a></span><ul class=\"toc-item\"><li><span><a href=\"#other-useful-information\" data-toc-modified-id=\"other-useful-information-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>other useful information</a></span></li></ul></li><li><span><a href=\"#Scrape-Australian-cumulative-data-from-Wikipedia\" data-toc-modified-id=\"Scrape-Australian-cumulative-data-from-Wikipedia-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Scrape Australian cumulative data from Wikipedia</a></span></li><li><span><a href=\"#Produce-a-semilog-plot-of-cases-by-states.\" data-toc-modified-id=\"Produce-a-semilog-plot-of-cases-by-states.-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Produce a semilog plot of cases by states.</a></span></li><li><span><a href=\"#Total-bar-charts---most-recent-day\" data-toc-modified-id=\"Total-bar-charts---most-recent-day-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Total bar charts - most recent day</a></span><ul class=\"toc-item\"><li><span><a href=\"#bar-chart---cumulative-cases\" data-toc-modified-id=\"bar-chart---cumulative-cases-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>bar chart - cumulative cases</a></span></li><li><span><a href=\"#bar-chart---cumulative-cases-per-capita\" data-toc-modified-id=\"bar-chart---cumulative-cases-per-capita-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>bar chart - cumulative cases per capita</a></span></li></ul></li><li><span><a href=\"#Chart-new-and-cumulative-cases\" data-toc-modified-id=\"Chart-new-and-cumulative-cases-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Chart new and cumulative cases</a></span></li><li><span><a href=\"#Plot-new-cases:-raw-and-smoothed\" data-toc-modified-id=\"Plot-new-cases:-raw-and-smoothed-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Plot new cases: raw and smoothed</a></span></li><li><span><a href=\"#Growth-factor\" data-toc-modified-id=\"Growth-factor-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Growth factor</a></span></li><li><span><a href=\"#Regional-per-capita\" data-toc-modified-id=\"Regional-per-capita-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Regional per capita</a></span></li><li><span><a href=\"#Recent\" data-toc-modified-id=\"Recent-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Recent</a></span></li><li><span><a href=\"#Bring-it-all-together\" data-toc-modified-id=\"Bring-it-all-together-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Bring it all together</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib.animation as animation\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.units as munits\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "#pandas\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "# scraping\n",
    "import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# local imports\n",
    "sys.path.append(r'../bin')\n",
    "import plotstuff as ps\n",
    "\n",
    "# plotting\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### other useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state information\n",
    "colors = ['#ef4444', '#faa31b', '#eee000', '#82c341',\n",
    "          '#009f75', 'dodgerblue', '#394ba0', '#d54799']   # '#88c6ed', \n",
    "\n",
    "AUSTRALIA = 'Australia'\n",
    "state_pop = {\n",
    "    # source: https://www.abs.gov.au/ausstats/abs@.nsf/Latestproducts/3101.0Main%20Features3Sep%202019?opendocument&tabname=Summary&prodno=3101.0&issue=Sep%202019&num=&view=\n",
    "    'NSW': 8_118_000,\n",
    "    'VIC': 6_629_900,\n",
    "    'QLD': 5_115_500,\n",
    "    'SA':  1_756_500,\n",
    "    'WA':  2_630_600,\n",
    "    'TAS':   535_500,\n",
    "    'NT':    245_600,\n",
    "    'ACT':   428_100\n",
    "}\n",
    "N_STATES = len(state_pop)\n",
    "state_pop = pd.Series(state_pop).sort_values()\n",
    "state_names = state_pop.index.to_list()[::-1]\n",
    "state_pop[AUSTRALIA] = state_pop.sum()\n",
    "\n",
    "# save location\n",
    "CHART_DIRECTORY = '../charts'\n",
    "Path(CHART_DIRECTORY).mkdir(parents=True, exist_ok=True)\n",
    "CHART_DIRECTORY += '/!AS-'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Australian cumulative data from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_wiki_data():\n",
    "    \n",
    "    # get cases\n",
    "    url = 'https://en.wikipedia.org/wiki/Template:2019%E2%80%9320_coronavirus_pandemic_data/Australia_medical_cases'\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    tables = soup.findAll('table')\n",
    "    for table in tables:\n",
    "        if table.findParent(\"table\") is None:\n",
    "            cases = pd.read_html(table.prettify(), header=0, index_col=0)[0]\n",
    "            break\n",
    "            \n",
    "    # get deaths\n",
    "    url = 'https://en.wikipedia.org/wiki/Template:COVID-19 pandemic data/Australia deaths'\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    tables = soup.findAll('table')\n",
    "    for table in tables:\n",
    "        if table.findParent(\"table\") is None:\n",
    "            deaths = pd.read_html(table.prettify(), header=1, index_col=0)[0]\n",
    "            break\n",
    "\n",
    "    return cases, deaths\n",
    "\n",
    "#cases, deaths = scrape_wiki_data()\n",
    "#print(deaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_cleaning(df: pd.DataFrame, mode: str) -> pd.DataFrame:\n",
    "    \n",
    "    # 5. if the last row is today, \n",
    "    #    delete it as incomplete by definition\n",
    "    now = datetime.datetime.today().date()\n",
    "    yesterday = (pd.Timestamp((now - datetime.timedelta(days=1))\n",
    "                           .strftime('%Y-%m-%d'))\n",
    "                )\n",
    "    today = now.strftime('%-d %B')\n",
    "    year = now.strftime('%Y')\n",
    "    if df.index[-1] == today:\n",
    "        df = df.iloc[:-1]\n",
    "    \n",
    "    # 6. make numeric\n",
    "    df = df.astype(float)\n",
    "\n",
    "    # 7. make the index a DatetimeIndex\n",
    "    #    expand to all days\n",
    "    df.index = pd.DatetimeIndex(df.index + year, dayfirst=True).date\n",
    "    idx = pd.date_range(df.index.min(), df.index.max())\n",
    "    df = df.reindex(idx, fill_value=np.nan)\n",
    "    df = df.where(df > 0, other=np.nan).ffill().fillna(0)#.astype(int)\n",
    "    \n",
    "    # reindex (to PeriodIndex)\n",
    "    idx = pd.date_range(df.index.min(), yesterday)\n",
    "    df = df.reindex(idx, fill_value=np.nan).ffill()\n",
    "    \n",
    "    # 8. make sure it is in date order\n",
    "    df = df.sort_index()\n",
    "\n",
    "    # --- save it, just to be sure - you never know \n",
    "    #     when Wikipedia will stop making this available\n",
    "    SAVE_DIRECTORY = '../saved_AU_data'\n",
    "    Path(SAVE_DIRECTORY).mkdir(parents=True, exist_ok=True)\n",
    "    for_saving = df.copy()\n",
    "    filename = f'{SAVE_DIRECTORY}/Australia-{mode}-{today}.csv'\n",
    "    for_saving.to_csv(filename)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_wiki_cases(df):    \n",
    "    # --- clean-up what we scraped - very tedious\n",
    "    #     as this table is very messy - fragile\n",
    "    #     as Wikipedia constantly changes its layout\n",
    "    #     and format.\n",
    "\n",
    "    # 1. get rid of footnotes from column names, etc.\n",
    "    df.columns = (df.columns.str.replace('\\[.*\\]', '')\n",
    "                  .str.replace('  ', ' ')\n",
    "                  .str.strip())\n",
    "    df.index = df.index.str.replace('\\[.*\\]', '')\n",
    "\n",
    "    # 2. remove nan and other rows\n",
    "    df = df[df.index.notna()]\n",
    "    df = df[df.index.str.contains('[0-9]')] # not dates\n",
    "    df = df[~df.index.str.contains('Values')]\n",
    "    df = df[~df.index.str.contains('Notes')]\n",
    "\n",
    "\n",
    "    # 3. remove footnotes from specified columns\n",
    "    if 'Ref.' in df.columns:\n",
    "        del df['Ref.']\n",
    "    if 'Reference' in df.columns:\n",
    "        del df['Reference']\n",
    "    for c in df.columns:\n",
    "        df[c] = (df[c].str.replace('\\[.*\\]', '').str.strip())\n",
    "        df[c] = df[c].str.replace(',', '')\n",
    "\n",
    "    # 4. remove '%' text from specified columns\n",
    "    cols = ['% growth']\n",
    "    for c in cols:\n",
    "        df[c] = (df[c].str.replace('\\%', '')\n",
    "                 .str.strip().astype(float))\n",
    "\n",
    "    df = common_cleaning(df, 'cases')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_wiki_deaths(df):\n",
    "    \n",
    "    # 1. delete reference column\n",
    "    if 'Ref.' in df.columns:\n",
    "        del df['Ref.']\n",
    "    if 'Reference' in df.columns:\n",
    "        del df['Reference']\n",
    "    \n",
    "    # 2. remove nan and other rows\n",
    "    df = df[df.index.notna()]\n",
    "    df = df[df.index.str.contains('[0-9]')] # not dates\n",
    "\n",
    "    df = common_cleaning(df, 'deaths')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_and_clean_data():\n",
    "    cases, deaths = scrape_wiki_data()\n",
    "    cases = clean_wiki_cases(cases)\n",
    "    deaths = clean_wiki_deaths(deaths)\n",
    "    \n",
    "    return cases, deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce a semilog plot of cases by states. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semilog_plot(states_data, mode):\n",
    "    \n",
    "    power = 6\n",
    "    pop_factor = int(10 ** power)\n",
    "\n",
    "    for per_capita in [False, True]:\n",
    "        \n",
    "        if per_capita:\n",
    "            states_data = states_data / state_pop * pop_factor\n",
    "            states_data = states_data[state_names]\n",
    "            title = f' per $10^{power}$ pop.'\n",
    "            filename = '-per-capita'\n",
    "            \n",
    "        else:\n",
    "            title = ''\n",
    "            filename= ''\n",
    "    \n",
    "        ax = plt.subplot()\n",
    "        ax.margins(0.01)\n",
    "        ax.xaxis_date()\n",
    "\n",
    "        for i, name in enumerate(states_data.columns):\n",
    "            ax.plot(states_data[name].index, \n",
    "                    states_data[name], lw=2, \n",
    "                    color=colors[i], label=name)\n",
    "\n",
    "        ax.legend(loc='best', ncol=2)\n",
    "\n",
    "        ps.finalise_plot(ax, \n",
    "                         title= 'COVID19 Cumulative '\n",
    "                               f'{mode.title()}{title}:'\n",
    "                                ' Australia',\n",
    "                         chart_directory=CHART_DIRECTORY,\n",
    "                         xlabel=None,\n",
    "                         ylabel=f'{mode.title()}{title} (log scale)',\n",
    "                         yscale='log',\n",
    "                         rfooter='Source: Wikipedia',\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total bar charts - most recent day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bar chart - cumulative cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_chart_cumulative(states_data, mode):\n",
    "    states_data[AUSTRALIA] = states_data.sum(axis=1)\n",
    "    latest = states_data.iloc[-1]\n",
    "    date = states_data.index[-1].ctime()[:10]\n",
    "    latest = latest.sort_values()\n",
    "    ps.plot_barh(latest, \n",
    "        title=f'COVID19 Cumulative {mode}: Australian States',\n",
    "        save_as = f'{CHART_DIRECTORY}bar-chart-cumulative-{mode}.png',\n",
    "        rfooter='Source: Wikipedia ' + date\n",
    "    )\n",
    "    return latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bar chart - cumulative cases per capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_chart_cum_per_capita(latest, mode):\n",
    "    power = 6\n",
    "    pop_factor = int(10 ** power)\n",
    "    latest = (latest / state_pop) * pop_factor\n",
    "    latest = latest[state_pop.index].round(2) # pop order\n",
    "    ps.plot_barh(latest, \n",
    "             title=f'COVID19 Cumulative {mode.title()} per'+\n",
    "                 f' $10^{power}$ pop.: Australian States',\n",
    "             save_as = f'{CHART_DIRECTORY}bar-chart-per-capita-cumulative-{mode}.png',\n",
    "             rfooter='Source: Wikipedia'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chart new and cumulative cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_new_and_cum_cases(states_new, states_cum, mode, data_quality):\n",
    "    states_cum = states_cum.T\n",
    "    previous = states_cum.columns.min() - pd.DateOffset(days=1)\n",
    "    states_cum[previous] = 0\n",
    "    states_cum = states_cum.T.sort_index()\n",
    "\n",
    "    for name in states_cum.columns:\n",
    "        ps.plot_new_cum(\n",
    "            states_new[name].copy(), \n",
    "            states_cum[name].copy(), \n",
    "            mode, \n",
    "            name,\n",
    "            'day',\n",
    "            title=f'{name}: COVID-19 {mode.title()}',\n",
    "            rfooter=data_quality[name],\n",
    "            save_as=f'{CHART_DIRECTORY}daily-new-vs-cum-{name}-{mode.lower()}.png',\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot new cases: raw and smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_new_original_smoothed(states_new, mode):\n",
    "    HMA = 15\n",
    "    smooth_all = pd.DataFrame()\n",
    "    rolling_all = pd.DataFrame()\n",
    "    for name in states_new.columns:\n",
    "        smooth_all[name] = ps.plot_orig_smooth(states_new[name], \n",
    "            HMA, \n",
    "            mode,\n",
    "            'Australia', \n",
    "            title=f'Covid19: {name} (new {mode} per day)', \n",
    "            ylabel=f'New {mode} per day',\n",
    "            rfooter='Source: Wikipedia',\n",
    "            save_as=f'{CHART_DIRECTORY}new-{mode}-chart-{name}.png'\n",
    "\n",
    "        )\n",
    "        rolling_all[name] = states_new[name].rolling(7).mean()\n",
    "\n",
    "    # latest per-captia comparison \n",
    "    power = 5\n",
    "    pop_factor = int(10 ** power)\n",
    "    latest = rolling_all.iloc[-1]  \n",
    "    latest = (latest / state_pop) * pop_factor\n",
    "    latest = latest[state_pop.index].round(2) # pop order\n",
    "    ps.plot_barh(latest,\n",
    "        title=f'COVID19 Daily New {mode.title()} (7 day average) / $10^{power}$ population',\n",
    "        save_as=f'{CHART_DIRECTORY}bar-chart-per-capita-new-{mode}.png',\n",
    "        rfooter='Source: Wikipedia'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Growth factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_growth_factor(states_new, mode):\n",
    "    for name in states_new.columns:\n",
    "        ps.plot_growth_factor(states_new[name], \n",
    "            title=f'{name}: weekly growth - new COVID-19 {mode.lower()}',\n",
    "            ylabel='Growth factor',\n",
    "            xlabel=None,\n",
    "            save_as=f'{CHART_DIRECTORY}growth-chart-{name}-{mode}.png',\n",
    "            rfooter='Source: Wikipedia',\n",
    "            lfooter=f'Weekly rolling average daily new {mode.lower()} this week / last week'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regional per capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regional(df, mode):\n",
    "\n",
    "    if 'Total' in df:\n",
    "        del df['Total']\n",
    "        \n",
    "    regions = {\n",
    "        'Australia': ['NSW', 'VIC', 'QLD', 'WA', 'SA', 'TAS', 'ACT', 'NT'],\n",
    "    }\n",
    "    \n",
    "    #old = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=colors)\n",
    "    \n",
    "    ps.plot_regional_per_captia(\n",
    "        df[regions['Australia']], mode, regions, state_pop, \n",
    "        title=f'State per capita {mode.lower()}',\n",
    "        rfooter='Source: Wikipedia',\n",
    "        chart_directory=CHART_DIRECTORY\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recent(df, mode):\n",
    "    RECENT = 42 # days\n",
    "    MA1 = 7 # days\n",
    "    MA2 = 14 # dats\n",
    "    plt.style.use('ggplot')\n",
    "    \n",
    "    for col in df.columns:\n",
    "        series = df[col]\n",
    "        \n",
    "        if series.iloc[-RECENT:].sum() <= 0: \n",
    "            continue\n",
    "        ma1 = series.rolling(MA1).mean()\n",
    "        ma2 = series.rolling(MA2).mean()\n",
    "        \n",
    "        MARGINS = 0.01\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.xaxis_date()\n",
    "        ax.margins(MARGINS) # seems to work here\n",
    "        \n",
    "        #series.iloc[-RECENT:].plot.\n",
    "        ax.bar(series.iloc[-RECENT:].index.values, series.iloc[-RECENT:], label=mode, color='#dd0000')\n",
    "        ax.plot(ma1.iloc[-RECENT:].index.values, ma1.iloc[-RECENT:], label=f'{MA1} day ave.', color='darkorange')\n",
    "        ax.plot(ma2.iloc[-RECENT:].index.values, ma2.iloc[-RECENT:], label=f'{MA2} day ave.', color='cornflowerblue')\n",
    "        ax.legend(loc='best')\n",
    "        title = f'COVID19 Recent {mode.title()} in {col} '\n",
    "        ps.finalise_plot(ax, title=title,\n",
    "                         ylabel=f'Daily New {mode.title()}',\n",
    "                         rfooter='Source: Wikipedia',\n",
    "                         chart_directory=CHART_DIRECTORY,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSW           4847.00\n",
      "VIC          20361.00\n",
      "QLD           1241.00\n",
      "WA             853.00\n",
      "SA             569.00\n",
      "TAS            234.00\n",
      "ACT            118.00\n",
      "NT              73.00\n",
      "Total        28296.00\n",
      "New cases       20.00\n",
      "% growth         0.07\n",
      "Name: 2020-12-26 00:00:00, dtype: float64\n",
      "Negatives in NSW\n",
      "2020-04-12   -3.0\n",
      "2020-05-04   -2.0\n",
      "2020-05-27   -3.0\n",
      "2020-06-07   -1.0\n",
      "2020-06-12   -1.0\n",
      "2020-06-23   -1.0\n",
      "2020-11-13   -1.0\n",
      "Name: NSW, dtype: float64\n",
      "Spikes in NSW\n",
      "       2020-07-03\n",
      "spike  189.000000\n",
      "mean     8.285714\n",
      "zeros    0.000000\n",
      "Negatives in VIC\n",
      "2020-10-18   -2.0\n",
      "2020-10-26   -2.0\n",
      "2020-11-01   -1.0\n",
      "2020-11-02   -1.0\n",
      "2020-12-15   -1.0\n",
      "Name: VIC, dtype: float64\n",
      "Negatives in QLD\n",
      "2020-04-30   -1.0\n",
      "2020-05-25   -3.0\n",
      "2020-08-07   -1.0\n",
      "2020-08-15   -1.0\n",
      "2020-09-16   -1.0\n",
      "2020-10-31   -1.0\n",
      "2020-12-19   -1.0\n",
      "Name: QLD, dtype: float64\n",
      "Negatives in WA\n",
      "2020-05-12    -1.0\n",
      "2020-08-06   -28.0\n",
      "Name: WA, dtype: float64\n",
      "Negatives in SA\n",
      "2020-11-19   -1.0\n",
      "2020-12-26   -1.0\n",
      "Name: SA, dtype: float64\n",
      "Negatives in TAS\n",
      "2020-04-05   -1.0\n",
      "Name: TAS, dtype: float64\n",
      "Negatives in ACT\n",
      "2020-04-12   -1.0\n",
      "Name: ACT, dtype: float64\n",
      "Data too sparse in NT (max_consecutive=3)\n",
      "Data too sparse in NSW (max_consecutive=4)\n",
      "Data too sparse in QLD (max_consecutive=1)\n",
      "Data too sparse in WA (max_consecutive=2)\n",
      "Data too sparse in SA (max_consecutive=3)\n",
      "Data too sparse in TAS (max_consecutive=3)\n",
      "Data too sparse in ACT (max_consecutive=1)\n",
      "Data too sparse in NT (max_consecutive=0)\n",
      "Warning: ylim[0] is -0.051000000000000004 for NT\n"
     ]
    }
   ],
   "source": [
    "cases, deaths = scrape_and_clean_data()\n",
    "print(cases.iloc[-1])\n",
    "\n",
    "modes = ['cases', 'deaths']\n",
    "data = [cases, deaths]\n",
    "\n",
    "saved = {}\n",
    "\n",
    "for mode, uncorrected_cumulative in zip(modes, data):\n",
    "\n",
    "    # remove extraneous information from web scraping\n",
    "    uncorrected_cumulative = uncorrected_cumulative[\n",
    "        uncorrected_cumulative.columns[0:N_STATES]]\n",
    "    \n",
    "    \n",
    "    # save national for later\n",
    "    saved[mode] =  uncorrected_cumulative.sum(axis=1)\n",
    "  \n",
    "    # data transformation - correct for data glitches\n",
    "    (uncorrected_daily_new, \n",
    "         corrected_daily_new, \n",
    "         corrected_cumulative) = ps.dataframe_correction(uncorrected_cumulative)\n",
    "    \n",
    "    # footer\n",
    "    data_quality = pd.Series(None, \n",
    "                            index=corrected_cumulative.columns,\n",
    "                            dtype='str')\n",
    "    for col in corrected_cumulative.columns:\n",
    "        if (uncorrected_daily_new[col] == \n",
    "            corrected_daily_new[col]).all():\n",
    "            data_quality[col] = (f'Source: Wikipedia; original data')\n",
    "        else:\n",
    "            data_quality[col] = ('Source: Wikipedia; '\n",
    "                            'data adjusted for extreme outliers')\n",
    "    \n",
    "    # recent\n",
    "    recent(corrected_daily_new.copy(), mode)\n",
    "    \n",
    "    # regional line plota\n",
    "    regional(corrected_daily_new.copy(), mode)\n",
    "    \n",
    "    # state trajectories\n",
    "    states_data = corrected_cumulative.copy()\n",
    "    START_DATE = pd.Timestamp('2020-03-01')\n",
    "    states_data = states_data[states_data.index >= START_DATE]\n",
    "    semilog_plot(states_data, mode)\n",
    "\n",
    "    # bar charts cumulative cases - current status\n",
    "    states_data = uncorrected_cumulative.copy().astype(int)\n",
    "    latest = bar_chart_cumulative(states_data, mode)\n",
    "    bar_chart_cum_per_capita(latest, mode)\n",
    "\n",
    "    # New and cumulative cases\n",
    "    states_cum = corrected_cumulative.copy()\n",
    "    states_cum[AUSTRALIA] = states_cum.sum(axis=1)\n",
    "    states_new = corrected_daily_new.copy()\n",
    "    states_new[AUSTRALIA] = states_new.sum(axis=1)\n",
    "    data_quality[AUSTRALIA] = ('Source: Wikipedia; '\n",
    "                            'data adjusted for extreme outliers')\n",
    "    plot_new_and_cum_cases(states_new, states_cum, mode, data_quality)\n",
    "\n",
    "    # New cases original and smoothed\n",
    "    plot_new_original_smoothed(states_new.copy(), mode)\n",
    "\n",
    "    # Growth rates\n",
    "    plot_growth_factor(states_new.copy(), mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First wave CFR:  1.417651146629604\n",
      "Second wave CFR:  3.8197241836879767\n"
     ]
    }
   ],
   "source": [
    "# quick comparison of case fatality rates - firat and second Australian waves\n",
    "point1 = pd.Timestamp('2020-05-31')\n",
    "p = saved['deaths'].loc[point1], saved['cases'].loc[point1]\n",
    "print('First wave CFR: ', p[0] / p[1] * 100)\n",
    "print('Second wave CFR: ', (saved['deaths'].iloc[-1] - p[0]) \n",
    "      / (saved['cases'].iloc[-1] - p[1]) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "195.297px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
